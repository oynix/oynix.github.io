[{"title":"xargs 命令","url":"/2022/05/4a93513ce45a/","content":"\n[阮一峰的这篇写的非常详尽了](https://www.ruanyifeng.com/blog/2019/08/xargs-tutorial.html)，点个赞！\n\n<!--more-->\n\n但是，还是那个问题，Linux的xargs是GNU版本的，而Mac的xargs是BSD版本的，所以还是有着一些差别，记录几个能用、且常用的。\n\n- -p\n询问是否执行\n- -t\n把执行的命令输出，但不询问\n- -L\n传入多行参数时，通过L指定多少行执行一次后面的命令\n- -n\nL是限定每次多少行，n是限定每次多少个，比如一个有多个，可用n来限定\n- -I\n给每次使用的参数起个名字，后面命令中使用这个名字，在执行的时候会用真实的参数替换这个命名，注意，每次出现的这个命名都会被替换，可能会有一些意想不到的效果\n```shell\ncat file.text | xargs -I file echo file\n```\n- -P\n大写的P，进程数量，0表示不限制，能启动多少就启动多少，移动文件的时候试用，多进程会加快一些速度，理论上是这样的，但我实践过后，发现还不如直接用mv，感觉更快一些","tags":["Linux","Shell"],"categories":["Linux"]},{"title":"URL编码与解码","url":"/2022/05/ffa81c6fdcc4/","content":"这几天接触了很多的网址URL，形形色色的URL，其中多数都掺杂着%，之前只是知道这是转码，因为有些符号不能直接在URL里展示，这次学习了一下。\n\n<!--more-->\n\n### 1. 引题\n我们都知道，URL是可以传参数的，比如\n```\nhttps://www.google.com/search?q=tom&ie=UTF-8\n```\n像上面这样，通过Google搜索关键词tom时，就会访问这样一个URL，通过URL向Google传递了2个参数，一个是q一个是ie，通过&符号连接，Google在收到请求，解析的时候，也会通过&符号切割，并读取q和ie的值。\n\n同理，当要搜索tom&jerry时，对应的URL应该是这个样子\n```\nhttps://www.google.com/search?q=tom&jerry&ie=UTF-8\n```\n但是，Google在解析的时候，就会出问题，无法正确解析。这个时候就需要对URL进行编码，将&转换成%26，Google收到请求后，会先对URL解码，这样一来就不会出问题\n```\nhttps://www.google.com/search?q=tom%26jerry&ie=UTF-8\n```\n\n### 2. 编码和解码\n简单说，就是将其转换成16进制的形式，然后再用百分号%分隔。再通过shell中的xxd命令操作\n```shell\necho -n '&' | xxd -plain\n\n> 26 \n```\n其中，-n是为了去掉echo默认输出的回车符。\n\n- 编码\n其中，sed的command表示每隔两个字符，添加一个百分号\n```shell\necho -n '你好' | xxd -plain | sed 's/\\(..\\)/%\\1/g'\n\n> %e4%bd%a0%e5%a5%bd\n```\n\n- 解码\n解码的过程，将每个%和两个十六进制数字的形式，转换成\\x加两个十六进制数字的形式，然后，使用printf命令就可以输出\n```shell\nprintf $(echo -n '%e4%bd%a0%e5%a5%bd' | sed 's/\\(%\\)\\([0-9a-fA-F]\\{2\\}\\)/\\\\x\\2/g')\n\n> 你好\n```\n","tags":["URL"],"categories":["网络"]},{"title":"修改shell输出字体颜色","url":"/2022/05/de4f8861214c/","content":"\n这几天一直在爬网站，写的shell特别多，自然看的log也就多，调整不同类型log的颜色，能更直观，尤其是大量log疯狂刷屏的时候。其实很多时候，都是在使用过程中产生了新需求，然后去查一查这需求能不能实现，一查发现，哎，能实现，然后就学到了新的知识。\n\n<!--more-->\n\n这里的改变颜色，指的是改变在shell中输出的颜色，从本质上来讲，输出的其实都是字符，只不过对于一些特殊的字符，shell会帮忙顺手处理一下，然后再显示出来。对于颜色的标定，是使用`\\033[`来标记，shell设定好了一些颜色，比如绿色、红色等，除了颜色，还有样式，比如加粗，具体格式如下\n```shell\necho -e '\\033[31m 31m \\033[0m'\n```\n31m表示的是红色，0m表示不修改，也就是恢复。跟在`\\033[31m`后面的内容都会变成红色，因为只想改变这一条log的颜色，所以在结束后还要把颜色改回来，避免影响下面的输出。\n\n31之前的值，我挨着试了一遍，没有什么特别醒目的改变，后面的几个变化较为明显，光说是说不出来，还说上个图吧\n![](https://s2.loli.net/2022/05/17/wZXnPDcp5zuflFU.png)\n\n总的来说，31、32和33就是标准的红绿黄，可以用来输出error、debug和warn级别的log。剩下的也就35和36看上去还算直观，可以用来输出一些需要特别关注的log。","tags":["Linux","Shell"],"categories":["Linux"]},{"title":"shell tr命令","url":"/2022/05/61d4af8f9d77/","content":"\n上篇写了sed命令，它是以行为单位来处理数据的，而tr命令则是以字符为单位处理数据，这里的字符指的是ASCII码。\n\n<!--more-->\n\n### 1. 简介\ntr命令是操作字符的，命令的基本格式如下\n```shell\ntr string1 string2\n```\n除此之外，还有三个参数，分别是-d、-c和-s，这3个参数和上面的2个字符相互搭配，就有了多种方式。tr的输入可以用管道流，也可以用输入符`<`，默认输出到屏幕，也可以通过`>`符号输出到文件。\n\n### 2. 替换\n常用于大小写替换，会把处于string1中的字符，替换成string2中对应的字符\n```shell\necho 'abc MN op' | tr 'a-z' 'A-Z'\n\n> ABC MN OP\n```\n\n### 3. 删除\n删除需要使用-d参数，delete，通过string1指定需要删除的字符集，所以不需要string2\n```shell\necho 'abc MN op' | tr -d 'a-z'\n\n>  MN \n```\n\n### 4. 反向删除\n通过-c参数表示使用string1字符集的补集，complement，上面是将string1中的字符删掉，反向则是将不在string1中的删掉，下面这个命令则是把小写字母之外的字符都删除，包括空格\n```shell\necho 'abc MN op' | tr -d -c 'a-z'\n\n> abcop\n```\n\n### 5. 合并连续重复的字符\n通过-s参数，squeeze，压缩的意思，连续且重复的多个字符，只保留一个，通过string1指定需要压缩的字符集\n```shell\necho 'aaabbbccc' | tr -s 'a'\n\n> abbbccc\n```\n\n### 6. 压缩并替换\n当使用-s参数，并同时指定了string1和string2时，表示按照string1压缩，并且将string1中的字符替换为string2，下面这个命令表示，压缩空格，并将空格替换为-\n```shell\necho '2022   05  17' | tr -s ' ' '-'\n\n> 2022-05-17\n```","tags":["Linux","Shell"],"categories":["Linux"]},{"title":"sed命令","url":"/2022/05/b4ce17f18043/","content":"                       \n之前只是大概写过几句，很粗糙，这几天用的很频繁，发现它的功能很多，很强大，所以再来细致的说一说。\n\n<!--more-->\n\n### 1. 简介\n常用的功能是：删除文件行，替换行内字符串。基本格式是这样的，可处理文件，也可以处理管道流\n```shell\n# 从文件读取数据\nsed [command] [file]\n\n# 接收并处理管道的数据\ncat [file] | sed [command]\n```\n原理很直观，按行读取数据到缓冲区，按command处理数据，完成后将缓冲区的数据输出，默认输出的屏幕。从这个流程可以看出，默认情况下，sed命令是不会修改原文件的，但可以通过参数，使其修改原文件。\n\n另外多说一句，Linux上的sed是GNU版本，而Mac上的sed是BSD版本，两个命令名字相同，但有些行为有些差别，如果别人都可以的命令在自己的机器上却不生效，听我的，它就是不行，别浪费时间干耗了，赶紧换个方式，曲线也能救国。\n\n### 2. 关闭输出到屏幕\n通过-n参数，可以关掉sed将每次处理完的数据输出到屏幕的行为，建议关掉\n```shell\nsed -n [command] [file]\n```\n\n### 3. 修改原文件\n上面说过，sed不修改原文件，而是将修改后的数据默认输出到屏幕，可通过-i参数来修改这种行为。\n```shell\nsed -i 'backup' '3d' file.txt\n```\n`3d`是删除第3行的意思，这行命令执行完之后，会在当前路径下生成一个文件，文件名是在原文件名的基础上，再加上-i指定的后缀，即file.txtbackup，这个文件是修改前的原始内容，而file.txt则是修改后的内容，可以把-i理解为备份原文件。\n\n上面是在Mac上的行为，而在Linux上，-i只是表明要修改原文件，没有参数，也没有其他的操作。\n\n### 4. 删除命令 d\ndelete，sed是按行处理数据，所以，若删除便是一整行，而不能只删除其中的字符，文件的首行是第1行。删除一般有这么几种情况，删除某一行、删除某几行，删除符合特定条件的行，比如包含某个关键词，分别说一说。\n\n- 删除文件的第3行\n```shell\nsed '3d' file.txt\n```\n- 删除最后一行，这里使用$符号，这和正则里相同\n```shell\nsed '$d' file.txt\n```\n- 删除文件第2到5行\n```shell\nsed '2,5d' file.txt\n```\n- 删除包含apple的行\n```shell\nsed '/apple/d' file.txt\n```\n- 从第2行开始删除，首次遇到含有apple的行后，停止\n```shell\nsed '2,/apple/d' file.txt\n```\n- 首次遇到含有apple的行开始删除，一直到第10行停止，为什么强调首次呢，因为可能会出现多行都含有apple的情况\n```shell\nsed '/apple/,10d' file.txt\n```\n- 删除空行，这个命令是个正则表达式，表示开头和结尾挨着的行，也就是空行，但是在Mac上不好使\n```shell\nsed '/^$/d' file\n```\n- 不删除，即反向删除，上面说的都是符合条件则删除，反向删除是符合条件才不被删除，如，包含apple则不删除，否则删除\n```shell\nsed '/apple/!d' file\n```\n\n### 5. 替换命令 s\nsubstitute，替换的意思，命令基本格式如下\n```shell\nsed 's/[old]/[new]/[scope]'\n```\n同样，还是以行为基本操作单位，将其中的old，替换成new，而scope表示要替换的范围，可能值有1，2...或者g，表示替换该行的第几处，1则只替换该行的第一处的old，2同理，而g表示替换该行里所有的old。old是用来过滤目标字符串的，因为其中的支持多种形式语法，花样繁多，也正是此造就了sed强大的功能。\n- 将每行所有apple替换成banana\n```shell\nsed 's/apple/banana/g' file.txt\n```\n- 将每行所有apple或者Apple替换成banana，中括号代表一个字符，里面是可能的值\n```shell\nsed 's/[Aa]pple/banana/g' file.txt\n```\n- 将每行所有apple替换成pineapple，在new中，&代表old的值，所以pipe&就代表pipeapple\n```shell\nsed 's/apple/pipe&/g'\n```\n- 字符展位，`.`表示1个字符，比如下面这个命令表示，不管pple前面是什么字符，都会连带着一起替换成banana\n```shell\nsed 's/.pple/banana/g' file.txt\n```\n- 字符数量，`?`表示0或者1，`*`表示0或者多个，`{n}`表示固定为n个，`{n,}`表示n个或者更多，`{n,m}`表示数量在n到m之间。下面这个命令表示把两个连续的a，替换成BB\n```shell\nsed 's/a\\{2\\}/BB/g' file.txt\n```\n\n### 6. 子串\n在old里面用小括号可以表示子串，子串按照顺序可在new中用\\1，\\2表示\n```shell\nsed 's/\\(a\\)\\(pple\\)/\\1-\\2/g' file\n```\n这条命令中，在old中，apple用括号分成了两部分(a)(pple)，其中a是第1个子串，pple是第2个子串，在new中\\1和\\2分别表示两个子串，最终apple就会被替换成a-pple。\n```shell\nsed 's/\\(.\\)\\(pple\\)/A\\2/g' file\n```\n而这条命令，则是用一个句点占位符，所以，不管old中pple前面的字符是什么，最后都会被替换成Apple。\n\n### 7. 打印命令 p\nprint，这个命令和删除命令的用法基本一致，即，打印某一行、某几行、符合限定条件的行\n```shell\nsed '1,4p' file.txt\n```\n### 8. 写文件命令 w\nwrite，后面跟着输出文件，不存在则创建，存在则覆盖，效果等同于复制。下面这条命令，就会把file.txt的内容写入到cp.txt文件中\n```shell\nsed 'wcp.txt' file.txt\n```\n\n### 9. 执行多个命令\n上面的例子中，我们对每一行只执行了一条命令，实际上可以一次执行多个命令，命令之间用分号分隔。比如，下面这行命令就表示先把该行所有apple替换成banana，然后再把这行输出到result.txt文件中\n```shell\nsed 's/apple/banana/g;w result.txt' file.txt\n```\n或者分开写，同时用-e参数，\n```shell\nsed -e 's/apple/banana/g' -e 'w result.txt' file.txt","tags":["Linux","Shell"],"categories":["Linux"]},{"title":"shell多进程并发","url":"/2022/05/8e045ba5bfb4/","content":"\nshell本身是不支持多线程的，想要并发编程，可以使用多进程。\n\n<!--more-->\n\n### 引言\n\nshell多进程写法很方便，在执行的命令结尾加一个`&`符号，便可以把当前操作放到后台进程执行，而当前进程可以继续执行其他操作。直接操作，进程数量会变得不可控，比如，对一个目录下每个文件都要执行一个操作，该操作通过`&`放到后台进程执行，那么，当该目录下有10个文件时，就会启动10个进程，有100个文件时，就会启动100个进程。\n\n而每个进程都是占用系统资源的，有些资源是有一定限制的，用`ulimit`命令可以查看\n```shell\n$ ulimit -a\ncore file size          (blocks, -c) 0\ndata seg size           (kbytes, -d) unlimited\nfile size               (blocks, -f) unlimited\nmax locked memory       (kbytes, -l) unlimited\nmax memory size         (kbytes, -m) unlimited\nopen files                      (-n) 256\npipe size            (512 bytes, -p) 1\nstack size              (kbytes, -s) 8192\ncpu time               (seconds, -t) unlimited\nmax user processes              (-u) 2784\nvirtual memory          (kbytes, -v) unlimited\n```\n可以看到，其中，进程的栈大小限制8192k bytes，即8M，当创建100个进程时，就会占用800M内存。而当内存不够时，系统就会报错提示，\n```shell\nResource temporarily unavailable\n```\n\n所以，需要对进程总数进行控制，下面说下通过管道控制的方式。\n\n### 管道FIFO First In First Out\n```shell\ntouch lock_f\n\ntrap \"rm -f lock_f;exec 9<&-;exec 9>&-;exit 0\" 2\n\nthread_num=10\n\ntemp_pipe=$$.fifo\nmkfifo $temp_pipe\nexec 9<>$temp_pipe # 绑定\n#rm -rf $temp_pipe\n\nfor (( i = 0; i < thread_num; i++ )); do\n\techo\ndone >&9\n\nfor (( i = 0; i < 20; i++ ));\ndo\n\t{\n\t\techo \"$i wait\"\n\t\tread -u9\n\t\techo \"$i start\"\n\t\tif [[ -f lock_f ]]; then\n\t\t\techo >&9\n\t\t\texit\n\t\tfi\n\t\tsleep 2\n\t\techo \"$i end\"\n\t\techo >&9\n\t} &\ndone\n\nwait\n\nrm lock_f\n\nexec 9>&- # 关掉输出\nexec 9<&- # 关掉输入\n\necho \"all end\"\n```\n- 通过trap拦截编号是2的信号，然后在里面执行一些操作\n- 通过lock file将中断通知给所有进程\n- mkfifo创建管道，然后与系统输入输出绑定，操作系统输入输出等同于操作管道\n- 使用wait，等待所有进程执行完毕","tags":["Linux","Shell"],"categories":["Linux"]},{"title":"极简爬虫ons.ooo","url":"/2022/05/f8397aff378b/","content":"\n偶然发现了几个都是很好看的网站，这是其中之一，[https://ons.ooo/](https://ons.ooo/)，临睡起意，写了几个简单的脚本，把上面的图片都抓了下来，一共有16万多张，大概有23个G。\n\n<!--more-->\n![](https://s2.loli.net/2022/05/11/ZCTuQAqwU3Gybh2.png)\n\n### 1. 简介\n爬虫，一般都是用Python，用Node，或者用Go，为了省事，就直接写了几个shell脚本，也幸亏这个网站的结构是传统的分页设计，要是动态加载的那就没得玩了。\n\n目前一共273页，每页有24个item，每个item点进去就是一个组图，组图里面是完整的，没有分页，组图里图片数量不等，少的十几张，多的几十张到近百张，这便是网站的整体结构设计。\n\n### 2. 思路\n最简单的想法，就是模拟人真实的浏览，遍历每一页，再遍历每一页上的每一个item，进入item之后，再遍历每一张图片，下载到本地，这也是我最开始的想法。\n\n这种方案有一个明显的弊端，会产生很多重复的请求。比如出错重试时、其他人下载时、调试时，等等，都会从头走一遍这个流程。简单说，我们的目的就是为了获取图片的URL，然后下载到本地，而这个URL是不变的，所以对于不变的量，获取一次就可以了，超过一次就是浪费流量。\n\n为了避免重复获取，稍微调整了一下思路，第一步先将所有图片的URL存储到本地，第二步将URL对应的图片下载到本地。第一步很快而且出错概率低，而下载图片出错概率较高，如连接超时、请求中断，等等。\n\n### 3. 通道并发\n如果用单个进程去跑，时间长的有些感人。单拿获取所有图片URL来说，请求一个item大概需要3秒左右，每页有24个item，一共有273页，将近20万秒，大概5个小时，下载的话会更久\n```shell\ntotal = 3 * 24 * 273 = 19656s\n```\n为了提速节省时间，使用了多进程并发，通过通道来控制，使用20个进程的情况下，拿到这16万张图的URL，需要17分钟上下，具体还要看网络情况，相比之下，这是量级的飞跃。如果机器允许，还可以进一步增加进程的数量。不要贪多，这个是进程，切换进程上下文的成本很高，如果并发过多，反倒会变慢。\n\n### 4. 实现\n脚本中，除了字符串操作，唯一用到的命令就是`curl`了，这大概就是极简中的极简。通过`curl`拿到html，经过一些列字符串操作，定位到其中的href、src，等等。\n\n工程里有两个html文件，一个是page的，一个是article的，page就是273页中的每一页，分析这个文件就可以得到页面中每一个item的href连接。而article则是item点进去的详情页面，分析这个文件便可以知道，组图中每一张图片的src下载链接。\n\n### 5. 仓库\n[Github Spider-onsooo](https://github.com/oynix/Spider-onsooo)","tags":["爬虫，美图"],"categories":["爬虫"]},{"title":"JetBrains证书服务器","url":"/2022/05/c53c55583592/","content":"上回说到新版本的IDE中都开始用JetBrains账号登陆，限制了很多行为，今天又发现一个新的方式。\n\n<!--more-->\n\n有一说一，JetBrains的IDE确实好用，连Android Studio也是在IntelliJ IDEA的基础上开发出来的，但它有一个绝对优势的改良，那就是免费，给了我们这些本不富裕的家庭很大的理解。\n\n对于并不免费的JetBrains家族的IDE们，早前最普遍的破解方式，就是从网上找不愿透露姓名的热心网友提供的公开license，或者认证服务器，随便一搜就有一大片，至于可用性要自己一一试过才知道，这种方式与其说是破解，倒不如直接说是白嫖，该花的钱都花了，只是花钱的不是自己罢了。但是这种方式有个弊端，就是不稳定，下班关机前还能开开心心敲代码，等到第二天再来，发现失效了，要么就是验证失败了。这个时候，又要从头再来，接着从网上搜索，一个一个过滤，相当麻烦，别人都写完几个bug了，你连IDE还没打开。\n\n后来，聪明机智的神秘东方网友，发现了一种曲线救国的方式，所有收费的IDE都是有一个30天的试用期的，试用期间的功能和正版license的功能是完全一样的，这下我不想着破解了，我就试用，等快到期了，我就把试用期重置，这样又能试用30天，用完这30天还有30天，在这30天后面等着的，是下一个30天。\n\n就这样，上有政策下有对策，JetBrains高一尺，网友们高一尺五，相互制衡之下，也算是相安无事。直到几个月前，横空出世的JetBrains账号，打破了这原本平静的局面。\n\n新版本的IDE，要想试用，就需要先登录一个叫做JetBrains账号的东西，如果没有，跳到官网便可注册。看到这，我大抵是懂了，开始要绑定了，不知道是不是和Unity学的，试用的30天和账号绑定起来了，这样就没法无限试用了。当然，这还只是我的猜测，没去验证，因为咱们这边表示这个账号的门槛太高，直接给咱们拦住了，所以就没试。\n\n好在还有退路，那就是，不升级，专门盯着官网的老版本下载。\n\n但是，转折来了，这也是今天要说的主题（铺垫了这么久，总算到了主题）。\n\n发现了一个服务器的搜索引擎。什么意思呢，搜索引擎，像谷歌，像百度，可以根据输入的关键词搜索到网络上公开的一些资源，比如网页，比如图片。而服务器搜索引擎，则是根据输入的条件，搜索网络上开放的机器，一台网络上的机器要想提供服务，总是要暴露出一些端口出来的，比如网页服务暴露80端口，https服务要暴露443接口，只要暴露出来，就可以被扫描到，这就是服务器搜索引擎的大致原理。\n\n服务器搜索引擎：[https://search.censys.io/](https://search.censys.io/)\n\n过滤条件是\n```shell\nservices.http.response.headers.location: account.jetbrains.com/fls-auth\n```\n这是固定的语法，大致的意思就是，访问器的回应消息头中的location，包含jetbrains。依据这个条件，判断这个机器是提供JetBrains认证服务的，那么把这个地址填到IDE的认证框里即可，如果不能用，就从搜索结果列表里换一个，这种比之前大海捞针的方式高效、快捷多了。\n\n最后还是要说一句，家里条件好的同学，要去买买正版。","tags":["JetBrains"],"categories":["JetBrains"]},{"title":"Android存储文件路径汇总","url":"/2022/05/eb42e35aec3a/","content":"\n总结下应用内可用的存储路径。\n<!--more-->\n\nContext获取存储目录的方法比较多，比如File目录，Cache目录，大致上可以分为两类，一类是应用内私有，只有应用自身可以访问，其他应用不可以直接访问，对于用户也是不可见的，但可以通过FileProvider将文件分享出去；另一类是应用外私有，同样是应用自身可以访问，但是用户是可以看到的。它们的共同点是，不需要系统权限，同时，会随着应用卸载而被删除。若不想被删除，那么就需要存储到共有目录中，而访问共有目录，就需要申请系统权限了。\n\n### 1. 应用内私有\n```java\nContext.getCacheDir();\nContext.getDataDir();\nContext.getFilesDir();\nContext.getCodeCacheDir();\nContext.getDir(String name, int mode);\n```\n这几个目录，所有的机型大致都在这个目录下，其中package name就是应用的包名\n```java\n/data/data/package_name/\n```\n其中，getDataDir指的就是该目录，其他的则会在该目录下创建文件夹，CacheDir对应cache目录，FilesDir对应files目录，CodeCache对应code_cache目录，而getDir则会创建新目录，名字就是第一个参数加上app前缀。\n\n### 2. 应用外私有\n```java\nContext.getExternalCacheDir();\nContext.getExternalCacheDirs();\nContext.getExternalFilesDir();\nContext.getExternalFilesDirs();\n```\n这几个目录，基本在这，package name也是应用包名，因为位于storage下，所以，对于用户是可见的\n```java\n/sdcard/Android/package_name/\n```\n或者，还有其他的目录映射，不同机型可能会有所差别\n```java\n/storage/self/primary/Android/package_name/\n```\n\n### 3. 公有目录\n```java\nEnvironment.getExternalStorageDirectory();\n```\n这个目录，对应的共有路径，访问这个目录，需要申请系统的读写外部存储的权限\n```java\n/sdcard/\n/storage/self/primary/\n```\n\n### 4. 总结\n- 应用私有的目录，在应用卸载时会被系统删除\n- 不同的ROM，路径可能会有差别，但是获取方式和使用原则是一样的\n- 要想把应用私有目录下的文件分享出去，参考[FileProvider的使用](https://oynix.github.io/2022/04/a19e8bb0ccff/)\n- 共有目录需要权限，私有的不需要，所以若不是必要，存储在应用私有的目录即可，减少权限的申请","tags":["Android"],"categories":["Android"]},{"title":"SharedFlow和StateFlow","url":"/2022/05/5e396ce92540/","content":"\n说完Flow，再来看看它的两个子类，SharedFlow和StateFlow。\n\n<!--more-->\n### 1. 冷流，热流\n在说之前，要先看看这两种流有什么不同。冷流，指的是只有在消费者消费时才会生产数据。而热流，即便没有活跃的消费者，它们也可以存活，也就是说，数据在流外产生，然后传递给数据流，这样便不依赖收集者。\n\n### 2. SharedFlow\n相比于冷流Flow，SharedFlow是热流，它以广播的形式向流的所有收集者发射数据，所以，所有的收集者都可以接收到发射的数据。它之所以叫做热流，是因为它的实例独立于收集者的存在而存在，这一点区别于flow函数创建的Flow，它是冷流，并且为每个收集者单独启动。\n\nSharedFlow永远不会完成，通过调用流的collect不会正常完成，通过launchIn函数调用也不会正常完成。SharedFlow的活跃收集者称为订阅者。\n\n订阅者是可以被取消的。通常随着协程运行所在的scope的取消而取消。一个SharedFlow的订阅者总是可以取消的，所以每次发射数据前都会对其作出检查。流的多数终端操作符在SharedFlow上都不会完成，比如toList，但是流的裁剪操作符可以完成，比如take、takeWhile。\n\nSharedFlow会保存指定数量的最新的数据，存储在replay cache里，每一个新的订阅者，都会先从获取replay cache中的数据，然后才是新发射的数据。replay cache的大小可在创建时通过参数replayCache指定。也可通过resetReplayCache重置replay cache。\n\n```kotlin\nclass EventBus {\n    private val _events = MutableSharedFlow<Event>() // private mutable shared flow\n    val events = _events.asSharedFlow() // publicly exposed as read-only shared flow\n\n    suspend fun produceEvent(event: Event) {\n        _events.emit(event) // suspends until all subscribers receive it\n    }\n}\n```\n上面是通过MutableSharedFlow创建了一个流，也可以通过shareIn操作符，将一个冷流转化成为SharedFlow。在发射数据时，方法会挂起，直到所有的订阅者接收到了数据并返回。\n\n和Channel类似，SharedFlow也提供了缓冲区的配置参数，\n```kotlin\npublic fun <T> MutableSharedFlow(\n    replay: Int = 0,\n    extraBufferCapacity: Int = 0,\n    onBufferOverflow: BufferOverflow = BufferOverflow.SUSPEND\n): MutableSharedFlow<T> {}\n```\nreplay表示存储的倒数最新事件的数量，buffer capacity则是缓冲区的容量大小，overflow为缓冲区数据满时，再发射数据时的行为策略，同样还是有三种：挂起等待、扔掉最新数据和扔掉最老的数据。\n\n### 3. StateFlow\n```kotlin\npublic interface StateFlow<out T> : SharedFlow<T> {\n    public val value: T\n}\n```\n从接口定义可以看出，StateFlow是SharedFlow的子类，所以SharedFlow的特性它都有，区别在于，它只保存最新的数据，只有一个数据值，这个时候也可以称它为状态，所以的它的名字是StateFlow\n```kotlin\npublic fun <T> MutableStateFlow(value: T): MutableStateFlow<T> {}\n```\n\n### 4. SharedFlow和StateFlow的不同\n- 从创建方法可以看出，StateFlow有初始值，SharedFlow没有。这其实就是replay的大小不同，State固定为1，所以它需要有个初始值，而Shared不确定，所以不需要。\n\n### 5. 应用\n根据二者的特点，可以看出，SharedFlow适合应用于事件的场景，而StateFlow则是适合用于更新状态的场景。\n\n### 6. 和LiveData对比\n说完上面那些，感觉这些又和LiveData有些相似，其实它们之间还是有着一些不同。\n\nLiveData是生命周期敏感的，因为它里面维护着Lifecycle，所以在进入到DESTROYED状态时，会取消当前的Observer，而Flow则是通过检查订阅者所在的协程是否还活跃来判断是否向其发射数据。\n\n此外，LiveData是不防抖动的，也就是说，每次postValue都会通知给Observer，而StateFlow是防抖动的，因为它固定保留一个最新的状态值，在每次发射数据前，都会把要发射的数据和当前保存的值对比，如果相同则忽略这次发射，所以它是防抖动的。\n\n最后说一句SharedFlow的shared，它的shared，共享，指的是它的数据对所有的收集者，也就是订阅者共享，同一个数据会广播给所有的订阅者，而冷流Flow，对于每一个收集者，都会执行生成数据的操作，所以它是独立的。\n","tags":["Kotlin","SharedFlow","StateFlow"],"categories":["Kotlin"]},{"title":"Kotlin的Channel","url":"/2022/05/586878aa60a4/","content":"\nChannel，直译过来就是通道的意思，有从通道读取别人数据的通道，也有将数据写给别人的通道，当然，也有既可以读数据也可以写数据的通道。这是通俗的解释，专业一点来讲，通道就是生产者消费者的模型。\n\n<!--more-->\n\n### 1. 使用\n```kotlin\nsuspend fun main() {\n\t// 创建一个Channel类型的实例\n    val channel = Channel<Int>()\n\n    // 生产者：负责向通道中写数据\n    val producer = GlobalScope.launch {\n        var i = 0\n        while (true) {\n            channel.send(i++)\n            delay(1000)\n        }\n    }\n\n    // 消费者：负责从通道中读数据\n    val consumer = GlobalScope.launch {\n        while (true) {\n            val element = channel.receive()\n        }\n    }\n\n    producer.join()\n    consumer.join()\n}\n```\n通过Channel方法就可以方便的初始化出来一个通道实例，因为channel的send和receive方法，都是挂起函数，所以要将它们放到协程中调用。为什么都是挂起函数呢？既然是生产者消费者模型，那么肯定就存在速度不同步的情况，生产者生产出一个数据，但是消费者还在忙碌中，写入后无法被接收，那么它就挂起等待；消费者也是同理，它想从通道读取一个数据来处理，但是生产者还没生产出来，那么它也挂起等待，所以这两个函数都是挂起函数。\n\n### 2. 通道的缓存\n通道提供了缓存，来缓解生产者和消费者之间速度差问题。我们上面创建通道使用的Channel，它不是一个构造函数，而是一个伪造成构造方法的工厂方法，\n```kotlin\npublic fun <E> Channel(\n    capacity: Int = RENDEZVOUS,\n    onBufferOverflow: BufferOverflow = BufferOverflow.SUSPEND,\n    onUndeliveredElement: ((E) -> Unit)? = null\n): Channel<E> =\n    when (capacity) {\n        RENDEZVOUS -> RendezvousChannel()\n        UNLIMITED -> LinkedListChannle()\n        CONFLATED -> ConflatedChannle()\n        else -> ArrayChannel(capacity)\n    }\n```\n它有3个参数，分别是通道缓存的容量、超出缓存容量时的行为策略，以及超出元素的处理操作。\n- capacity\nRENDEZVOUS，这个词直译过来是约会的意思，虽然现代人的约会千奇百怪，但是在设计者的想法里，约会就是一对一的形式，所以这种情况下，通道是没有缓存的，生产者写不进数据就等着，消费者读不到数据也等着；\nUNLIMITED这个就很好理解了，没有限制，所以它是一个LinkedList类型的通道，来者不拒，所有来不及消费的数据我都给你缓存下来；\nCONFLATED这个词和inflate正好相反，还记得我们在加载布局文件时，用的是LayoutInflater的inflate方法，它是扩充、扩张的意思，所以conflate就是合并、缩小的意思，实际的效果就是，这种类型的通道只缓存最新的、最后一个元素。\nArrayChannel也很好理解，根据传入的capacity创建一个固定容量的数组型通道。\n- onBufferOverflow\n即便是给通道设置了缓存，那么还是有超出缓存容量的可能，这个参数就是用来设置超出容量时的行为，它有3个可选值：SUSPEND，顾名思义，就是挂起等待的意思；DROP_OLDEST，丢弃最老的，也就是最新的会把最老的元素挤掉；DROP_LATEST，刚好相反，丢弃最新的。\n- onUndeliveredElement\n一个可选参数，当数据元素发送后，但是没有传送到消费者，这个函数就会被调用\n\n### 3. 迭代通道\n前面的例子中，消费者从通道中读取数据时，是在while循环里操作的，实际上，通道本身是支持迭代的，所以消费者还可以这样写，\n```kotlin\nval consumer = GlobalScope.launch {\n    val iterator = channel.iterator()\n    while (iterator.hasNext()) {\n        val element = iterator.next()\n    }\n}\n```\n当没有数据时，协程就会在hasNext方法挂起，直到有新的数据写入到通道内，这个写法自然还可以进一步简化成foreach，\n```kotlin\nval consumer = GlobalScope.launch {\n    for (element in channel)\n        \n    }\n}\n```\n\n### 4. 通道的关闭\nChannel本身是个接口类型，它继承了读通道和写通道\n```kotlin\npublic interface Channel<E> : SendChannel<E>, ReceiveChannel<E> { }\n```\n它的父接口中，只有写通道，也就是SendChannel有关闭方法，而ReceiveChannel没有关闭方法。这是什么意思呢？这就好比会上领导发言，领导讲话结束之后，都会说上一句我说完了，这个时候你也听完了，如果领导刚说到一半，你急着下班回家，然后你说一句我听完了，那么领导这个时候是说，还是不说呢。所以，结束这个事要由发送者来调用。\n\nSendChannel有一个isClosedForSend的属性，当调用close后，这个属性会立刻返回true，表示不会再向通道中写入数据。同样，ReceiveChannle有个isClosedForReceive的属性，因为有缓冲的存在，所以只有当缓冲区内的数据都被处理完时，这个属性才会返回true。","tags":["Kotlin","Channel"],"categories":["Kotlin"]},{"title":"Kotlin Flow","url":"/2022/05/54728a7f7b90/","content":"\nKotlin的Flow和RxJava有着很多相似之处，提供了很多操作符来操作数据流。简单写一些使用笔记\n\n<!--more-->\n\n### 1. 特点\n- 冷流\n创建后不发射数据，使用终端操作符后才触发发射数据。\n- 生产消费交替执行\n在数据流上，发射数据的称为生产者，处理数据的称为消费者，二者交替执行，生产-消费-生产-消费，在考虑背压情况下，生产次数可能会多于消费次数。\n\n同RxJava，所以Flow也是有着大量的操作符，掌握了这些操作符，基本也就会用了。\n\n### 1. 流构建器\n- flow方法\n```kotlin\nflow { for (i in 1..5) { emit(i) } }.collect { println(it) }\n```\n- flowOf方法\n内部调用的是flow方法\n```kotlin\nflowOf(1, 2, 3).collect { print(it) }\n```\n- asFlow方法\n内部调用的还是flow方法\n```kotlin\narrayOf(1, 2, 3).asFlow().collect { print(it) }\n```\n此外，还有几个其他的，提供的默认构建器都写在`Builders.kt`里。\n\n### 2. 切换线程操作符\n是用操作符`flowOn`来切换上游操作发生的线程\n```kotlin\nflowOf(1, 2, 3).flowOn(Dispatchers.IO).collect { print(it) }\n```\n而处理数据所在的线程取决于调用终端操作符的线程\n```kotlin\n// 上游发射数据操作发生在IO线程\nval flow = flowOf(1, 2, 3).flowOn(Dispatchers.IO)\n\n// 处理数据发生的主线程\nmainScope.launch {\n    flow.collect { print(it) }\n}\n\n// 处理数据发生在子线程\nioScope.launch {\n    flow.collect { print(it) }\n}\n```\n\n### 3. 终端操作符\n上面提到了终端操作符，所谓终端操作符，就是在这条数据流上末端调用的操作符，即触发收集数据的操作，除了上面提到的collect，还有几个：\n- collect：收集所有\n- first/single：取首个/单个（只允许有一个，否则报错）\n- toList/toSet/toCollection：转化成集合\n- count：计数\n- reduce/fold：合并，同集合操作，fold有初始值reduce没有\n- launchIn/produceIn/broadcastIn：触发流启动\n\n### 4. 过渡操作符\n- filter\n过滤操作，返回一个boolean值，true时将传入下游\n```kotlin\nflowOf(1, 2, 3).filter { it % 2 == 0 }.collect { print(it) }\n```\n- map\n这里的转换操作是指，将上游流中的传下来的每个数据转换成其他形式\n```kotlin\nflowOf(1, 2, 3).map { \"to String: $it\" }.collect { print(it) }\n```\n\n### 5. 限长操作符\n使用take来限制传到下游数据的数量\n```kotlin\nflowOf(1, 2, 3).take(2).collenct { print(it) }\n```\n\n### 6. 转换操作符\n常用transform，可以实现map和filter，也可以实现更为复杂的转换，可以发射任意次数据\n```kotlin\nflowOf(1, 2, 3).transform {\n    if (it > 1) emit(it * it)\n    if (it > 2) emit(it * 10)\n    emit(it)\n}.collect { print(it) }\n```\n\n### 7. 捕获异常\n```kotlin\nflowOf(1, 2, 3).catch { print(it) }.collect { print(it) }\n```\n\n### 8. 背压\n背压是指上游生成数据的速度高于下游处理数据的速度，这个时候下游应该怎么办。一般有这么几种策略：把多出的扔掉、把多出的合并和把多出的缓存\n- conflate\n合并的意思是，只保留最新的，当消费者正在忙的时候，生产出来的数据直接放弃了。如，生产者每100ms生产一个数据，但是消费者处理一个数据需要500ms，那么，消费者只能处理到第1，5，10...个数据\n```kotlin\nflow {\n    for (i in 1..5) {\n        emit(i)\n        delay(100)\n    }\n}\n.conflate()\n.collect {\n    delay(500)\n    pritnt(\"finish with $it\")\n}\n```\n- collectLatest\n收集最新数据，对于每一个从上游传来的数据，消费者如果正在忙碌，那么就取消当前的任务，来处理最新来的数据。意思就是说，消费者对于每一个数据都会处理，但不一定能处理完。对于下面这个例子，前面的数据都只能打出begin，只有最后一条数据能打出begin和finish\n```kotlin\nflor {\n    for (i in 1..5) {\n        emit(i)\n        delay(100)\n    }\n}.collectLatest {\n    print(\"begin with $it\")\n    delay(500)\n    print(\"finish with $it\")\n}\n```\n- buffer\n缓冲，设置缓冲大小后，会将上游发来的数据存在缓冲池。缓冲池是在生产者和消费者之间创建的一个Channel，缓冲池大小就是Channel的大小，同时允许配置生产的数据超过缓冲池大小时的行为，挂起、扔掉最新和扔掉最旧\n```kotlin\nflor {\n    for (i in 1..5) {\n        emit(i)\n        delay(100)\n    }\n}\n.buffer(3)\n.collectLatest {\n    print(\"begin with $it\")\n    delay(500)\n    print(\"finish with $it\")\n}\n```\n\n### 9. 合并流\n- zip\n合并两个流成一个流，最终流的长度取决于最短流的长度\n```kotlin\nval flow = flowOf(1, 2, 3).onEach { delay(10) }\nval flow2 = flowOf(\"a\", \"b\", \"c\", \"d\").onEach { delay(15) }\nflow.zip(flow2) { i, s -> i.toString() + s }.collect {\n    println(it) // Will print \"1a 2b 3c\"\n}\n```\n- combine\n它和zip的区别是，最终流的长度是较长流的长度，在合并时，使用另一个流中最新的数据\n```kotlin\nval flow = flowOf(1, 2).onEach { delay(10) }\nval flow2 = flowOf(\"a\", \"b\", \"c\").onEach { delay(15) }\nflow.combine(flow2) { i, s -> i.toString() + s }.collect {\n    println(it) // Will print \"1a 2a 2b 2c\"\n}\n```\n\n### 10. 其他操作符\n- onEach\n在收集每个数据前，可以插入一些操作\n```kotlin\nflowOf(1, 2, 3).onEach { print(it) }.collect { print(it) }\n```\n- onStart\n在收集前加入操作\n```kotlin\nflowOf(1, 2, 3).onStart { emit(0) }.collect { print(it) }\n```\n- onCompletion\n同上，参数是Throwable，如果处理过程中有异常，便通过这个参数传出\n```kotlin\nflowOf(1, 2, 3).onCompletion { print(\"exception:${it?.toString()}\") }.collect { print(it) }\n```","tags":["Android","Kotlin"],"categories":["Kotlin"]},{"title":"Retrofit使用","url":"/2022/05/59844027c896/","content":"\n上篇文章简单说了OkHttp的使用，这篇来说Retrofit。同样，Retrofit也是Square公司出品。\n\n<!--more-->\n\n[Retrofit Github地址](https://github.com/square/retrofit)\n\n### 1. 简介\n在OkHttp的封装下，我们发送网络请求方便了很多，省去了很多重复性的样板代码。而Retrofit的作用，是进一步减少样板代码量，比如发送POST请求时，每次都需要将参数转化成JSON格式，添加到Body中，发送到服务器。接收回应时，每次也是需要先将Response里的Body解析成类，然后从中读取需要的参数。Retrofit通过注解的形式，将这些重复性的工作也省去了。\n\nRetrofit中使用了大量的注解，请求方式、请求参数等均使用注解来标明，记住这些注解，基本就掌握了用法。\n\n### 2. 使用\n是用Retrofit大致分为4个步骤\n- 创建Retrofit实例\nRetrofit支持配置一些选项，比如CallAdapter、Converter等\n- 创建请求API的接口\n这里只需要写接口，而不需要写具体实现，Retrofit使用动态代理的方式，来满足调用者\n- 生成请求API的实例\n通过第一步中生成的Retrofit实例，来生成上一步中接口的实例\n- 通过请求API的实例发送请求\n使用上一步中的实例，就可以发送网络请求了\n\n### 3. 示例\n看了上面的步骤会觉得很抽象，下面举个简单的例子，就会很具体了。比如，通过GET获取用户信息，通过POST更新用户名称。\n\n这是一个用来描述用户的类，只有两个字段，一个是id，一个用户名\n```java\n// 描述用户的信息\npublic class User {\n    public int id;\n    public String name;\n}\n```\n第一步，创建一个Retrofit的实例，\n```java\nRetrofit retrofit = new Retrofit.Builder()\n                        .baseUrl(\"https://useinfo.hostname.com/\")\n                        .build();\n\n// 也可以手动增加一些配置，这里添加了一个Gson的转换器，和一个RxJava的CallAdapter，后面介绍\nRetrofit retrofit = new Retrofit.Builder()\n                        .baseUrl(\"https://useinfo.hostname.com/\")\n                        .addConverterFactory(GsonConverterFactory.create())\n                        .addCallAdapterFactory(RxJavaCallAdapterFactory.create())\n                        .build();\n```\n第二步，创建请求API的接口\n```java\ninterface UserApi {\n\n\t@GET(\"user/{userId}\")\n    Call<UserInfo> getInfo(@Path(\"userId\") int userId);\n\n    @POST(\"user\")\n    Call<String> updateUser(@Body UserInfo user);\n}\n```\n第三步，生成请求API的实例，因为上面的请求API还只是接口，并不能直接用，要先生成实例\n```java\nUserApi api = retrofit.create(UserApi.class);\n```\n最后一步，用实例发送请求\n```java\n// 获取用户信息\nUserInfo user = api.getInfo(1);\n\n// 更改用户名字\nuser.name = \"new Name\";\nString message = api.updateUser(user);\n```\n\n以上，便是一个简单的调用，可以看到的是，确实都是注解堆起来的，所以，下面看看都有哪些注解，每个注解的用法。\n\n### 4. 注解\n注解可以分为3类：网络请求方法类、标记类和网络请求参数类。\n- 网络请求方法\n可以说Retrofit是RESTful风格请求的封装，注解和请求方式一一对应\n```java\n@GET\n@POST\n@PUT\n@DELETE\n@PATCH\n@HEAD\n@OPTIONS\n@HTTP：自定义HTTP请求 @HTTP(method = \"DELETE\", path = \"remove/\", hasBody = true)\n```\n使用这些注解，便可以标明一个方法的网络请求方法，注解接收一个参数，表明请求的路径，就像上面例子中的那样。Retrofit将URL分成了两部分，第一部分是主机地址，在创建Retrofit时配置的baseUrl，另一部分就是每个请求的具体路径，最终的请求URL就是base后面接上请求方法里的路径，后面会单独说这里要注意的地方\n- 标记类\n```java\n@FormUrlEncoded：表明是Form表单，需要和@Field搭配使用，参数使用@Field修饰\n@Multipart：表明body是multi-part，需要和@Part搭配使用，参数使用@Part修饰\n@Streaming：表示数据以流的形式返回，适用于返回数据较大的场景，如果不标记，默认把数据全部载入内存，取数据是从内存取\n```\n这几个注解是用来标记方法的。\n- 网络请求参数\n```java\n@Header：Call<ResponseBody> foo(@Header(\"Accept-Language\") String lang)\n@Headers：与上面不同，这个注解标记方法\n@Url：使用这个注解将忽略baseUrl配置  Call<ResponseBody> list(@Url String url);\n@Body：是用Converter将参数写入到请求body中\n@Path：请求路径的中的参数    @GET(\"/image/{id}\") Call<ResponseBody> example(@Path(\"id\") int id);\n@Field：form表单的参数 @FormUrlEncoded  @POST(\"/\") Call<ResponseBody> example(@Field(\"name\") String name, @Field(\"occupation\") String occupation);\n@FieldMap：同上，多个参数，修饰Map Call<ResponseBody> things(@FieldMap Map<String, String> fields);\n@Part：这个我很少用，看看Retrofit自己的解释\nDenotes a single part of a multi-part request.\nThe parameter type on which this annotation exists will be processed in one of three ways:\nIf the type is okhttp3.MultipartBody.Part the contents will be used directly. Omit the name from the annotation (i.e., @Part MultipartBody.Part part).\nIf the type is RequestBody the value will be used directly with its content type. Supply the part name in the annotation (e.g., @Part(\"foo\") RequestBody foo).\nOther object types will be converted to an appropriate representation by using a converter. Supply the part name in the annotation (e.g., @Part(\"foo\") Image photo).\nValues may be null which will omit them from the request body.\n\n   @Multipart\n   @POST(\"/\")\n   Call<ResponseBody> example(\n       @Part(\"description\") String description,\n       @Part(value = \"image\", encoding = \"8-bit\") RequestBody image);\n   \nPart parameters may not be null.\n@PartMap：同上，修饰Map\n@Query：添加GET请求URL中的参数 例如：user?id=23&name=John  @GET(\"/friends\") Call<ResponseBody> friends(@Query(\"page\") int page);\n@QueryMap：同上，修饰Map\n```\n\n### 5. 请求的最终URL\nRetrofit会根据请求方法注解(@GET, @POST等)里面的路径参数动态生成最终的URL，对于Retrofit的baseUrl配置项，有两种形式，当以斜杠`/`结尾时是目录形式，当以非斜杠结尾时是文件形式，这两种形式是不同的，对于请求方法注解中写的路径，以斜杠`/`开头表示绝对路径和不以斜杠开头表示相对路径，这两种形式也是不同的。\n\n所以在生成最终的请求URL时就会有多种情况：\n- 情况一，请求方法中写的是https/http开头的完整URL，这时Retrofit便会使用配置的baseUrl，而是直接使用请求方法注解里的值，当所有请求都写的完整请求URL，那么这时候可以不配置baseUrl\n- 情况二，路径使用的绝对路径，也就是以斜杠`/`开头，那么这时不管baseUrl是哪种形式，这个路径会直接接到主机和端口后，形成最终的URL\n```java\nbaseUrl = \"https://host:port/a/b\"\npath = \"/user\"\nURL = \"https://host:port/user\"\n```\n- 情况三，路径是相对路径，baseUrl是目录形式，那么这时候会直接拼接，形成最终URL\n```java\nbaseUrl = \"https://host:port/a/\" // 这里是斜杠结尾，是目录形式\npath = \"user\"\nURL = \"https://host:prot/a/user\"\n```\n- 情况四，路径是相对路径，但baseUrl是文件形式，那么这时候路径会接到最后一个文件后，形成最终URL。可以这么理解，因为文件下不能有文件，目录下才能有文件，所以user不能接在a的后面。\n```java\nbaseUrl = \"https://host:port/a\" // 注意这里没有斜杠结尾，所以是文件形式\npath = \"user\"\nURL = \"https://host:port/user\"\n```\n\n按照RESTful的风格来说，一般常用的是，baseUrl是用目录形式，也就是以斜杠`/`结尾，路径使用相对路径。\n\n### 6. CallAdapter\nCallAdapter和Converter是Retrofit中最精妙的设计了，这就好比OkHttp中的责任链，所以，接下来分别看看这两个。\n\n先看CallAdapter，那么它是在适配什么呢？顾名思义，请求适配器，在适配请求的返回值类型。先看下这两个请求：\n```java\nCall<User> getUser();\n\nResponse<User> getUser();\n```\n都是网络请求，但是返回类型不同，一个是Call，一个是Response，这两种形式Retrofit都是支持的，那么它是怎么做到的呢？没错，就是通过CallAdapter，每个返回类型，都有一个对应的CallAdapter，来将服务器返回的数据转换的成目标类型。目前支持的有Guava、Java8、RxJava，也可以自定义，在创建Retrofit实例时添加进去，即可。上面的例子中便是添加了一个RxJava的CallAdapter，可以直接将结果转换成Observers，可以方便的进行链式调用。\n\n说完它的作用，那么就要看看Retrofit是如何实现的了。\n\n我们写的是请求API接口，并没有具体的实现，调用Retrofit的create(Class)方法时，它实际上生成并返回了一个动态代理，我们调用API实例的方法时，真实调用的代理里的invoke方法\n```java\n  public <T> T create(final Class<T> service) {\n    validateServiceInterface(service);\n    return (T)\n        Proxy.newProxyInstance(service.getClassLoader(), new Class<?>[] {service},\n            new InvocationHandler() {\n              private final Platform platform = Platform.get();\n              private final Object[] emptyArgs = new Object[0];\n\n              @Override\n              public @Nullable Object invoke(Object proxy, Method method, @Nullable Object[] args)\n                  throws Throwable {\n                // If the method is a method from Object then defer to normal invocation.\n                if (method.getDeclaringClass() == Object.class) {\n                  return method.invoke(this, args);\n                }\n                args = args != null ? args : emptyArgs;\n                return platform.isDefaultMethod(method) ? platform.invokeDefaultMethod(method, service, proxy, args) : loadServiceMethod(method).invoke(args);\n              }\n            });\n  }\n```\ninvoke方法很短，就这么几行，看过`platform.isDefaultMethod(method)`这个方法就知道，如果接口里的方法有默认实现，返回true，否则返回false，这是Java8才开始支持的，之前版本接口方法是不允许有方法体的。我们声明的API接口没有方法体，所有最终都会调用\n```java\nloadServiceMethod(method).invoke(args)\n```\n所以，只需要看这个方法是如何处理返回值，就知道Retrofit是怎么使用CallAdapter的了。\n\n```java\n  ServiceMethod<?> loadServiceMethod(Method method) {\n    ServiceMethod<?> result = serviceMethodCache.get(method);\n    if (result != null) return result;\n\n    synchronized (serviceMethodCache) {\n      result = serviceMethodCache.get(method);\n      if (result == null) {\n        result = ServiceMethod.parseAnnotations(this, method);\n        serviceMethodCache.put(method, result);\n      }\n    }\n    return result;\n  }\n```\nRetrofit将接口里的方法，抽象成了一个ServiceMethod类型，这里是做了一个缓存，为接口里的每个方法生成一个ServiceMethod实例，且只生成一个实例，节约资源提高性能。获取到ServiceMethod后，就会调用它的invoke方法，invoke是个抽象方法，它只有在HttpServiceMethod中有实现，而invoke中又调用了另一个抽象方法adopt，adapt里调用的是callAdapter的adapt方法。\n\n总的来说就是，invoke方法调用的是callAdapter的adapt方法，而callAdapter是在构造函数的时候传进去的，意思就是说，在构造好ServiceMethod实例的时候，它所使用的CallAdapter就确定了。那么，看看在构造的时候如何选取的CallAdapter，看上面的代码就知道，ServiceMethod是通过静态方法parseAnnotations创建的，这个方法里又调用了HttpServiceMethod的parseAnnotations方法，也就是说，最终创建的ServiceMethod的是HttpServiceMethod的parseAnnotations方法。\n\n来看HttpServiceMethod的parseAnnotations，这个方法中的CallAdapter，是通过这个方法创建的\n```java\n  private static <ResponseT, ReturnT> CallAdapter<ResponseT, ReturnT> createCallAdapter(\n      Retrofit retrofit, Method method, Type returnType, Annotation[] annotations) {\n    try {\n      //noinspection unchecked\n      return (CallAdapter<ResponseT, ReturnT>) retrofit.callAdapter(returnType, annotations);\n    } catch (RuntimeException e) { // Wide exception range because factories are user code.\n      throw methodError(method, e, \"Unable to create call adapter for %s\", returnType);\n    }\n  }\n```\n也就是调用了retrofit的callAdapter方法，retrofit中最终创建CallAdapter的方法是这个\n```java\n  public CallAdapter<?, ?> nextCallAdapter(\n      @Nullable CallAdapter.Factory skipPast, Type returnType, Annotation[] annotations) {\n    int start = callAdapterFactories.indexOf(skipPast) + 1;\n    for (int i = start, count = callAdapterFactories.size(); i < count; i++) {\n      CallAdapter<?, ?> adapter = callAdapterFactories.get(i).get(returnType, annotations, this);\n      if (adapter != null) {\n        return adapter;\n      }\n    }\n\n    ...\n    throw new IllegalArgumentException(builder.toString());\n  }\n```\n看到了吧，这里Retrofit就是在遍历自己的CallAdapterFactory，然后调用get方法，将返回值类型returnType和annotations传入，如果返回不为空，则返回。CallAdapterFactory的这个get方法的作用是，如果对应的CallAdapter能把数据转化成returnType类型，那么就生成出一个CallAdapter出来，如果不能则返回null，如果Retrofit中所带的CallAdapter没有一个符合条件的，那么就会来到最后一行，抛出一个Exception。\n\n如果我们在创建Retrofit时，不手动添加CallAdapter，它也能用，是因为Retrofit里有个缺省的CallAdapter，叫DefaultCallAdapterFactory\n```java\nfinal class DefaultCallAdapterFactory extends CallAdapter.Factory {\n  private final @Nullable Executor callbackExecutor;\n\n  DefaultCallAdapterFactory(@Nullable Executor callbackExecutor) {\n    this.callbackExecutor = callbackExecutor;\n  }\n\n  @Override\n  public @Nullable CallAdapter<?, ?> get(Type returnType, Annotation[] annotations, Retrofit retrofit) {\n    if (getRawType(returnType) != Call.class) { return null; }\n\n    if (!(returnType instanceof ParameterizedType)) {\n      throw new IllegalArgumentException(\"Call return type must be parameterized as Call<Foo> or Call<? extends Foo>\");\n    }\n    final Type responseType = Utils.getParameterUpperBound(0, (ParameterizedType) returnType);\n\n    final Executor executor = Utils.isAnnotationPresent(annotations, SkipCallbackExecutor.class) ? null : callbackExecutor;\n\n    return new CallAdapter<Object, Call<?>>() {\n      @Override\n      public Type responseType() { return responseType; }\n\n      @Override\n      public Call<Object> adapt(Call<Object> call) { return executor == null ? call : new ExecutorCallbackCall<>(executor, call); }\n    };\n  }\n}\n```\n方法里第一行是这么写的\n```java\nif (getRawType(returnType) != Call.class) { return null; }\n```\n意思就是，如果returnType不是Call，那么就返回null，换句话说，这个CallAdapter只能处理`Call<T>`类型的方法，也就是我们常写的那种，responseType是Call的范型T，方法最后直接new了一个CallAdapter返回了，在adapt方法中，因为Call就是最基本的形式，需要的也是Call类型，所以不需要额外的处理，就直接返回了，ExecutorCallbackCall是切换线程的，就不多说了。\n\n总结一下就是，Retrofit里保存了自带的和我们手动添加的所有CallAdapterFactory，我们调用API实例的方法时，实际上是在调用动态代理的invoke方法，这方法里为每个API接口方法生成了一个ServiceMethod，在生成ServiceMethod时会从Retrofit的CallAdapterFactory中查找，看是否有CallAdapter可以将Call转换成目标类型，有则使用，无则抛异常。这样，在我们调用API实例的方法时，就可以得到结果了。\n\n如果需要自定义CallAdapter，则需要实现CallAdapterFactory和CallAdapter。\n\n### 7. Converter\n说完CallAdapter，再来看看Converter，说实话，我都有点敲累了，本着一鼓作气的精神，还是坚持敲完吧。\n\n有了上面的经验，这个就容易一些了。同样，Retrofit中也是保存了所有的ConverterFactory，所有需要Converter的地方，都是从这里提供的。ConvertFactory是提供Converter的工厂，它里面主要有3个方法，也就是可以提供三个维度的Converter\n```java\npublic interface Converter<F, T> {\n  @Nullable\n  T convert(F value) throws IOException;\n\n  /** Creates {@link Converter} instances based on a type and target usage. */\n  abstract class Factory {\n    /**\n     * Returns a {@link Converter} for converting an HTTP response body to {@code type}, or null if\n     * {@code type} cannot be handled by this factory. This is used to create converters for\n     * response types such as {@code SimpleResponse} from a {@code Call<SimpleResponse>}\n     * declaration.\n     */\n    public @Nullable Converter<ResponseBody, ?> responseBodyConverter(\n        Type type, Annotation[] annotations, Retrofit retrofit) {\n      return null;\n    }\n\n    /**\n     * Returns a {@link Converter} for converting {@code type} to an HTTP request body, or null if\n     * {@code type} cannot be handled by this factory. This is used to create converters for types\n     * specified by {@link Body @Body}, {@link Part @Part}, and {@link PartMap @PartMap} values.\n     */\n    public @Nullable Converter<?, RequestBody> requestBodyConverter(\n        Type type,\n        Annotation[] parameterAnnotations,\n        Annotation[] methodAnnotations,\n        Retrofit retrofit) {\n      return null;\n    }\n\n    /**\n     * Returns a {@link Converter} for converting {@code type} to a {@link String}, or null if\n     * {@code type} cannot be handled by this factory. This is used to create converters for types\n     * specified by {@link Field @Field}, {@link FieldMap @FieldMap} values, {@link Header @Header},\n     * {@link HeaderMap @HeaderMap}, {@link Path @Path}, {@link Query @Query}, and {@link\n     * QueryMap @QueryMap} values.\n     */\n    public @Nullable Converter<?, String> stringConverter(\n        Type type, Annotation[] annotations, Retrofit retrofit) {\n      return null;\n    }\n\n  }\n}\n```\n这三个维度分别是requestBodyConverter、responseBodyConverter和stringConverter。\n\n下面我们来看看发起请求过程中的一些细节。\n\n我们在声明请求时用注解标记了很多信息，比如请求Method，请求Path，这些最终都需要转换成网络请求认识的形式才可以，转化注解这件事，是在RequestFactory中做的，而RequestFactory是在ServiceMethod创建时一起创建的\n```java\n// ServiceMethod.parseAnnotations(this, method);\nstatic <T> ServiceMethod<T> parseAnnotations(Retrofit retrofit, Method method) {\n    RequestFactory requestFactory = RequestFactory.parseAnnotations(retrofit, method);\n    ...\n}\n```\nRequestFactory通过静态方法创建了实例，在创建时，对所有注解进行了解析，在这个解析过程中，便是使用了Retrofit的ConverterFactory的stringConvterer和requestBodyConverter，解析参数时用stringConverter，解析RequestBody时用requestBodyConverter。\n\nConverter的获取方式和CallAdapter类似，同样是传入一个类型，如果能转化，则返回一个Converter，不能就返回null，解析Body时，多是将起转化成JSON格式\n```java\n  public <T> Converter<T, RequestBody> nextRequestBodyConverter(@Nullable Converter.Factory skipPast, Type type, Annotation[] parameterAnnotations, Annotation[] methodAnnotations) {\n\n    int start = converterFactories.indexOf(skipPast) + 1;\n    for (int i = start, count = converterFactories.size(); i < count; i++) {\n      Converter.Factory factory = converterFactories.get(i);\n      Converter<?, RequestBody> converter = factory.requestBodyConverter(type, parameterAnnotations, methodAnnotations, this);\n      if (converter != null) {\n        //noinspection unchecked\n        return (Converter<T, RequestBody>) converter;\n      }\n    }\n\n    ...\n    throw new IllegalArgumentException(builder.toString());\n  }\n```\n生成ServiceMethod后，便会调用其invoke方法，这个方法会将请求包装成一个叫做OkHttpCall的类型\n```java\n// HttpServiceMethod.java\n  final @Nullable ReturnT invoke(Object[] args) {\n    Call<ResponseT> call = new OkHttpCall<>(requestFactory, args, callFactory, responseConverter);\n    return adapt(call, args);\n  }\n```\n将刚刚生成的requestFactory作为参数传了进去，同时还传入了responseConveter，用来解析服务器返回的数据，同样，responseConverter也是由Retrofit提供，如果有能处理type的Converter，则返回，无则返回null\n```java\n  public <T> Converter<ResponseBody, T> nextResponseBodyConverter(@Nullable Converter.Factory skipPast, Type type, Annotation[] annotations) {\n    int start = converterFactories.indexOf(skipPast) + 1;\n    for (int i = start, count = converterFactories.size(); i < count; i++) {\n      Converter<ResponseBody, ?> converter = converterFactories.get(i).responseBodyConverter(type, annotations, this);\n      if (converter != null) {\n        //noinspection unchecked\n        return (Converter<ResponseBody, T>) converter;\n      }\n    }\n\n    ...\n    throw new IllegalArgumentException(builder.toString());\n  }\n```\n\n再来看看GsonConverterFactory的实现\n```java\npublic final class GsonConverterFactory extends Converter.Factory {\n\n  public static GsonConverterFactory create() {\n    return create(new Gson());\n  }\n\n  public static GsonConverterFactory create(Gson gson) {\n    if (gson == null) throw new NullPointerException(\"gson == null\");\n    return new GsonConverterFactory(gson);\n  }\n\n  private final Gson gson;\n\n  private GsonConverterFactory(Gson gson) {\n    this.gson = gson;\n  }\n\n  @Override\n  public Converter<ResponseBody, ?> responseBodyConverter(Type type, Annotation[] annotations, Retrofit retrofit) {\n    TypeAdapter<?> adapter = gson.getAdapter(TypeToken.get(type));\n    return new GsonResponseBodyConverter<>(gson, adapter);\n  }\n\n  @Override\n  public Converter<?, RequestBody> requestBodyConverter(Type type, Annotation[] parameterAnnotations, Annotation[] methodAnnotations, Retrofit retrofit) {\n    TypeAdapter<?> adapter = gson.getAdapter(TypeToken.get(type));\n    return new GsonRequestBodyConverter<>(gson, adapter);\n  }\n}\n```\n可以看到，它只重写了两个维度，requestBody和responseBody的Converter，GsonResponseBodyConverter的作用是把JSON串转化成对象，而GsonRequestBodyConverter的作用是把对象转化成JSON串\n```java\n// GsonRequestBodyConverter.java\n  public RequestBody convert(T value) throws IOException {\n    Buffer buffer = new Buffer();\n    Writer writer = new OutputStreamWriter(buffer.outputStream(), UTF_8);\n    JsonWriter jsonWriter = gson.newJsonWriter(writer);\n    adapter.write(jsonWriter, value);\n    jsonWriter.close();\n    return RequestBody.create(MEDIA_TYPE, buffer.readByteString());\n  }\n\n// GsonResponseBodyConverter.java\n  public T convert(ResponseBody value) throws IOException {\n    JsonReader jsonReader = gson.newJsonReader(value.charStream());\n    try {\n      T result = adapter.read(jsonReader);\n      if (jsonReader.peek() != JsonToken.END_DOCUMENT) {\n        throw new JsonIOException(\"JSON document was not fully consumed.\");\n      }\n      return result;\n    } finally {\n      value.close();\n    }\n  }\n```\n\n同样，若自定义Converter，实现Converter.Factory和Converter，即可。\n\n### 8. 写在最后\n直观来看，依赖框架帮助我们省去了不少重复性的工作。但是，省去不等于是不做。从宏观角度来看，发送一个网络请求的需要做的事情有构建请求，连接服务器，发送请求，接收回应。这些必须的步骤，每次请求都是必不可缺的，这里的省去只是简化了我们的工作，但这些事并没有省去，只是这些依赖库在背后用复杂的逻辑默默的帮我们在做。从这个角度看，依赖库确实可以提升开发效率，但也不能过分依赖，框架背后的不少内容，还是需要我们熟知的，就像是网络请求，如果只知道通过这些框架发送请求、处理回应，那么在遇到一些涉及基础知识的问题时，可以就会有些不知所措。","tags":["Android","Retrofit"],"categories":["Android"]},{"title":"OkHttp使用","url":"/2022/05/bd9c9a5395ee/","content":"说到网络请求框架，OkHttp应该是当下较为流行的了，原因就在于它简单易用，且高效。同样，也是Square公司的作品。\n\n<!--more-->\n### 1. 引入\n[库地址](https://github.com/square/okhttp)\n添加依赖时，在app的build.gradle加一个库即可\n```groovy\nimplementation(\"com.squareup.okhttp3:okhttp:4.9.3\")\n```\n\n### 2. 使用\n使用OkHttp发送网络请求，一般分为5个步骤\n- 生成OkHttpClient\nClient可以配置一些和连接相关的参数，比如连接timeout、读timeout、写timeout、连接池的配置、添加拦截器，等等\n- 生成Request\nRequest可以设定和请求相关的参数，如请求的URL、请求方式、请求头、请求的body\n- 生成Call\n一个Call，即为一个网络请求，这一步需要上面的Client和Request\n- 发送Call\n将请求发出，这里有两种方式，一种是同步发送，会阻塞线程，等待数据返回；另一种是异步发送，在回调里处理返回的数据\n- 等待Call返回Response\nResponse即为服务器返回的数据，包含Header，和Body\n```java\nOkHttpClient client = new OkHttpClient();\nRequest requst = new Request.Builder().url(\"\").get().build();\nCall call = client.newCall(request);\nResponse response = call.execute(); // 同步\ncall.enqueue(callback); // 异步\n\nString message = response.body().string();\n```\n其中，Client也可以定制化，和Request类似，也是使用构建者模式\n```java\nOkHttpClient client = new OkHttpClient.Builder()\n                          .connectTimeout(60, TimeUnit.SECONDS)\n                          .readTimeout(60, TimeUnit.SECONDS)\n                          .writeTime(60, TimeUnit.SECONDS)\n                          .connectionPool(new ConnectionPool(30, 30, TimeUnit.MINUTES))\n                          .build();\n```\n\n### 3. 责任链\n责任链是OkHttp中最巧妙的设计了。链上的每个元素，抽象成了一个拦截器Interceptor，每个拦截器都可以处理Request和Response。这种设计的好处就是，将处理者和请求者解耦，缺点就是，每次发起请求需要对链上的拦截者遍历，当拦截者过多时会影响性能。\n\n什么意思呢，简单说就是，每次发起网络请求，Request会经过责任链上的每一个拦截器，最终到达服务器，同样，服务器返回的Response也会经过链上的每一个拦截器，最终回到请求者。比如，你想给每个请求都加上一个包含鉴权的Header，那么只需要向责任链中插入一个拦截器，这样就可以触碰到所有的Request和Response，不需要操作Response，而只需要向Resquest的Header中增加一对Key-Value即可，这种模式下，不需要关心谁发起的请求，也不需要关心谁将会处理请求，只需要插入一个拦截器Interceptor即可。\n\n这里面有两个角色，一个是链，一个是拦截器。\n\n先说拦截器。拦截器本身是拿不到任何东西的，它只有插入到责任链上之后，才能操作Request和Response，所以，它的Request是链提供给它的，同时，它还要返回一个Response，才能保证责任链能完整的流通，不然其中某个拦截器，在拿到Request后，不返回Response，那么，请求到这里就断掉了。一个链上可以有多个拦截器，Interceptor是个接口，其中只有一个interceptor方法，自定义的拦截器需要实现这个方法，Chain提供了多个方法，来提供和请求相关的参数，比如连接timeout、读写timeout，当然，还包括Request\n```java\npublic interface Interceptor {\n  Response intercept(Chain chain) throws IOException;\n}\n\npublic class HeaderInterceptor implements Interceptor {\n\tResponse intercept(Chain chain) throws IOException {\n\t\t// 通过request方法获得Request\n        Request request = chain.request();\n        // do something with request\n        ...\n\n        // 通过proceed方法得到Resposne\n        Response response = chain.proceed(request);\n        // do something with resposne\n        ...\n\n        // 最终将response返回给链\n        return response;\n\t}\n}\n\n// 将拦截器插入到链中\nOkHttpClient client = new OkHttpClient.Builder()\n                          .addInterceptor(new HeaderInterceptor())\n                          .build();\n```\n\n看完拦截器，再来看看另外一个角色，链。Chain也是一个接口，它只有一个实现类，RealInterceptorChain，看看request方法是如何获取到Request，proceed方法又是如何获取到Response的。\n```java\n  @Override public Request request() {\n    return request;\n  }\n```\nrequest方法很简单，就是直接返回的成员变量request，而这个变量是在构造方法里面传入的，就没什么可多说的了。那就再看看proceed方法，\n```java\n  public Response proceed(Request request, Transmitter transmitter, @Nullable Exchange exchange)\n      throws IOException {\n    if (index >= interceptors.size()) throw new AssertionError();\n\n    calls++;\n\n    // If we already have a stream, confirm that the incoming request will use it.\n    if (this.exchange != null && !this.exchange.connection().supportsUrl(request.url())) {\n      throw new IllegalStateException(\"network interceptor \" + interceptors.get(index - 1)\n          + \" must retain the same host and port\");\n    }\n\n    // If we already have a stream, confirm that this is the only call to chain.proceed().\n    if (this.exchange != null && calls > 1) {\n      throw new IllegalStateException(\"network interceptor \" + interceptors.get(index - 1)\n          + \" must call proceed() exactly once\");\n    }\n\n    // Call the next interceptor in the chain.\n    RealInterceptorChain next = new RealInterceptorChain(interceptors, transmitter, exchange,\n        index + 1, request, call, connectTimeout, readTimeout, writeTimeout);\n    Interceptor interceptor = interceptors.get(index);\n    Response response = interceptor.intercept(next);\n\n    // Confirm that the next interceptor made its required call to chain.proceed().\n    if (exchange != null && index + 1 < interceptors.size() && next.calls != 1) {\n      throw new IllegalStateException(\"network interceptor \" + interceptor\n          + \" must call proceed() exactly once\");\n    }\n\n    // Confirm that the intercepted response isn't null.\n    if (response == null) {\n      throw new NullPointerException(\"interceptor \" + interceptor + \" returned null\");\n    }\n\n    if (response.body() == null) {\n      throw new IllegalStateException(\n          \"interceptor \" + interceptor + \" returned a response with no body\");\n    }\n\n    return response;\n  }\n```\n里面做了一些检查和判断，关键的就是中间的创建next变量。next的类型还是RealInterceptorChain，构造方法中第一个参数就是所有的拦截器，还有个index参数，表明这个next用的是第几个拦截器，换句话说就是，每个拦截器都对应一个RealInterceptorChain类型的变量。初始化next，又获取到了拦截器，通过interceptor.intercept(next)来获取response，来返回给上面的chain.proceed(request)。\n\n可能有点乱，来捋一捋。一个拦截器想要获取Request很简单，Chain的构造方法里便有。一拦截器想要获取Response时，Chain就会获取到链中的下一个拦截器，通过调用它的intercept方法来获取Response，进入到下一个拦截器的intercept方法中时，它的Response又要通过Chain获取下下一个拦截器，跟它要Response。形象点来说就是，A想要操作Response，它就会带着Request和B要Response，B又会带着Request和C要Response，C又会和D要，就这么一直在链上传递下去。那么大家都这么踢皮球一样踢来踢去，真正的Response从何而来呢？从要有个兜底的吧？没错，真有一个兜底的，它就是链上的最后一个拦截器，CallServerInterceptor。\n\n所以，还要再看看发送请求前，都给链上添加了那些拦截器。\n\n上面说过，发送网路请求时，最终会生成一个Call，然后将其发出，而Call是一个接口，它只有一个实现类，叫做RealCall，不管是调用的Call的同步方法execute还是异步方法enqueue，最终都会来到RealCall里的getResponseWithInterceptorChain方法，完整内容如下，\n```java\nResponse getResponseWithInterceptorChain() throws IOException {\n    // Build a full stack of interceptors.\n    List<Interceptor> interceptors = new ArrayList<>();\n    interceptors.addAll(client.interceptors());\n    interceptors.add(new RetryAndFollowUpInterceptor(client));\n    interceptors.add(new BridgeInterceptor(client.cookieJar()));\n    interceptors.add(new CacheInterceptor(client.internalCache()));\n    interceptors.add(new ConnectInterceptor(client));\n    if (!forWebSocket) {\n      interceptors.addAll(client.networkInterceptors());\n    }\n    interceptors.add(new CallServerInterceptor(forWebSocket));\n\n    Interceptor.Chain chain = new RealInterceptorChain(interceptors, transmitter, null, 0,\n        originalRequest, this, client.connectTimeoutMillis(),\n        client.readTimeoutMillis(), client.writeTimeoutMillis());\n\n    boolean calledNoMoreExchanges = false;\n    try {\n      Response response = chain.proceed(originalRequest);\n      if (transmitter.isCanceled()) {\n        closeQuietly(response);\n        throw new IOException(\"Canceled\");\n      }\n      return response;\n    } catch (IOException e) {\n      calledNoMoreExchanges = true;\n      throw transmitter.noMoreExchanges(e);\n    } finally {\n      if (!calledNoMoreExchanges) {\n        transmitter.noMoreExchanges(null);\n      }\n    }\n}\n```\n可以看到，发送请求前，除了添加我们给Client添加的拦截器，OkHttp还添加了一些自己的拦截器，用来对Request和Response做一些处理。最后一个拦截器，便是CallServerInterceptor\n```java\n// This is the last interceptor in the chain. It makes a network call to the server.\npublic final class CallServerInterceptor implements Interceptor {\n      @Override public Response intercept(Chain chain) throws IOException {\n          // 构建Request\n      \t  // 发送Request\n      \t  // 生成Response\n      \t  // 返回response\n      \t  return repsonse;\n      }\n}\n```\n它的类说明里，写的是链中的最后一个拦截器。所以她没办法再踢皮球，和别人要Response。它的intercept方法里，将上游传来的request发送出去，然后等服务器返回，将数据封装成Response，再度返回给链上游。\n\n总结来看就是，每个拦截器中，想要操作Response，需要将自己处理过的Request传给链下游，下游接着往下传递，直到到达链末端的CallServerInterceptor，它向服务器发送请求，接收服务器的响应，然后再将Response回传给链上游，直到到达请求发送者，这个请求算作结束。\n","tags":["Android","OkHttp"],"categories":["Android"]},{"title":"Kotlin之属性代理","url":"/2022/05/540209f94fc3/","content":"\n属性代理是Kotlin独有的功能。\n<!--more-->\n\n### 1. 简介\n属性代理是借助Kotlin中代理设计模式，把这个模式应用于一个属性时，它可以将属性访问器的逻辑代理给一个对象。即，将setter和getter的实现，都交给一个对象来实现，这个对象需要实现getValue和setValue方法，既可以是普通方法，也可以是扩展方法。使用属性时，依然照常使用，只是访问器会调用扶助对象的setValue和getValue。\n```kotlin\nclass Foo {\n    var name: String by NameDelegate()\n}\n\nclass NameDelegate {\n    operator fun <T> getValue(thisRef: Any?, property: KProperty<*>): T {}\n    operator fun <T> setValue(thisRef: Any?, property: KPproperty<*>, value: T) {}\n}\n```\n上面便是属性代理的定义形式。另外，Kotlin还提供了几个常见的属性代理\n```kotlin\nDelegates.notNull()\nDelegates.observable()\nDelegates.vetoable()\n\n```\n\n### 2. 几个结构\n在介绍Kotlin提供的代理之前，先要说2个它的接口，很好理解\n- ReadOnlyProperty，只读属性，只有getValue方法\n```kotlin\npublic fun interface ReadOnlyProperty<in T, out V> {\n    public operator fun getValue(thisRef: T, property: KProperty<*>): V\n}\n```\n- ReadWriteProperty，可读写属性，既有getValue方法，也有setValue方法\n```kotlin\npublic interface ReadWriteProperty<in T, V> : ReadOnlyProperty<T, V> {\n    public override operator fun getValue(thisRef: T, property: KProperty<*>): V\n    public operator fun setValue(thisRef: T, property: KProperty<*>, value: V)\n}\n```\n\n### 3. Delegates.notNull()\nnotNull是一个方法，返回的就是一个带有getValue和setValue方法的对象，其中主要代码如下\n```kotlin\nprivate class NotNullVar<T : Any>() : ReadWriteProperty<Any?, T> {\n    private var value: T? = null\n\n    public override fun getValue(thisRef: Any?, property: KProperty<*>): T {\n        return value ?: throw IllegalStateException(\"Property ${property.name} should be initialized before get.\")\n    }\n\n    public override fun setValue(thisRef: Any?, property: KProperty<*>, value: T) {\n        this.value = value\n    }\n}\n```\n可以看到，NotNullVal实现了可读写属性的接口，setValue没有变，只是赋值给成员变量，而getValue加了空判断。在非空问题上，Kotlin还提供了一个lateinit关键字，但是这个关键字只能用来修饰引用类型的变量，而notNull适用于基础数据类型和引用类型。\n\n### 4. Delegates.observable()\n```kotlin\npublic abstract class ObservableProperty<V>(initialValue: V) : ReadWriteProperty<Any?, V> {\n    private var value = initialValue\n    protected open fun beforeChange(property: KProperty<*>, oldValue: V, newValue: V): Boolean = true\n    protected open fun afterChange(property: KProperty<*>, oldValue: V, newValue: V): Unit {}\n\n    public override fun getValue(thisRef: Any?, property: KProperty<*>): V { return value }\n\n    public override fun setValue(thisRef: Any?, property: KProperty<*>, value: V) {\n        val oldValue = this.value\n        if (!beforeChange(property, oldValue, value)) { return }\n        this.value = value\n        afterChange(property, oldValue, value)\n    }\n}\n\npublic inline fun <T> observable(initialValue: T, crossinline onChange: (property: KProperty<*>, oldValue: T, newValue: T) -> Unit):\n        ReadWriteProperty<Any?, T> =\n    object : ObservableProperty<T>(initialValue) {\n        override fun afterChange(property: KProperty<*>, oldValue: T, newValue: T) = onChange(property, oldValue, newValue)\n    }\n```\nObservableProperty，也是实现了可读写的接口，相比于可读写属性，多了两个方法，一个是beforeChange，一个是afterChange，若beforeChange返回值为false，那么此次set无效，返回true时方可生效，而afterChange则是在set成功后调用，beforeChange默认返回时true。\n\n可以看到，observable提供了一个类型为ObservableProperty的对象，并重写了afterChange方法，交给了传入的onChange处理。也就是说，每次set完成后，都会调用传入onChange发出通知。\n\n### 5. Delegates.vetoable()\n```kotlin\npublic inline fun <T> vetoable(initialValue: T, crossinline onChange: (property: KProperty<*>, oldValue: T, newValue: T) -> Boolean):\n          ReadWriteProperty<Any?, T> =\n      object : ObservableProperty<T>(initialValue) {\n          override fun beforeChange(property: KProperty<*>, oldValue: T, newValue: T): Boolean = onChange(property, oldValue, newValue)\n      }\n```\n看过上看的说明，这个就很容易理解了，重写了beforeChange，用传入的函数的返回值来决定本次set是否生效。\n\n### 6. 原理\n咋一看上去这种写法很高级，让咱们来编译成Java代码，看看这层层面纱之下，藏着的到底是什么。\n```kotlin\nclass Teacher {\n    var name: String by Delegates.notNull()\n    var age: Int by Delegates.notNull()\n}\n```\n编译成java之后的代码\n```java\npublic final class Teacher {\n   // $FF: synthetic field\n   static final KProperty[] $$delegatedProperties = new KProperty[]{(KProperty)Reflection.mutableProperty1(new MutablePropertyReference1Impl(Reflection.getOrCreateKotlinClass(Teacher.class), \"name\", \"getName()Ljava/lang/String;\")), (KProperty)Reflection.mutableProperty1(new MutablePropertyReference1Impl(Reflection.getOrCreateKotlinClass(Teacher.class), \"age\", \"getAge()I\"))};\n\n   @NotNull\n   private final ReadWriteProperty name$delegate;\n   @NotNull\n   private final ReadWriteProperty age$delegate;\n\n   @NotNull\n   public final String getName() {\n      return (String)this.name$delegate.getValue(this, $$delegatedProperties[0]);\n   }\n\n   public final void setName(@NotNull String var1) {\n      Intrinsics.checkParameterIsNotNull(var1, \"<set-?>\");\n      this.name$delegate.setValue(this, $$delegatedProperties[0], var1);\n   }\n\n   public final int getAge() {\n      return ((Number)this.age$delegate.getValue(this, $$delegatedProperties[1])).intValue();\n   }\n\n   public final void setAge(int var1) {\n      this.age$delegate.setValue(this, $$delegatedProperties[1], var1);\n   }\n\n   public Teacher() {\n      this.name$delegate = Delegates.INSTANCE.notNull();\n      this.age$delegate = Delegates.INSTANCE.notNull();\n   }\n}\n```\n分析\n- 不管是代理的setValue还是getValue，其中都有一个KProperty类型的参数，所以每个属性都需要一个对应的KProperty对象\n- 除了KProperty，每个属性，都需要一个代理对象，这里是ReadWriteProperty\n- 每个属性，都有一个setter，和一个getter\n- setter中，调用代理对象的setValue方法\n- getter中，调用代理对象的getValue方法\n\n### 总结\n我的感觉，如果能直接以最终编译后Java代码来看属性代理，它反倒是增加了不少代码，如果需要什么额外的操作，完全可以直接写在属性的setter或者getter里。语法糖的好处就是，可以写一个notNull的类型，然后在所有不为空的地方使用，可以不用在每一个地方都加上判断代码，提升了效率。","tags":["Android","Kotlin"],"categories":["Android"]},{"title":"LeakCanary分析","url":"/2022/04/3a7955f632aa/","content":"\nLeakCanary主要用在Android中分析内存泄漏。何为内存泄漏？简单说便是，当一个对象所占用堆存储空间该被系统GC回收时，却由于种种原因没有被回收，那么这些内存就称为泄漏的内存。举个例子，退出一个Activity时，这时这个Activity该被回收，但是因为Activity内声明的Thread还在跑，Thread持有Activity的引用，导致Activity无法被回收，这时就造成了内存泄漏。\n\n<!--more-->\n\nLeakCanary是Square公司出品，这是家做移动支付的公司，但对于开发者来说，这就是家开源库公司，因为不少当下较为流行的三方库，都是出自Square，比如OkHttp，Retrofit，Picasso，这几个较为常用。\n\n### 1. 使用\n- [Github库地址](https://github.com/square/leakcanary)\n- [文档地址](https://square.github.io/leakcanary/)\n接入十分简单，在build.gradle中，加入下面的依赖，即可\n```groovy\ndependencies {\n  // debugImplementation because LeakCanary should only run in debug builds.\n  debugImplementation 'com.squareup.leakcanary:leakcanary-android:2.9.1'\n}\n```\n\n### 2. 工作步骤\n当LeakCanary被安装后，它会自动检测，并报告应用中的内存泄漏，分为4个步骤：\n1. 检测存活的对象\n2. 输出堆信息\n3. 分析堆信息\n4. 将泄漏分类\n\n### 2.1 检测存活对象\nLeakCanary注册了Android生命周期的检测，会自动检测执行过onDestroy方法的Activity和Fragment，这些都应该被GC回收。ObjectWatcher会持有这些对象的弱引用，LeakCanary会检测下面这些对象\n- 被销毁的Activity实例\n- 被销毁的Fragment实例\n- 被销毁的Fragment View实例\n- 被清理的ViewModel实例\n如果被ObjectWatcher持有的对象，在5秒后依然没有被清理，那么就会执行GC，之后，若被持有object依然存在没有被回收，那么就有可能泄漏了。\n\n### 2.2 输出堆信息\n当存活的对象到达阈值的时候，LeakCanary就会将Java堆信息输出到一个.hprof文件中，这个操作可能会卡住应用一小段时间，会有Toast给出提示。\n\n### 2.3 分析堆信息\n> Shark: Smart Heap Analytisis Reports for Kotlin，是一个分析堆信息的工具\nLeakCanary使用Shark来分析hprof文件，并定位存活对象在堆信息中的位置。对于每一个存活的对象，LeakCanary都会找到阻止这个对象被系统GC回收的引用路径。当分析完成时，会有一个包含汇总信息的通知提示，点开便可查看详细信息。\n\n### 2.4 泄漏分类\nLeakCanary将她从应用中发现的泄漏分为两类，一类是应用自身的泄漏，一类是依赖库的泄漏。依赖库泄漏是三方库中已知的bug导致，我们无法控制。这个泄漏对我们应用产生了影响，但不幸的是，我们无法修复。\n\n### 3. 总结\nLeakCanary关键部分，就是如何检测泄漏对象：通过注册回调监听Activity和Fragment的生命周期，在其destroy之后，创建WeakReference，然后就是等待5秒，理想状态下这个时间内会被GC回收，如果5秒还存活，那么就手动调用GC，依然存活的就考虑是泄漏了，最后就是分析堆、查引用路径。下面这个文章对里面的代码做了分析，但是版本不是最新，和最新的可能会有一些出入，但大体逻辑是一样的。\n\n[全解系列：内存泄漏定位工具LeakCanary](https://cloud.tencent.com/developer/article/1699620)","tags":["Android","LeakCanary"]},{"title":"Linux命令--tee","url":"/2022/04/90cf3f57d0c0/","content":"\ntee，这个单词没有什么实际性的含义，就是T型管道的意思，在`--`的基础上，变成`T`型，这样就多了一个输出。所以，这个命令的作用就是，在不改变输出原有行为的基础上，将其额外的导向文件中。\n\n<!--more-->\n\n### 1. 举例\n比如想要ping一个地址，下面这样操作只是在标准输出显示了出来，\n```shell\n$ ping baidu.com\nPING baidu.com (220.181.38.148): 56 data bytes\n64 bytes from 220.181.38.148: icmp_seq=0 ttl=53 time=37.463 ms\n64 bytes from 220.181.38.148: icmp_seq=1 ttl=53 time=36.565 ms\n64 bytes from 220.181.38.148: icmp_seq=2 ttl=53 time=35.840 ms\n64 bytes from 220.181.38.148: icmp_seq=3 ttl=53 time=36.733 ms\n64 bytes from 220.181.38.148: icmp_seq=4 ttl=53 time=36.475 ms\n```\n这个时候，加上tee命令，原有的输出没有发生改变，但同时将输出也写到了文件output.txt中，这就是tee命令的用法\n```shell\n$ ping baidu.com | tee output.txt\nPING baidu.com (220.181.38.148): 56 data bytes\n64 bytes from 220.181.38.148: icmp_seq=0 ttl=53 time=42.524 ms\n64 bytes from 220.181.38.148: icmp_seq=1 ttl=53 time=39.871 ms\n64 bytes from 220.181.38.148: icmp_seq=2 ttl=53 time=41.977 ms\n64 bytes from 220.181.38.148: icmp_seq=3 ttl=53 time=38.483 ms\n64 bytes from 220.181.38.148: icmp_seq=4 ttl=53 time=43.906 ms\n\n$ cat output.txt\nPING baidu.com (220.181.38.148): 56 data bytes\n64 bytes from 220.181.38.148: icmp_seq=0 ttl=53 time=42.524 ms\n64 bytes from 220.181.38.148: icmp_seq=1 ttl=53 time=39.871 ms\n64 bytes from 220.181.38.148: icmp_seq=2 ttl=53 time=41.977 ms\n64 bytes from 220.181.38.148: icmp_seq=3 ttl=53 time=38.483 ms\n64 bytes from 220.181.38.148: icmp_seq=4 ttl=53 time=43.906 ms\n```\n\n### 2. 参数\ntee命令默认是覆盖的形式写入到文件，当执行两次时，第二次的输出就会覆盖第一次的输出，是用a，append参数，可以以追加的形式写入到文件。此外，还有i，ignore参数，用来忽略中断命令，同时，tee支持多个文件\n```shell\n$ ping baidu.com | tee -a output1.txt output2.txt output3.txt\n```","tags":["Linux","tee"],"categories":["Linux"]},{"title":"Android WebView使用","url":"/2022/04/dd3a16ba32a7/","content":"\n当需要打开一个URL时，常规操作是用系统浏览器打开，很方便、便捷，不足之处就是只能显示，无法交互。使用SDK提供的WebView可以解决这一点，自然也需要多做一些额外的工作。\n\n<!--more-->\n\n### 1. 简介\n简单说，WebView就是一个具备基础功能浏览器，不想市面上的浏览器那样，加入了各种定制化功能。其内部基于webkit引擎，低版本和高版本采用了不同的webkit版本内核，4.4后使用了Chrome内核。而webkit又是什么呢？它是一个开源的web浏览器引擎，即浏览器内核。当我们请求一个URL后，服务器返回来的是一个个文件，如html，css，等，浏览器的工作，就是把这些文件渲染成易读的形式展现给我们，不同的形式、不同的颜色、不同的交互，等。关于简介，就说这么多。\n\n### 2. 使用\n- 创建\n作为一个控件，和其他控件一样，可以在布局文件中声明，后在使用时代码中获取。也可以在代码中直接创建，然后添加到布局中\n- 基本方法\n```java\n// 同步页面状态到webview，使其可以正常响应，同时在不需要的时候暂停一些动作节省系统资源，如DOM解析，JS执行等\nwebView.onResume();\nwebView.onPause();\n\n// 暂停webview的layout，parsing，jstimer\n// 这是针对全局的，而不单单是当前的webview\nwebView.pauseTimers();\nwebView.resumeTimers();\n\n// 避免webview在销毁时还在加载导致泄漏，如音乐或视频，所以先将其移出，再执行销毁\nrootLayout.removeView(webView);\nwebView.destroy();\n```\n- 前进后退\n```java\nwebView.canGoBakc();\nwebView.goBack();\nwebView.canGoForward();\nwebView.goForward();\n// 负数后退，正数则前进\nwebView.goBackOrForwardd(int steps);\n```\n按下返回键时，Activity会先消费掉此事件，而退出页面，若想按下返回执行webView的后退操作，则需要传递事件给WebView\n```java\npublic void onBackPressed() {\n\twebView.goBack();\n}\n```\n- 清除\n```java\n// 内核缓存是全局的，所以该操作针对的是全局应用\nwebView.clearCache(true);\n\n// 访问记录\nwebView.clearHistory();\n\nwebView.clearFormData();\n```\n\n### 3. 常用类之WebSettings\n用来配置一些和webkit内核相关的属性\n```java\nWebSettings settings = webView.getSettings();\n\n// JS\nsettings.setJavaScriptEnabled(true);\n// 插件\nsettings.setPluginsEnabled(true);\n// 自适应屏幕，二者合用\nsettings.setUseViewPort(true); // 将图片调整到适合webview大小\nsettings.setLoadWithOverviewMode(true); // 缩放至屏幕大小\n// 缩放\nsettings.setSupportZoom(true); // 打开缩放\nsettings.setBuiltInZoomControls(true); // 内置缩放控件\nsettings.setDisplayZoomControls(false);\n// \nsettings.setCacheMode(WebSettings.LOAD_CACHE_ELSE_NETWORK); // 缓存模式\nsettings.setAllowFileAccess(true); // 访问文件\nsettings.setJavaScriptCanOpenWindowsAutomatically(true);\nsettings.setLoadsImagesAutomatically(true);\nsettings.setDefaultTextEncodingName(\"utf-8\");\n\n// 缓存模式\nLOAD_CACHE_ONLY： 只使用缓存\nLOAD_DEFAULT：根据cache-control决定是否使用缓存\nLOAD_NO_CACHE：不用缓存\nLOAD_CACHE_ELSE_NETWORK: 只要本地有，不论过期与否，或者设置了no-cache，都使用缓存中数据\n```\n\n### 4. 常用类之WebViewClient\n主要用来设定WebView的通知、请求事件，如\n```java\nonLoadResource\nonPageStart\nonPageFinish\nonReceiveError\nonReceivedHttpAuthRequest\nonReceivedSslError WebView默认是不处理https请求的，页面显示空白，需手动处理\n```\n\n### 5. 常用类之WebChromeClient\n主要用来辅助WebView处理对话框、网站图标、标题，加载进度等，如\n```java\nonCloseWindow\nonCreateWindow\nonJsAlert(WebView上alert无效，需要在此处理)\nonJsPrompt\nonJsConfirm\nonProgressChanged\nonReceivedIcon\nonReceivedTitle\n```","tags":["Android","WebView"],"categories":["Android"]},{"title":"SurfaceView的使用","url":"/2022/04/324133c11cf5/","content":"\n我们在View中绘制的内容，是由系统绘制的，每隔16ms，系统发出一次VSYNC信号，重新绘制屏幕，这个操作在主线程，所以如果我们在两次绘制之间做的操作耗时超过16ms，页面就会出现卡顿。而SurfaceView则是由我们主动绘制，在子线程，不会卡主线程，同时，SurfaceView实现了双缓存机制。\n\n<!--more-->\n\n摘抄一段关于双缓存的介绍\n> 双缓冲技术是游戏开发中的一个重要的技术。当一个动画争先显示时，程序又在改变它，前面还没有显示完，程序又请求重新绘制，这样屏幕就会不停地闪烁。而双缓冲技术是把要处理的图片在内存中处理好之后，再将其显示在屏幕上。双缓冲主要是为了解决 反复局部刷屏带来的闪烁。把要画的东西先画到一个内存区域里，然后整体的一次性画出来。\n\n### 1. SurfaceHolder\nSurfaceHolder是一个接口，里面定义了使用SurfaceView的相关方法接口。比如，添加Surface状态改变时的回掉、获取画布，等。SurfaceView中维护了一个该类型的变量，我们的操作都是通过这个叫做holder的变量。\n\n### 2. SurfaceHolder.Callback\n因为SurfaceView是我们主动绘制的，所以我们就需要知道其状态，以确保在绘制的时候它是存在且可用的，通过添加此Callback来接收Surface状态发生改变时的回调。Surface有两种状态，即，已创建和已销毁。\n\n### 3. 使用\n```kotlin\nclass CustomerSurfaceView : SurfaceView, SurfaceHolder.Callback, Runnable {\n\n    constructor(ctx: Context) : super(ctx)\n    constructor(ctx: Context, attrs: AttributeSet) : super(ctx, attrs)\n\n    init {\n        holder.addCallback(this)\n    }\n\n    @Volatile\n    private var running = false\n    private var thread: Thread? = null\n    private var nextDraw = 0L\n\n    private val engine: GameEngine = GameEngine(context)\n\n    override fun surfaceCreated(holder: SurfaceHolder) {\n        engine.begin()\n        running = true\n        thread = Thread(this)\n        thread?.start()\n    }\n\n    override fun surfaceChanged(holder: SurfaceHolder, format: Int, width: Int, height: Int) {\n    }\n\n    override fun surfaceDestroyed(holder: SurfaceHolder) {\n        running = false\n        if (thread == null) return\n        synchronized(holder) {\n            while (true) {\n                try {\n                    val t = thread!!\n                    t.join(3000)\n                    break\n                } catch (e: Exception) {\n                    Log.e(\"==\", e.toString())\n                }\n            }\n        }\n        thread = null\n        engine.end()\n        holder.surface.release()\n    }\n\n    override fun run() {\n        while (running) {\n            while (System.currentTimeMillis() < nextDraw) {\n                Thread.yield()\n            }\n            if (!running) return\n            if (holder == null) {\n                return\n            }\n            val start = System.currentTimeMillis()\n            synchronized(holder) {\n                val canvas = holder.lockCanvas()\n                if (canvas != null) {\n                    try {\n                        engine.draw(canvas)\n                    } catch (e: Exception) {\n                        Log.e(\"==\", e.toString())\n                    } finally {\n                        try {\n                            holder.unlockCanvasAndPost(canvas)\n                        } catch (e: Exception) {\n                            Log.e(\"==\", e.toString())\n                        }\n                    }\n                }\n            }\n            nextDraw = start + CraftEngine.FRAME_INTERVAL\n        }\n    }\n\n    @SuppressLint(\"ClickableViewAccessibility\")\n    override fun onTouchEvent(event: MotionEvent?): Boolean {\n        return gestureDetector.onTouchEvent(event)\n    }\n\n    private val gestureDetector = GestureDetector(context, object :\n        GestureDetector.SimpleOnGestureListener() {\n\n        private lateinit var downEvent: MotionEvent\n\n        override fun onDown(e: MotionEvent): Boolean {\n            downEvent = e\n            return true\n        }\n\n        override fun onScroll(\n            e1: MotionEvent?,\n            e2: MotionEvent?,\n            distanceX: Float,\n            distanceY: Float\n        ): Boolean {\n            engine.onTouchMove(distanceX, distanceY)\n            return true\n        }\n    })\n}\n```\n我用它写了一个飞机大战的游戏，创建一个类继承SurfaceView，为了监听它的状态，直接用它实现了Callback，然后在类初始化里，通过holder添加了监听，在回调方法里就可以处理相关的逻辑。\n\n简单说就是，在创建后，启动一个子线程绘制，绘制的画布通过holder锁定获取，绘制完成后需要解锁，在销毁后，将绘制线程停止，节省资源。\n\n这个类里面主要负责处理Surface状态改变，并处理绘制线程，至于具体的游戏逻辑，我都放到了GameEngine里，这里面处理飞机的生成、移动、攻击、碰撞，等。\n\n实时绘制自然视觉效果最好，但由于肉眼的生理限制，当两帧之间的间隔不超过16ms，肉眼就感觉不到卡顿，这样看来1ms就绘制一次，或者5ms就绘制一次就没有必要了，浪费资源，所以，还需要控制一下绘制间隔，控制在16ms即可。\n\n这里有个小坑，开始我的设计是，每次绘制直接交给engine处理，包括帧距控制，SurfaceView里的while循环里只调用了一个engine的draw方法，但是，这种写法，在我的测试机上切换页面之后，Surface的销毁回调就会出问题，要么是不回调，要么就是等一会才会回调。四处查了一些资料，折腾了好久，但也没找到有效的解决方法，最后偶然一试，发现把帧距控制放到SurfaceView里，也就是在while循环里做点事，也就是像上面那些写，甚至只是在里面打行log，问题就莫名其妙的不在了。我想这里面一定还有着什么我所不知道的小秘密，暂时也不管它了，又不是不能用。\n\n需要注意的是，holder每次拿到的画布，都是上一次绘制完的画布，需要手动处理脏区域。拿我做的飞机来说，如果每次只管把飞机绘制到最新位置，那么屏幕上就会出现一串飞机拉线，等同于，每次绘制时拿到的纸，就是上次交出去的纸，所以需要先把上个位置的飞机擦掉，然后再在最新的位置上画上飞机。当然，最简单的办法就是每次都绘制一遍背景图，用背景图盖住上次的内容。另外，为了进一步提高性能，可以不用每次都绘制整张画布，而是选择只绘制需要绘制的区域，lockCanvas有个重载方法，传入一个需要绘制的区域，就可以获取到对应的画布。\n\n此外，我还加了一个GestureDetector，玩游戏难免需要有用户操作输入，通过GestureDetector可以最简单的获取到用的操作。\n\n线程等待这里用的是Thread的yield方法，而不是sleep方法，这二者的区别是，sleep方法会一直占用线程，让卡在这里等着，而yield，顾名思义，大喊一声，你们谁要用就拿去用，我现在还不用，然后释放掉CPU时间片，将自己变成就绪状态。而CPU在被释放掉之后，会再次从当前所有处于就绪状态的线程中，选一个执行，所以这个时候，有可能还会选中刚刚yield的线程。\n","tags":["Android","SurfaceView"],"categories":["Android"]},{"title":"shell字符串操作","url":"/2022/04/753a8bfe877f/","content":"除了sed、awk等命令，shell也内置了一些字符串的操作，可以满足大部分需求，且速度会更快些，省去了调用命令的时间。\n\n<!--more-->\n\n### 1. 字符串读值\n```shell\n- ${var}: 取值\n- ${var-DEFAULT}: 如果var没有被声明，那么就以DEFAULT作为其值\n- ${var:-DEFAULT}: 没被声明或为空，则以DEFAULT作为其值\n- ${var=DEFAULT}: 如果var没有被声明，那么就以DEFAULT作为其值\n- ${var:=DEFAULT}: 没被声明或为空，则以DEFAULT作为其值\n- ${var+OTHER}: 如果var声明了，那么其值就是$OTHER，否则就为null字符串\n- ${var:+OTHER}: 同上\n- ${var?ERR_MSG}: 如果var没有被声明，则打印ERR_MSG\n- ${var:?ERR_MSG}: 同上\n- ${!varprefix*}: 匹配之前所有以prefix开头的变量名称\n- ${!varprefix@}: 同上\n```\n\n### 2. 字符串操作\n```shell\n- ${#string}: 长度\n- ${string:position}: 从position角标开始提取自字符串，角标从0开始\n- ${string:position:length}: 同上，同时限定长度\n- ${string:0-position:length}: 同上，从右边开始数，从1开始，最右字符是1\n- ${string#*substring}: 截取，保留substring右边字符，不包含substring，遇到第一个substring就截取\n- ${string##*substring}: 同上，遇到最后一个substring再截取，常用于URL，星号可通配任意个字符\n- ${string%substring*}: 从右侧开始截取，保留substring左侧字符，不包含substring，遇到第一个就截取\n- ${string%%substring*}: 同上，遇到最后一个再截取\n- ${string/substring/replacement}: 用replacement替换第一个substring\n- ${string//substring/replacement}: 同上，替换所有\n- ${string/#substring/replacement}: 如果string的前缀匹配substring，则用replacement替换substring\n- ${string/%substing/replacement}: 同上，换成后缀\n```","tags":["Linux","shell"],"categories":["Linux"]},{"title":"vim常用命令","url":"/2022/04/46f76ab08387/","content":"在Linux上查看、编辑文件时，vim就必不可少了。有句话不是说，高手，尤其是真正的高手，都是不需要鼠标的，所有操作都通过键盘完成。vim强大之处在于，它支持的功能和操作很多很多，但其实很多命令都是互补的，所以就不必记住每个命令，列一下常用的必要命令。\n\n<!--more-->\n\n命令按类型分为几大类，移动、插入、查找替换、复制粘贴、删除和撤销重做、命令\n\n### 1. 移动\n- hjkl：j是下，k是上，hl是左和右，和玩游戏时移动规则一样\n- w和e：向后移动一个单词，w停在首，e停在尾，这和它俩在键盘上的位置一样\n- b和ge：和上面相反，是往前挪\n- 0 ^ $: 0到开头，^到非空白字符，$行尾字符\n- gg和G：文件头和文件尾\n- zz: 将当前行移动到屏幕中央 zt，top zb，bottom\n\n### 2. 插入\n- a: append 当前字符后\n- i: insert 当前字符位置\n- I和A：行首和行尾插入\n- o和O：下一行，上一行\n\n### 3. 查找替换\n- /text：查找，n下一个，N上一个\n- ?text：反向查找，用上面那个就可以了\n- r和R：替换一个字符，和多个字符\n- :s/old/new/g 不加g替换第一个匹配，加g替换当前行所有匹配\n- :%s/old/new/g 不加g替换所有行第一个匹配，加g替换所有行所有匹配\n- :10,20s/old/new/ 把%换成了指定的行\n\n### 4. 复制粘贴\n- v和V：选中字符和选中行\n- y：复制选中内容 yy复制当前行\n- p：在当前位置粘贴\n\n### 5. 删除 撤销 重做\n- d：删除，也是剪切，它需要指定删除范围，dd=当前行 dh=左侧字符 dl=自己 dk=自己行和上行 dj=自己行和下行 dd=自己行 dgg=自己行到首行 dG=自己行到尾行 d^=前面的 d$=自己和后面的 D=d$ :1,10d=1到10行 :11,$d=11到最后行\n- u和U，撤销上个操作和撤销整行的修改\n- ctrl+r：重做，也就是恢复，撤销撤销\n\n### 6. 命令\n- :set number 行号\n- :set nonunber 关行号\n- :w 保存\n- :q 退出\n- :!command shell命令\n- :q! 强行退出 不保存\n- ctrl + u d：滚动页面 up down","tags":["Linux","Vim"],"categories":["Linux"]},{"title":"Android之从桌面启动应用全过程","url":"/2022/04/fc395161d946/","content":"\n这篇来学习一下从按下桌面应用图标、到应用完成启动，运行至前台，这个过程中系统都做了哪些事。\n\n<!--more-->\n\n### 1. 引言\n为了搞明白，网上的文章没少看，书也翻了不少，这些内容的相同点是，写的都很多，过程可谓相当之繁琐。不同点是，各说各的，没有哪两个人说的是一样的，这个人说这里是这样的，那个人又说这里是这样的，众说纷纭，搞得我这种站在中间本想来学知识，倒成了看热闹的，真想介绍他们互相认识，然后再看着他们讨论。也有可能是版本的原因吧，年代久远带着丝丝尘土味道的文章必然看的是老版本，而越热乎冒着热气的文章定是接近新的系统版本。我已经不想再花更多的时间来验证每篇文章，看看到底哪里对哪里不对，干脆就自己来，自己动手，丰衣足食。\n\n重要的不是版本，而是学习方法，系统版本在不断的升级换代，死记代码实为下下策，只有掌握了学习源码的方法，才是以不变应万变的良策。\n\n以下的方式很简单，别光看，东西很多，记不住的，跟着一起做，习得方法方为本源呐。\n\n### 2. 版本\n我用的SDK 30，在AndroidStudio/Preferences/Android SDK里，下载一下源码，或者用sdkmanager也可以，然后就可以看到源码了，具体路径在这\n```shell\n~/Library/Android/sdk/sources/android-30\n```\n\n### 3. 如何搜索源码\n在AndroidStudio中，双击Shift，多数文件，都可以在这里面通过文件名搜到。能搜到是能搜到，但也只是能搜到而已，里面的引用关系却不都是可以关联，到处都是被`@Hide`、`@NotsupportedAppUsage`等注解修饰的，所以任意打开个文件，满篇的红色报错所烘托出的喜庆氛围，时时刻刻让你有种在过年的错觉。所以，对于那些找不到的方法，找不到的类型，就只能手动去搜索，看看它到底是啥，看看这方法里面到底干了点啥。\n- 搜索文件，一种是在Android Studio里按文件名搜索，另一种是在shell里搜索，是用find命令，其中FileName可以用`*`占位\n```shell\n# 切换到源码路径下\ncd ~/Library/Android/sdk/sources/android-30\n\n# find，查找当前目录下，以及所有子目录下，所有文件名符合条件的文件\nfind . -name \"FileName\"\n```\n- 搜索方法，如果知道在哪个文件，那就直接用Android Studio里的搜索功能，在哪嗖的一下就搜出来了。但是，有时方法属于某个内部类的，所以文件的名字就不是类的名字，这样就搜不到文件，这个时候就直接用grep命令，在大杀器面前，没有什么可以藏起来。\n```shell\ncd ~/Library/Android/sdk/sources/android-30\n\n# r:recursive 查找当前目录，及其所有子目录下的所有文件中，包含关键字的行，支持占位符，支持正则，搜索神器\ngrep -r \"keyWord\" .\n```\n\n以上这些，是帮助学习过程能顺利向前推进的方式，有了动力，下面就说方向。\n\n### 4. Launcher\n首先明确的是，桌面Launcher也是应用，是一个有些特殊的应用，它在系统启动过程中启动的，Android系统启动流程之前简单写过，[点进去可以再看一遍](https://oynix.github.io/2022/01/f6c3174008b0/)。桌面上看到的应用图标，点击之后的打开，长按之后的小浮窗，图标分组管理，拖拽调整位置，卸载时的动画，等等，这些都是Launcher的功能，各大厂商就是修改了Launcher里面的代码后，实现了自己独特风格的桌面。抛开其他的不谈，这里只看点击Launcher上的应用图标后，到应用完全打开，这其中的全过程。\n\n我们上面刚刚下载的，是SDK的源码，这些SDK是供我们在开发APP过程调用的，而Launcher本身就是个APP，是系统自带的APP，它不属于SDK的源码，所以不管用哪种方式，在刚下载的源码中都是搜不到的蛛丝马迹的。这个时候怎么办？对，如果不想去找framework的源码，那就靠推测。\n\n既然Launcher是个APP，那最终就是要继承自Activity的，点击图标就是启动Activity，那就直接看Activity里的startActivity就可以了。\n\n### 5. Activity#startActivity\n搜索打开Activity.java，定位startActivity方法，发现它有几个重载的方法（重载和重写的区别在于，重写是换核不换壳，重载是换参数换返回值），但是不管哪个最终都走到了startActivityForResult方法里，其内又调用了Instrumentation的execStartActivity，Instrumentaion是一个管理Activity和Application生命周期的变量，在Activity搜索这个变量的赋值，发现是在attach方法里初始化，下一步跟进它的execStartActivity方法。\n\n### 6. Instrumentation#execStartActivity\n搜索Instrumentation，定位execStartActivity方法，发现里面内容很少，最终调用的是\n```java\nActivityTaskManager.getService().startActivity\n```\n跳到ActivityTaskManager里，找到getService方法，发现返回的是个IActivityTaskManager类型的实例，不管用哪种方式搜都是搜不到对应类文件的，这时就要搜关键词了，会发现有个类继承自IActivityTaskManager.Stub，看这熟悉的味道，AIDL不就来了吗，既然来了，那就插播一条Binder。\n\n### 7. Binder\n这里只简单的说用法，以便于能继续把代码看下去，等会单独写一篇较为详细的说。\n\nAndroid系统中，同一个进程间，资源共享，不同进程间，资源不共享，无法直接通信。Binder是Android系统中进程之间通信的方式。进程间通信，无非就是调用方法，一个进程提供方法，另一个进程调用这些方法。当然，直接调用是不可能的，中间要通过Binder。所以，提供方进程要以Binder规定的形式定义方法，调用方进程也用Binder规定的方式调用，这样就可以通信了，至于跨进程的的事交给Binder来做。\n\n拿上面的例子来说，IActivityTaskManager中，就是提供方进程所提供的所有方法，同时，提供方要实现这些方法，通过继承IActivityTaskManager.Stub的方式，Stub中默认写了一些Binder需要用到的方法。而调用方，直接调用IActivityManager中定义的方法，即可。继续跟进代码。\n\n### 8. ActivityTaskManagerService#startActivity\n上面调用了IActivityTaskManager的startActivity方法，实际提供功能的是实现类ActivityTaskManagerService，搜索这个类并定位startActivity方法，这个时候，就不在Launcher的进程了，而是来到了ActivityTaskManagerService所在的进程，这个是系统进程，是在系统初始化期间启动起来的。\n\n接下来，即将上演的就是一场足球大赛了，你会看到这个Launcher发来的启动Activity请求，在这个进程间被大家踢来踢去，你传给我，我又传给他，他又回传给我，紧张激烈，眼花缭乱，精彩至极。\n\nstartActivity方法几经转发，最终调用的是其内部的startActivityAsUser方法，这方法里面关键的代码是这句\n```java\n// ActivityTaskManagerService#startActivityAsUser\ngetActivityStartController().obtainStarter(intent, \"startActivityAsUser\").set.set.set.set.execute()\n```\ngetActivityStartController()获取的是一个ActivityStarerController，obtainStarter获取到的是一个ActivityStarter实例。Controller里对ActivityStarter实例进行了复用管理，这和Handler中用的Message.obtain很像，所以可以推断出，ActivityStart也是个频繁使用的对象，所以才需要增加复用的管理，以优化内存。下面看看ActivityStarter选手如何带球过人。\n\n### 9. ActivityStarter\n可以看到的是，在获取到ActivityStarter的实例后，进行了一些列的字段赋值操作，这里类比Message即可，最终调用了execute方法，所以它的流程是，获取对象后初始化各个字段，最后执行，搜索ActivityStarter，定位execute方法。\n\n可以看到的是，execute方法内先是对之前的参数做了一些校验，随后便调用了executeRequest方法，execute一脚将球踢出，我们的目光随着球来到了executeRequest方法。\n\n这个方法主要在做启动前的检查，里面有着不少的注释，解释了每一步在在检查什么，比如状态，比如权限。做完自己想做的事后，并没有实际启动Activity，而是再一次将球传出，转眼球便来到了startActivityUnchecked的脚下，startActivityUnchecked看着脚下的脚，迅速反应。\n\nstartActivityUnchecked可能不在状态，早晨吃冰了有点拉肚子，几个垫步，就将球传给了startActivityInner，看着远去的球，邪魅一笑：嘿嘿，又是划水的一天呢。\n\nstartActivityInner中依然是检查，继续着前人没有完成的工作，同时也对task stack的focusable做了一些检查，最后调用了RootWindowContainer的resumeFocusedStacksTopActivities方法，然后自己就下班了。\n\n伪球赛直播好累，好好说话。\n\n### 10. RootWindowContainer\n想要启动一个Activity，势必要将其显示到屏幕上，RootWindowContainer就是管理屏幕窗口的，这里涉及到了另一个大类，WindowManagerService，WMS，这里只需要知道它将Activity显示了出来，\n\n搜索RootWindowContainer，定位resumeFocusedStacksTopActivities，可以看到，在这里它调用了它其中维护了这个窗口对应的ActivityStack的方法，resumeTopActivityUncheckedLocked\n\n### 11. ActivityStack\n搜到进入到ActivityStack，发现这个文件好长，有3000多行，定位到resumeTopActivityUncheckedLocked，方法内有一大段说明注释\n```java\n            // When resuming the top activity, it may be necessary to pause the top activity (for\n            // example, returning to the lock screen. We suppress the normal pause logic in\n            // {@link #resumeTopActivityUncheckedLocked}, since the top activity is resumed at the\n            // end. We call the {@link ActivityStackSupervisor#checkReadyForSleepLocked} again here\n            // to ensure any necessary pause logic occurs. In the case where the Activity will be\n            // shown regardless of the lock screen, the call to\n            // {@link ActivityStackSupervisor#checkReadyForSleepLocked} is skipped.\n```\n意思大概是，启动一个Activity时，可能需要暂停上一个Activity。所以这个方法里做了两件事，一件是启动Activity，另一件是暂停Activity。启动Activity调用的是resumeTopActivityInnerLocked，暂停Activity调用的是checkReadyForSleep。\n\n这里需要暂停的就是Launcher，在启动完其他Activity后，Launcher就不处于前台了，自然是要被暂停。checkReadyForSleep里调用的是ActivityStackSupervisor的checkReadyForSleepLocked方法，这个方法里又调用了RootWindowContainer的putStacksToSleep，启动Activity和暂停Activity都免不了和Window打交道，毕竟启动和暂停给用户的直观感受就是能看到，和看不到了，其他的细节就不多说了。\n\n回过头来看resumeTopActivityInnerLocked，走了这么远，感觉希望就在眼前了。这个方法内先是为Activity创建了一个新的进程\n```java\nActivityRecord next = ....;\nif (next.attachedToProcess()) {\n    next.app.updateProcessInfo(false /* updateServiceConnectionActivities */,\n            true /* activityChange */, false /* updateOomAdj */,\n            false /* addPendingTopUid */);\n} else if (!next.isProcessRunning()) {\n    // Since the start-process is asynchronous, if we already know the process of next\n    // activity isn't running, we can start the process earlier to save the time to wait\n    // for the current activity to be paused.\n    final boolean isTop = this == taskDisplayArea.getFocusedStack();\n    mAtmService.startProcessAsync(next, false /* knownToBeDead */, isTop,\n            isTop ? \"pre-top-activity\" : \"pre-activity\");\n}\n```\nnext的类型是ActivityRecord，TaskRecord对应一个Activity栈，启动Activity时向栈内压入，销毁Activity时从栈顶弹出，栈里面存储的结构是ActivityRecord，每个ActivityRecord对应一个Activity。这里的next，指的是要启动的Activity，attachedToProcess检查的是是否存在一个进程，这里是没有，所以进入到else，else里做的事情就是为这个ActivityRecord创建一个进程。mAtmService.startProcessAsync便是创建进程的操作。\n\nmAtmService的类型是ActivityTaskManagerService，也就是上面提到过的唯一继承了IActivityTaskManager.Stub的类\n\n### 12. 为Activity启动一个进程\n上面的mAtmService.startProcessAsync将会进入开启进程的任务。搜索ActivityTaskManagerService，定位到startProcessAsync方法\n```java\n// Post message to start process to avoid possible deadlock of calling into AMS with the\n// ATMS lock held.\n final Message m = PooledLambda.obtainMessage(ActivityManagerInternal::startProcess,\n                    mAmInternal, activity.processName, activity.info.applicationInfo, knownToBeDead,\n                    isTop, hostingType, activity.intent.getComponent());\nmH.sendMessage(m);\n```\n方法里面有一句注释，说的是为了避免死锁，所以使用消息的方式创建，mH的类型就是Handler，PooledLambda我还没看，但是可以确定的是，发送消息之后，第一参数lambda就会执行，也就是会调用ActivityManagerInternal的startProcess方法，ActivityManagerInternal是个抽象类，全局搜索\"extends ActivityManagerInternal\"后，可以看到LocalService是它的唯一实现类。\n\nLocalService是AMS的内部类，打开AMS，定位到startProcess方法，里面没有过多操作，直接调用了外部类AMS的startProcessLocked方法，startProcessLocked中直接调用了ProcessList的startProcessLocked方法。\n\nProcessList里面的startProcessLocked一定有着俄罗斯套娃的血统，一路走过4个重载方法，才看到了底，然后又调用了startProcess方法，在这个方法里面，总算是调用Process的start的方法，Process中Zygote通过fork自己，创建出一个新的进程，在进程中执行了android.app.ActivityThread的main方法。\n\n至此，新的进程启动完成。\n\n### 13. ActivityThread与AMS绑定\n这时，我们已经不在系统服务的进程中了，而是来到了刚刚系统进程为Activity新创建的进程。\n\nActivityThread在新的进程中被加载后，会调用它的main函数，我们来看看它在main函数中做了什么事情\n```java\npublic static void main(String[] args) {\n    Looper.prepareMainLooper();\n    ActivityThread thread = new ActivityThread();\n    thread.attach(false, startSeq);\n    Looper.loop();\n}\n```\n很清晰，只做了两件事，一个是创建一个ActivityThread实例并attach，另一个是开始消息循环Looper，毕竟Android是个消息驱动的机制，所以进程启动先开启Looper也是必须的。然后再来看看attach中做了什么事情\n```java\nfinal ApplicationThread mAppThread = new ApplicationThread();\n\nfinal IActivityManager mgr = ActivityManager.getService();\ntry {\n    mgr.attachApplication(mAppThread, startSeq);\n} catch (RemoteException ex) {\n    throw ex.rethrowFromSystemServer();\n}\n```\n获取IActivityManager实例，然后调用它的attachApplication方法。熟悉吗，上面是不是提到过？Launcher启动Activity时，最终调用的是不是就是这个\n```java\nActivityTaskManager.getService().startActivity\n```\n这里也是一样，Launcher是在和ActivityTaskManager跨进程通信，而这里是在和ActivityManagerService通信。这么一调用，才来到这个进程没多久，转眼就要回到系统服务进程中。\n\nActivityManagerService是IActivityManager的唯一实现类，所以上面的调用就会走到AMS的attachApplication中，这个方法里没有做太多事，直接调用了attachApplicationLocked方法，\n```java\n thread.bindApplication(processName, appInfo, providerList,\n                        instr2.mClass,\n                        profilerInfo, instr2.mArguments,\n                        instr2.mWatcher,\n                        instr2.mUiAutomationConnection, testMode,\n                        mBinderTransactionTrackingEnabled, enableTrackAllocation,\n                        isRestrictedBackupMode || !normalMode, app.isPersistent(),\n                        new Configuration(app.getWindowProcessController().getConfiguration()),\n                        app.compat, getCommonServicesLocked(app.isolated),\n                        mCoreSettingsObserver.getCoreSettingsLocked(),\n                        buildSerial, autofillOptions, contentCaptureOptions,\n                        app.mDisabledCompatChanges);\n```\nattachApplicationLocked先是调用了传进啦的thread的bindApplication方法，thread的类型是ApplicationThread，是Activity进程调用attach方法时的第一个参数，Activity进程是刚刚创建启动，其中还没有相关的数据，通过这个方法将系统服务进程的参数发送到Activity进程。之后，attachApplicationLocked继续发扬踢皮球的好传统，将球传给了ActivityTaskManagerInternal的attachApplication，这是个抽象方法，具体实现类在ActivityTaskManagerService中的attachApplication方法，定位到这个方法后，可以看到里面再次传球，调用了RootWindowContainer的attachApplication，然后又调用了startActivityForAttachedApplicationIfNeeded方法，这个方法又调用了ActivityStackSupervisor的realStartActivityLocker方法，到这里，终于看到了曙光，这个方法里的关键代码是这些\n```java\n // line838\n // Create activity launch transaction.\nfinal ClientTransaction clientTransaction = ClientTransaction.obtain(proc.getThread(), r.appToken);\n\nclientTransaction.addCallback(LaunchActivityItem.obtain(new Intent(r.intent),\n        System.identityHashCode(r), r.info,\n        // TODO: Have this take the merged configuration instead of separate global\n        // and override configs.\n        mergedConfiguration.getGlobalConfiguration(),\n        mergedConfiguration.getOverrideConfiguration(), r.compat,\n        r.launchedFromPackage, task.voiceInteractor, proc.getReportedProcState(),\n        r.getSavedState(), r.getPersistentSavedState(), results, newIntents,\n        dc.isNextTransitionForward(), proc.createProfilerInfoIfNeeded(),\n        r.assistToken, r.createFixedRotationAdjustmentsIfNeeded()));\n\n// Set desired final state.\nfinal ActivityLifecycleItem lifecycleItem;\nif (andResume) {\n    lifecycleItem = ResumeActivityItem.obtain(dc.isNextTransitionForward());\n} else {\n    lifecycleItem = PauseActivityItem.obtain();\n}\nclientTransaction.setLifecycleStateRequest(lifecycleItem);\n\n// Schedule transaction.\nmService.getLifecycleManager().scheduleTransaction(clientTransaction);\n```\nTransaction，事务，是Binder通信中的一个概念，里面是用自定义的协议，每次发送协议进行数据传递，都称为一个事务。\n\n先是获取到了一个clientTransaction实例，然后向其中添加了一个LaunchActivityItem，然后又设置了ResumeActivityItem，最终传给了scheduleTransaction。最终会调用IApplicationThread的scheduleTransaction方法，也就是说，系统服务进程会调用Activity进程的中ApplicationTHread的scheduleTransaction方法，这个事务中的LaunchActivityItem，最终会调用ActivityThread的handleLaunchActivity，而ResumeActivityItem会调用ActivityThread的handleResumeActivity方法。Activity的onResume方法执行完，就意味着这个页面已经展示在了屏幕上。\n\n现在想一下，为什么要这么做呢？我们通过ActivityTaskManager.getService可以调用ActivityTaskManagerService中的方法，通过ActivityManager.getService可以调用ActivityManagerService中的方法，这是我们的Activity进程调用系统进程服务的方法，那么系统服进程中的服务若是需要调用Activity进程中的方法，那么它该需要通过什么方式来获取具有可调用方法的实例呢？答案是没有，系统服务进城是开机时创建的，它可以提供接口供后来者调用来获取实例来和它通信，但是我们的Activity进程是在用户的使用过程中创建和小灰的，所以，要想让系统服务进程调用我们Activity进程的方法，那么就需要在Activity进程启动的时候，主动将包含方法的实例告诉系统服务进程，也就是上面所说的绑定操作。而这里所谓的包含方法的实例，则叫做代理。Activity进程通过系统服务进程的代理，调用系统服务进程的方法；系统服务进程则是通过Activity进程的代理，来调用Activity进程的方法。\n\n也就是说，IApplicationThread是Activity进程在系统服务进程的代理，系统服务进程都会通过IApplicationThread来调用Activity进程的方法。\n\n至此，启动流程完成。\n\n### 14. Transaction\n上面的方法里用到了Transaction，LaunchActivityItem是怎么调用ActivityThread的handleLaunhActivity方法的呢？ResumeActivityItem又是怎么调用ActivityThread的handleResumeActivity的呢？下面来说一说这个。\n\n首先，我们知道的是，系统服务进程中的Transaction是通过这样发送出去的\n```java\nmService.getLifecycleManager().scheduleTransaction(clientTransaction);\n```\nmService的类型是ActivityTaskManagerService，定位到它的getLifecycleManager方法，发现返回类型是ClientLifecycleManager，也就是说，最终transaction是传给了ClientLifecycleManager的scheduleTransaction方法\n```java\n// ClientLifecycleManager.java\nvoid scheduleTransaction(ClientTransaction transaction) throws RemoteException {\n    final IApplicationThread client = transaction.getClient();\n    transaction.schedule();\n    if (!(client instanceof Binder)) {\n        // If client is not an instance of Binder - it's a remote call and at this point it is\n        // safe to recycle the object. All objects used for local calls will be recycled after\n        // the transaction is executed on client in ActivityThread.\n        transaction.recycle();\n    }\n}\n```\n这个方法里面，直接调用了ClientTransaction的schedule方法\n```java\n// ClientTransaction.java\npublic void schedule() throws RemoteException {\n    mClient.scheduleTransaction(this);\n}\n```\n这个方法又调用了mClient的scheduleTransaction方法，mClient的类型是IApplicationThread，意思就是说，这个时候就把ClientTransaction发送给了ActivityThread的内部类ApplicationThread处理了。启动流程说完了，耐心一下子就上来，来，一行一行往下说，看看ApplicationThread中是怎么处理Transaction的\n```java\n// ApplicationThread.java\npublic void scheduleTransaction(ClientTransaction transaction) throws RemoteException {\n    ActivityThread.this.scheduleTransaction(transaction);\n}\n```\n又很简单，又什么都没干，交给了外部类ActivityThread，而scheduleTransaction方法不是ActivityThread自己的，是它继承自父类ClientTransactionHandler的，它并没有重写，所以，还要到父类ClientTransactionHandler中看看这个方法\n```java\n// ClientTransactionHandler.java\nvoid scheduleTransaction(ClientTransaction transaction) {\n    transaction.preExecute(this);\n    sendMessage(ActivityThread.H.EXECUTE_TRANSACTION, transaction);\n}\n\nabstract void sendMessage(int what, Object obj);\n```\n看到这，就明白了吧，父类处理ClienTransaction的方式就是，调用sendMessage方法，ActivityThread作为子类，实现了sendMessage方法，所以它能接收到这个message，它处理message的方式是这样\n```java\npublic void handleMessage(Message msg) {\n    switch (msg.what) {\n        case EXECUTE_TRANSACTION:\n            final ClientTransaction transaction = (ClientTransaction) msg.obj;\n            mTransactionExecutor.execute(transaction);\n            if (isSystem()) {\n                // Client transactions inside system process are recycled on the client side\n                // instead of ClientLifecycleManager to avoid being cleared before this\n                // message is handled.\n                transaction.recycle();\n            }\n            // TODO(lifecycler): Recycle locally scheduled transactions.\n            break;\n    }\n}\n```\n再次传球，交给了mTransactionExecutor处理，它是ActivityThread中的一个变量，类型是TransactionExecutor\n```java\n// TransactionExecutor.java\npublic void execute(ClientTransaction transaction) {\n    executeCallbacks(transaction);\n\n    executeLifecycleState(transaction);\n}\n\npublic void executeCallbacks(ClientTransaction transaction) {\n\tfinal int size = callbacks.size();\n    for (int i = 0; i < size; ++i) {\n        item.execute(mTransactionHandler, token, mPendingActions);\n        item.postExecute(mTransactionHandler, token, mPendingActions);\n    }\n}\n\nprivate void executeLifecycleState(ClientTransaction transaction) {\n\tfinal ActivityLifecycleItem lifecycleItem = transaction.getLifecycleStateRequest();\n    lifecycleItem.execute(mTransactionHandler, token, mPendingActions);\n    lifecycleItem.postExecute(mTransactionHandler, token, mPendingActions);\n}\n```\nTransactionExecutor执行execute时，先调用callback，再调用lifecyclestate，完事。而它们的execute和postEcexute方法，都是写在自身里面的，LaunchActivityItem写的就是handleLaunchActivity，ResumeActivityItem写的就是handleResumeActivity\n```java\n// ResumeActivityItem.java\npublic void execute(ClientTransactionHandler client, IBinder token, PendingTransactionActions pendingActions) {\n    client.handleResumeActivity(token, true /* finalStateRequest */, mIsForward, \"RESUME_ACTIVITY\");\n}\n\n// LaunchActivityItem.java\npublic void execute(ClientTransactionHandler client, IBinder token, PendingTransactionActions pendingActions) {\n    ActivityClientRecord r = new ActivityClientRecord(token, mIntent, mIdent, mInfo,\n            mOverrideConfig, mCompatInfo, mReferrer, mVoiceInteractor, mState, mPersistentState,\n            mPendingResults, mPendingNewIntents, mIsForward,\n            mProfilerInfo, client, mAssistToken, mFixedRotationAdjustments);\n    client.handleLaunchActivity(r, pendingActions, null /* customIntent */);\n}\n```\n\n### 15. 总结\n这个过程，其实用几句话就能说完，Launcher进程通过Binder向系统服务进程发送启动请求，系统服务进程做一些准备后，创建一个新进程，新进程通过Binder和系统服务进程绑定，然后系统服务进程通过Binder调用这个新进程的生命周期方法。\n\n看着简单的流程中，其实充满了各种各种的情况，所以要做很多检查，验证，因此，一个启动Activity的请求，就可以让系统像个足球场般热闹起来。","tags":["Android"],"categories":["Android"]},{"title":"解决Android ViewBinding爆红","url":"/2022/04/2814e9f4347b/","content":"\nViewBinding生成的类经常在一些不经意的操作之后爆红，说找不到，虽然不影响运行，但是看起来很不爽，即便你能看到生成类就在那躺着，但是AS就是说找不到。既然它自己找不到，那就给它指个路。\n\n<!--more-->\n\n在app下的build.gradle添加配置，将生成的文件手动添加进去即可\n```groovy\nandroid {\n    sourceSets {\n        debug {\n            java.srcDirs = ['src/main/java', 'build/generated/data_binding_base_class_source_out/debug/out']\n        }\n    }\n}\n```\n\n当然，也可以包含完整的资源\n```groovy\nandroid { \n    sourceSets {\n        main {\n            assets.srcDirs = ['src/main/assets', 'src/main/assets/']\n            jniLibs.srcDirs = ['libs']\n            res.srcDirs = ['src/main/res']\n            java {\n                srcDirs = ['src/main/java']\n                exclude 'src/ignoreDir'  // 不想包含文件的路径\n            }\n        }\n        debug {\n            java.srcDirs = ['src/main/java', 'build/generated/data_binding_base_class_source_out/debug/out']\n        }\n        release {\n            java.srcDirs = ['src/main/java', 'build/generated/data_binding_base_class_source_out/release/out']\n        }\n    }\n}\n```\n\n但是，这样会带来另外一个问题，原本点生成的ViewBinding生成类，是跳转到对应的xml布局文件中，当添加了资源目录后，跳转到的就是生成的类文件了。原因是，加入到sourceSets后，生成类文件就被IDE当成普通的类文件处理。我觉得，相比于爆红，这个倒是可以接受的，不通过生成类跳转便是了。","tags":["Android"],"categories":["Android"]},{"title":"Kotlin的inline，noinline，crossline","url":"/2022/04/2cb2cb5ddfa5/","content":"\n好好说说这line三兄弟。\n<!--more-->\n\n### 1. Kotlin高阶函数\n要想说明白，从头捋了一下，还得从Kotlin的高阶函数说起。首先，什么是高阶函数呢？其实所谓的高，是相对而言的，就普遍性而言，函数的参数和返回值，要么没有，要么是个数值，要么是个引用类型的对象，这是低阶函数。当一个函数的参数或者返回值类型，也是一个函数类型时，这种就叫高阶函数，函数型的类型，是Kotlin中特有而Java没有的。\n```kotlin\n// 这是参数类型是函数的函数\nfun fun1(item: () -> Unit) {}\n\n// 这是返回值类型是函数的函数\nfun fun2(): () -> Unit {}\n\n// 声明函数类型的变量，\n// 因为函数名字用不到，所以被Kotlin强制要求不能写，f1、f2、f3是变量名字\nval f1 = fun () {}\nval f2: (Int) -> Unit = {}\nval f3 = {}\n```\n简单吧，高阶函数就是这样的\n\n### 2. Kotlin中的::\n使用两个冒号加上函数的名字，这个函数就可以被当作参数传递，这其中是为什么呢？\n\n首先需要明确的是，函数就是函数，不是对象，然而只有对象才能被当作参数传递，所有传递函数的地方，在编译之后Kotlin都将其封装成了一个对象，通过括号调用函数类型的参数，实际上就是在调用这个函数对象的invoke方法，开发中可以直接传递函数，这本质上是个语法糖。\n\n语法糖，一时爽。我们都知道，创建对象是有消耗的，每调用一次传递函数类型的函数，就要为这个参数创建一个对象，如果在循环中调用，那可能就是个隐藏的内存炸弹。所以，为了解决这个可能的隐患，有请inline登场。\n\n### 3. inline\ninline多用于修饰带有函数类型参数的函数，如果你用它来修饰一个普通函数，也可以，但是IDE会给你弹提醒，告诉你，没必要。调用被inline修饰的函数，不会增加一层调用栈，inline，顾名思义，在一条线上。所以，在编译期间，会把inline的函数直接复制到调用的位置，连同函数类型的参数也一并展开，这样就巧妙的去掉了函数参数，从而也不会增加创建函数对象的消耗了\n```kotlin\ninline fun f(fp: (String) -> Unit) {\n\tprintln(\"welcome\")\n\tfp(\"message from f\")\n}\n\nfun main() {\n\tf { msg ->\n\t\tprintln(msg)\n\t}\n}\n```\n编译后的main函数，会把f的代码复制过，大概长这个样子\n```kotlin\nfun main() {\n\tprintln(\"welcome\")\n\tprintln(\"message from f\")\n}\n```\n\n### 4. noinline\n看名字就知道，和inline相反，但是inline是修饰方法，noinline是修饰函数参数的，我们已经知道了，inline修饰的方法，在编译时会复制代码，并把函数参数展开。有时候，函数会有多个函数类型的参数，我们并不希望将所有参数都展开，这个时候用noinline修饰不想被展开的函数类型的参数，即可。\n\n### 5. crossline\n这里主要涉及return的问题，看个例子\n```kotlin\ninline fun hi(callback: () -> Unit) {\n\tprintln(\"finish\")\n\tcallback()\n}\n\nfun main() {\n\thi {\n\t\tprintln(\"callback\")\n\t\treturn\n\t}\n\tprintlin(\"main end\")\n}\n```\n调用hi函数时，函数参数体中的return直观上看返回的是hi，然后会执行println(\"main end\")，但是，hi可是inline修饰的函数，还是先看看最终形态\n```kotlin\nfun main() {\n\tprintln(\"finish\")\n\tprintln(\"callback\")\n\treturn\n\tprintln(\"main end\")\n}\n```\n这么一看，return又是返回的main函数，所以由于嵌套的函数体，return成了一个繁琐的问题，因此，Kotlin有有几个规定\n- 函数参数的参数体内，不允许调用return，只有inline修饰的函数的函数参数体可以调用return，此时return返回的是外层函数\n- inline修饰的函数中，不允许再嵌套调用函数参数\n ```kotlin\n inline fun hi(callback: () -> Unit) {\n \tprintln(\"finish\")\n \tscope.launch {\n \t\tcallback() // 此处报错\n \t}\n }\n ```\n- 如果真的需要在inline函数中嵌套调用函数参数，那么就用crossline修饰这个参数，但是，被修饰参数的函数体中，便不能再调用return\n- 上面只是说不可以单独调用return，但是都可以调用return@label来手动指定返回锚点\n\n总结下来就是，inline函数中没有被crossline修饰的函数参数体中，可以调用return，返回的是外层函数。同时，只有被crossline修饰的函数参数，才可以嵌套调用。\n\n### 6. 总结\n- inline：修饰函数，被修饰的函数编译后将代码复制到调用处，并将函数类型的参数展开\n- noinline：修饰函数类型的参数，被修饰后将不再展开\n- crossline：修饰函数类型的参数，被修饰后可以在inline函数中嵌套调用\n","tags":["Kotlin"],"categories":["Kotlin"]},{"title":"Java和Kotlin的范型","url":"/2022/04/4040bd6a597f/","content":"\n我发现，想要解释清楚一个名词，如果只是拿着定义反复说，远不如举个合适的例子来的更快更直接。而且，举的例子越形象，理解的就越快，选的对比物越独特，记忆就越持久，这样即便是过了很久，只要是到了用的时候，便会立刻回忆起这个独特的例子，从而相关知识再次被成功加载到脑子里。\n\n<!--more-->\n### 序言\n范型这个东西，接触也不是一天两天了，但好像就从来没有领悟透彻，需要的时候查一查，加上高度人性化的IDE，总是能满足迎面而来的种种需求，等到事后便又云里雾里，所谓知其然，更要知其所以然，这篇就来好好说说，系统性的来捋一捋。\n\n想了一下，还是用生活中常见的东西来举例吧：手机。新世纪初曾出现过一种系统名字为塞班的手机，Symbian，后来被诺基亚收购，全球出货量相当之高，至今记录尚未被打破，在当时有个塞班手机是个很开心的事了，在上面能装QQ，通过流量和朋友聊天，相比于发短信能省下不少钱，那个时候30M的流量可以用上一个月，每天都计算着流量玩手机。时代在发展，社会在进步，再后来，更智能的Android系统和iOS系统出现了，逐步替代了塞班机器，出了塞班机能做到的事情，它还有着更先进的功能。\n\n接下来，就用手机(Phone, Symbian, Android)、手机生产商(Producer)和手机用户(Consumer)，来说说范型是什么。\n\n在功能上，我们可以把它们之间看成是继承的关系，Phone代表的就是能打电话的设备，Symbian代表的在能打电话的基础上，还能进行一些简单的联网操作，比如发个QQ消息，打开个网页，而Android则是在Symbian的功能之上，又增加了更多的功能，比如语音通话、视频通话、看直播，等等。\n```shell\n|--Phone （打电话）\n   |--Symbian （打电话，发消息）\n      |--Android （打电话，发消息，视频通话）\n```\n\n### 1. 引出\n先从熟悉的Java说起。\n\n我们都知道，当声明完一个类型的变量后，可以用这个类型自身来初始化，也可以用它的子类来初始化，这些都是可以编译运行的\n```java\nSymbian phone = new Symbian();\nSymbian phone = new Android();\n```\n这个其实很好理解，你想，我声明一个Symbian是为了干嘛，不是打电话就是发消息，那么，不管给我一个Symbian还是给我一个Android，等我拿到手后，都可以满足我的需求，所以这是允许的，这也就是Java三大特性之一，多态。\n\n说完这个，再来看看下面这种使用集合时的情况\n```java\nList<Symbian> sym = new ArrayList<Symbian>();\nList<Android> and = sym;\n```\n声明一个Android类型的集合，然后用一个类型是Symbian的集合来赋值，你会发现，这么写会报错，也就是不被允许的。这是因为，Symbian虽然是Android的子类，`List<Symbian>`却不是`List<Android>`的子类，这里，就涉及到了类型擦除。\n\n简单说说什么是类型擦除。Java虽然支持范型，但是JVM里却没有范型这个东西的，Java写的代码最终都要放到JVM里去跑，所以，其中的范型都要去掉，替换成一个确定的类型，这个操作，就叫类型擦除，这个事是在编译阶段由编译器来做的。所以，`List<Symbian>`不是`List<Android>`的子类，但是，`List<Symbian>`是`Collection<Symbian>`的子类。\n\n针对这个问题，Java提供了两个通配符，? extends和? super。\n\n### 2. ? extends\n? extends是Java提供的范型通配符，通过extends限制了位置类型的?，用法如下\n```java\nList<? extends Symbian> phone = new ArrayList<Symbian>();\nList<? extends Symbian> phone = new ArrayList<Android>();\n```\n对于声明的变量phone，?代表着类型不确定，但是通过extends可以知道，它是Symbian的子类，所以在初始化的时候，可用Symbian或者它的子类，甚至它的子类的子类，都是可以的。\n\n通过phone的get方法获取元素时，返回的类型只能是Symbian，因为对于变量phone来说，它只知道自己存储的是Symbian或其子类，具体类型并不知道，所以为了安全，它只能返回Symbian类型。假如它返回了一个Android类型，调用者拿返回值来视频通话，但是实际存储若是Symbian类型，则没有视频通过这个功能，为避免这种情况，Java将返回类型限定为Symbian。\n\n现在想一下通过add方法向phone添加元素的情况，当存储的真实类型是Android时，这个时候是不能向其中添加Symbian类型元素的，因为Symbian是Android的子类，父类型接收子类型的实例这是可以的，因为父类型有的功能子类型都有，所以调用父类型任何方法都不会出错，但是子类型接收父类型的实例是不可以的，生命一个Android类型，用Symbian初始化，等到调用视频通过时，Symbian就傻眼了，它不会呀。为了避免这个可能出现意外的情况，所以Java直接禁止了向其中添加元素，既然解决不了问题，那就解决提出问题的人。\n\n所以，? extends T通配符可以用自身及其子类，子类的子类初始化，从其中get获取元素时，均为T类型，且不可向其add元素。\n\n### 3. ? super\n看过上面的extends，这个? super T就很好理解了，?同样代表着类型不确定，但是是T的父类型，\n```java\nList<? super Symbian> phone = new ArrayList<Symbian>();\nList<? super Symbian> phone = new ArrayList<Phone>();\n```\n通过super通配符限定变量phone的范型，它可以使用Android，或是Symbian初始化。要知道，Java中Object是所有类的父类型，所以在此使用Object初始化，也是可以的。\n\n通过get从中获取元素时，因为phone不知道具体类型，所以为了万无一失，它只能返回Object类型，只有Object类型才能应对所有类型的情况。通过add添加时，虽然phone不确定自己存储的是哪种类型，但是，接收Symbian及其子类型类型就一定不会出错，因为不管是Symbian的父类型还是间接父类型，只要它有的功能，Symbian就一定也有，同理，Symbian的子类型也有。\n\n总结下来就是，? super限定符的集合，可以add添加，但是获取的都是Object类型\n\n### 4. 总结\nJava这些对于范型极其限定符的种种限制，其实，都是为了编译后在JVM中运行不出现问题，如果能从这一点考虑，这些就很好理解了。如果把Java中的继承关系，看成上下承接关系的话，父类在上，子类在下，子类在继承了父类型之后，又扩展了自己独特的功能，就像上面的例子中Phone、Symbian和Android的关系，这样来看，它们就像一个没有底边的三角形，坐在尖尖上的就是Object的，功能最少，越向下的子类型，功能越丰富，也就越庞大，这个关系模型需要记住，有了这个还算形象的模型，后面的一点定义会很好理解。\n\n? extends T限定符限定了类型是T或其子类，官方说法是，限定了类型上限，结合三角形模型来看，就像是在T这一层画一条线，被这个限定符限定的，只能是这条线以下的类型，这条线即为类型上限，T为功能最小的类型，也叫协变，covariance。\n\n? super T限定符限定了类型是T或其父类，官方说法是，限定了类型下限，结合三角形模型来看，类型T同样是一条线，可接收的类型均在线的上方，这条线是类型下限，T是功能最多的类型，这个叫逆变，contravariance，向下才能做大做强，它非要逆流而上，所以叫它逆变\n\n当没有修饰符，只有一个T时，这个时候限定了类型只能是这种，没有其他可能，所以这个叫不变，invariance\n\n### 5. 类型擦除\n上面提到了类型擦除，那么如何擦除，以及擦除后是什么样子的呢？简单说，就是用实际的类型替换掉不确定的范型。举个例子\n```java\npublic class Test<T extends Phone> {\n   T phone;\n\n   public T getPhone() { return phone; }\n   public void setPhone(T p) { phone = p; }\n}\n```\n假设这个带范型的类，擦除之后大概就是这样\n```java\npublic class Test {\n   Phone phone;\n\n   public Phone getPhone() { reurn phone; }\n   public void setPhone(Phone p) { phone = p; }\n}\n```\n擦除之后，没有繁星的类，在JVM中才可运行。这是类中范型的例子，方法参数的情况也是一样的道理。\n\n不变的范型，替换成Object。\n\n协变的范型，替换成上限类型。\n\n逆变的范型，替换成Object。\n\n### 6. <?> <T>\n如果仔细看上面的话，会发现一个小细节，在开始声明变量phone时，用的是? extends，到上面类型擦除的例子里，用的变成了T extends。这两个的区别就在此，\n- `<?>`：范型的声明\n- `<T>`：范型的定义\n相同点，就是二者都可以限定类型的上限，或者下限。\n\n### 7. in，out\n说完Java，再看看Kotlin。\n\nKotlin中没有extends和super，与之替换的是out和in\n- out：限定类型上限，与? extends等同，在三教模型中，上面是个死胡同，想要out就要向下后，所以限定了上限\n- in：等同? super，限定类型下限，也可以结合三角模型来记，in就是往三角里面走\n\n### 8. Java的？和Kotlin的*\n在Java中单独使用`?`当作范型类型时，它表示的所有类型，等同于：? extends Object。\n\nKotlin中有个与之对等的`*`，等同于out Any。\n\n### 9. where\n当有多个类型限定范型时，Java和Kotlin的写法稍有不同，Java是这样的\n```java\nclass Apple<T extends Fruits> {}\n\nclass Apple<T extends Fruits & Food> {}\n```\nKotlin中，单个限制时使用冒号，多个时使用where\n```kotlin\nclass Apple<T : Fruits>\n\nclass Apple<T> where T : Fruits, T : Food\n```\n\n### 10. refied\n上面说过范型擦除，所以在运行时候需要知道范型确切类型信息的操作都没法用了，因为不是上限类型就是下限类型，或者是Object\n```Java\nClass Test<T> {\n   void print(Object item) {\n      if (item instanceof T) {\n         // 这里是获取不到的，编译也过不去\n      }\n   }\n}\n```\nKotlin也是一样的\n```Kotlin\nclass Test<T> {\n   fun print(item: Any) {\n      if (item is T) {\n         // 同Java一样\n      }\n   }\n}\n```\n在Java中的解决方式是，将T换成Class`<T>`，然后通过Class.isInstance方法\n   ```Java\nClass Test<T> {\n   Class<T> ct;\n   Test(Class<T> c) {\n      ct = t;\n   }\n   void print(Object item) {\n      if (ct.isInstance(item)) {\n      }\n   }\n}\n```\n在Kotlin中，也可以使用这中方法\n```Kotlin\nclass Test<T>(val c: Class<T>) {\n   fun print(item: Any) {\n      if (c.isInstance(item)) {\n      }\n   }\n}\n```\n除此之外，Kotlin还提供了一个关键字reified，使得一种更为简答的方式可用\n```kotlin\nclass Test<T> {\n   inline fun <T reified> print(item: Any) {\n      if (item is T) {\n      }\n   }\n}\n```\n\n### 11. 应用 PECS\n上面提到过，extends限定了类型上限的List，不能添加，只能向外提供，我们给它起个名字，就叫做生产者，Producer。同样，super限定了类型下限的List，get出来的都是Object，并没有什么实际意义，而可通过add向内添加元素，我们也给它起个名字，叫做消费者，Consumer，结合二者，便是常说的PECS，在Kotlin中，应该就是POCI了吧，但是好像还没听过有谁这么叫，在Java面前，可能Kotlin还是年轻些。\n\n生产者和消费者模式，就是范型限定的常见应用，举个例子，说明一下。还是用手机的例子。\n\n生产者接口，可以提供商品\n```kotlin\ninterface Producer<out T> {\n   fun produce(): T\n}\n```\n消费者接口，可以使用商品\n```kotlin\ninterface Consumer<in T> {}\n```\n手机生产者\n```kotlin\nclass PhoneProducer : Producer<Phone> {}\nclass SymbianProducer : Producer<Symbian> {}\nclass AndroidProducer : Producer<Android> {}\n```\n实例化出来生产者\n```kotlin\nval p1: Producer<Phone> = PhoneProducer()\nval p2: Producer<Phone> = SymbianProducer()\nval p3: Producer<Phone> = AndroidProducer()\n```\n分析一下，我们声明了一个类型是`Producer<Phone>`的变量p，Producer使用了out范型修饰符，也就是说，p的类型上限就是Phone，那么自然可以传递Phone或其子类行给p，如果反过来则不行，通俗的理解就是，我一个准备生产只带有打电话功能的手机，你给我一个Phone工厂可以生产，Symbian工厂也能生产，Android工厂更能生产了，相反，我想要一个生产Android的工厂，你给一个生产Symbian的，肯定就是不行了，这里的重点是能否生产出。\n```kotlin\nval p1: Producer<Android> = PhoneProducer() // 报错\nval p2: Producer<Android> = SymbianProducer() // 报错\nval p3: Producer<Android> = AndroidProducer()\n```\n这便是体现了限定上限范型的协变性。\n\n生产者看完，再来看看消费者\n```kotlin\nclass PhoneConsumer : Consumer<Phone> {}\nclass SymbianConsumer : Consumer<Symbian> {}\nclass AndroidConsumer : Consumer<Android> {}\n```\n实例化出消费者\n```kotlin\nval c1: Consumer<Android> = PhoneConsumer()\nval c2: Consumer<Android> = SymbianConsumer()\nval c2: Consumer<Android> = AndroidConsumer()\n```\n再分析一个消费者，限定符in限定了类型下限是Android，所以可以传递父类型给c，这里通俗的理解就是，我一个能把Android玩明白的消费者，你让我去玩一个只能打电话的Phone，我肯定没有问题，同理，反过来也是不行的，我只能会用只能打电话的老年机Phone，你给我一个Android，我不会用的呀，这里的重点是能否消费掉，这里体现的是范型的逆变性。\n```kotlin\nval c1: Consumer<Phone> = PhoneConsumer()\nval c2: Consumer<Phone> = SymbianConsumer() // 报错\nval c3: Consumer<Phone> = AndroidConsumer() // 报错\n```\n\n此外，除了生产者和消费者，还有个聚合体，叫生产消费者，ProducerConsumer，根据传入的类型T，生产时成为类型上限，消费时成为类型下限，最终，就只能是类型T，所以生产消费这体现的是不变性。\n\n### 9.总结\n发现每个小节的开头语，多数都是上面提到过、上面说过，下面的内容在不断的延伸上面的内容，就像台阶一样，只有把下面的看明白，才能看懂上面的。完整的看一遍下来，发现范型里也没什么深奥难懂的点，只是自己知识的盲点给它增加了几分神秘色彩，稍稍花上点时间，就可以揭开这神秘的面纱。\n","tags":["Kotlin","Java"],"categories":["Kotlin"]},{"title":"Kotlin的KClass，Java的Class","url":"/2022/04/e73b1ac0e745/","content":"Java中有Class，而Kotlin则有它的KClass，说说二者的区别和联系。\n\n<!--more-->\n\n### 1. Java Class\nJava中的Class是一个final修饰的类，只有一个私有的构造方法，\n```java\npublic final class Class<T> {\n    /*\n     * Private constructor. Only the Java Virtual Machine creates Class objects.\n     * This constructor is not used and prevents the default constructor being\n     * generated.\n     */\n    private Class() {}\n}\n```\n根据方法说明可以知道，这个构造方法是给JVM调用的，JVM在加载类的时候会创建对应的Class实例，存放在方法区，一个类只会有一个Class实例，所以下面这个例子中，c1和c2是一样的。\n```java\n// Java\nclass Person {}\n\nPerson p = new Person();\nClass c1 = p.getClass();\nClass c2 = Person.class;\n```\nClass类中的方法和成员变量相当之多，但基本都关于Class本身的数据相关，比如获取成员函数、获取成员变量，等等。\n\n### 2. Kotlin KClass\n与Java Class不同的是，KClass是一个接口，根据接口说明，`::class`可以获取到KClass的实例，这个接口中同样也是声明了一些和类有关的变量，比如类的名字，类的成员等等\n```kotlin\n/**\n * Represents a class and provides introspection capabilities.\n * Instances of this class are obtainable by the `::class` syntax.\n * See the [Kotlin language documentation](https://kotlinlang.org/docs/reference/reflection.html#class-references)\n * for more information.\n *\n * @param T the type of the class.\n */\n```\nKClass有一个实现类，名字是ClassReference，根据名字可以看出，这个类就是参考的Class，通过将Class实例作为构造参数传入，相关字段均通过class实例获取\n```kotlin\npublic class ClassReference(override val jClass: Class<*>) : KClass\n```\n通过Kotlin可扩展的语言自身特性，为KClass扩展了几个属性，这些属性在JvmClassMapping.kt中\n```kotlin\npublic val <T> KClass<T>.java: Class<T>\npublic val <T : Any> Class<T>.kotlin: KClass<T>\n\npublic inline val <T : Any> T.javaClass: Class<T>\n\npublic val <T : Any> KClass<T>.javaPrimitiveType: Class<T>?\npublic val <T : Any> KClass<T>.javaObjectType: Class<T>\n\n@Deprecated(\"Use 'java' property to get Java class corresponding to this Kotlin class or cast this instance to Any if you really want to get the runtime Java class of this implementation of KClass.\", ReplaceWith(\"(this as Any).javaClass\"), level = DeprecationLevel.ERROR)\npublic inline val <T : Any> KClass<T>.javaClass: Class<KClass<T>>\n```\n前两个属性还挺有趣，Class.kotlin获取KClass，KClass.javaClass获取Class，真是你中有我，我中有你，.完java再.kotlin，能这么一直循环玩下去。后两个属性的区别是，如果本身不是原始类型，那么javaPrimitiveType会返回null。\n\n最后一个javaClass，已经弃用了，上面写了，让使用java属性，那就不管它就好了\n\n### 3. 总结\nJava的Class我们是很熟识的了，容易造成混乱的，就是它和KClass的关联，二者可以互相获取\n\n- 获取KClass，按照文档里写的，直接取class属性，在实例和在类上调用，获得的结果是一样的\n```kotlin\n// 1. 直接获取\nclass Person {}\nval kc1 = Person::class\nval kc2 = Person()::class\n\n// 2. 从Class获取\nval kClass = Person().javaClass.kotlin\n```\n- 获取Class，主要通过扩展属性\n```kotlin\n// 1. 从实例获取\nval jClass = Person().javaClass\n\n// 2. 从KClass获取\nval jClass = Person::class.java\n```","tags":["Android","Kotlin","Java"],"categories":["Android"]},{"title":"TCP介绍","url":"/2022/04/1657b987f4f2/","content":"TCP，Transmission Control Protocol，传输控制协议，是众多网络协议中较为重要的一个协议，网上多是写三次握手和四次挥手的，一搜就能看到一片又一片，多数都是CV战士的杰作，CV战士绝不认输，所以这篇文章来全面的说说TCP。\n\n<!--more-->\n\n### 1. 引言\n如果抛开复杂的协议，只看网络的话，网络传输的就是二进制数据流，也就是一串，或者一长串0011、0101的数据。网络的目的是为了通信、为了交流，这些数据流的通信方式就是，发送方和接收方约定好每个位置的0或1代表着什么，这样接收方收到数据时，就知道发送方想要表达的意思了。但是，一个发送方不可能只给一个接收方发送数据，接收方也不能只接收一个发送方，而且发送方也不总是发送方，也有可能接收数据，因此，为了方便发送和接收，不出现五花八门的约定，大家便统一了数据的格式，这就是协议（protocol）。同时，为了更好的适应不同的情形所产生的需求，各种各样的协议应用而生，数据格式只是协议中的一部分，除此之外，每种协议还规定了各自的发送、接收的特点等等诸多细节，而TCP，就是这众多协议中的一员，这是一个相当复杂的协议，作为一个可靠性连接协议，你不知道它为了能让你的数据正确且完整的到达接收端在背后付出了多大的努力。\n\n### 2. 简介\n数据在TCP层称为流（Stream），数据分组称为分段（Segment）。数据在IP层称为Datagram，数据分组称为分片（Fragment）。UDP中分组称为Message。\n\n### 3. 运作方式\nTCP协议的运行划分为三个阶段：连接创建(connection establishment)、数据传送（data transfer）和连接终止（connection termination）。操作系统将TCP连接抽象为套接字表示的本地端点（local end-point），作为编程接口给程序使用。在TCP连接的生命期内，本地端点要经历一系列的状态改变。\n\nTCP在每一个要发送的数据包前面，都会添加一个数据头，这个数据头的长度是20个字节，长大概这个样子\n![](https://s2.loli.net/2022/04/18/KzldYFkO8nfXUQ2.png)\n一行代表32个bit，也就是4个字节。前4个字节分别存储源端口和目标端口，序列号seq和确认号ack各占4个字节，接下来的4个字节存储标识位和窗口大小，最后4个字节存储校验和和紧急指针。\n\n#### 3.1 创建通路\nTCP用三次握手创建一个连接，通常是服务器打开一个套接字socket进行监听listen，等待被动打开，客户端连接服务器，主动打开。服务器执行listen之后，会创建两个队列：\n- SYN队列：存放完成两次握手的连接，长度由listen的参数backlog指定\n- ACCEPT队列：存放完成三次握手的连接，长度由listen的参数backlog指定\n\n三次握手过程，下面就直接写Client和Server，不写客户端和服务端\n1. Client通过执行connect向Server发送一个SYN包，消息序列号seq为随机数A，请求主动打开\n2. Server收到一个合法的SYN包后，将该包放入SYN队列中，返回一个SYN/ACK，ACK为A+1，消息序列号seq为随机数B\n3. Client收到SYN/ACK包后，发送一个ACK为B+1的包，消息序列号seq为A+1。然后Client的connect函数返回成功。当Server收到这个ACK包后，把请求帧从SYN队列移出，放到ACCEPT中，如果accept函数处于阻塞状态，可以被唤醒来从ACCEPT中取出ACK包，重新创建一个新的用于双向通信的sockfd，并返回\n\n三次握手的目的是为了防止已失效的连接请求报文段传送到了服务器，因而产生错误，也为了解决网络中存在延迟的重复分组。例如，Client发出的第一个SYN包没有丢失，而是在某个网络节点长时间的滞留了，以致延误到Client连接释放后的某个时间才到达Server。本来这是一个已失效的报文段，但Server收到后并不知已失效，而是当作Client的连接请求来处理，于是向Client发出确认报文段，同意创建连接。假设不采用三次握手，那么只要Server发出确认，新的连接就在Server创建了。由于Client并没有发出创建连接的请求，因此不会处理Server发过来的确认包，也就不会向Server发送数据。但是在Server端新的传输连接已经创建，并一直等待Client发来数据，这样便会一直占用Server的资源，造成浪费。采用三次握手可以防止这种情况的发生。\n\n就像你去医院看病一样，你（Client）在大厅挂了一个号（SYN），等到医生（Server）拿到病人的号后，他需要对着等候区喊一声（ACK/SYN）：253号病人在不在？你大声的回一声（ACK）：在！这个时候医生才能给你看病。如果等医生喊的时候，你已经提前有事走了，那么就不用再在你身上花时间了，毕竟医生很忙。两次握手就像是医生拿到病人的号后喊了一声：253号病人该你了，就开始准备相关的资料等你来，但是你已经离开了，医生并不知情，就只能一直等，等一个等不来的人。而四次握手、五次握手，就相当于，在你回答了一声：在，之后医生又问：253号病人在不在？你说：在，医生又问：253号病人在不在？你接着说：在。可以是可以，但没必要。\n\n#### 插播：seq和ack\n这里插播seq和ack的说明，seq以一个随机数开始，叫做ISN（之所以随机是为了克制TCP序号预测攻击），它是一个32位的无符号数。每个数据包在头信息中都会带着seq和ack，seq表示自己成功发送的数据量，而ack表示自己成功接收的有序字节的最大字节量。这里要用seq和ack减去ISN，这个时候才表示真实数据数量，这个在WireShark里叫做相对seq，relative sequence number。\n\n这里强调有序是因为存在丢包的情况，比如发送方发了1，2，3，4，5个包，但是包3在路上丢了，所以接收方回复包4和包5的ack都是2。\n\nseq表示自己成功发送的数据，所以每个包中都是有实际用处的。但是ack并不是在每个包中都会用到，比如建立连接时的第一个包，这个时候连接还未建立，所以谈客户端收到多少来自服务器的数据是没有意义的，因此在标识位用了一个bit来标识ack是否有效。\n\nack表示自己成功接收的数据量，每次收到对方的seq后，如果可以正确处理（这里要考虑异常情况，比如上面的丢包情况，这时候则不能正确处理，要等着丢失的包），则更新ack，表示已经成功接收这么多的数据，然后将ack确认回复给发送方。\n\nseq表示自己成功发送的数据量，每次收到对方的ack后，就会更新自己的seq，表示这么多字节的数据已经成功发送。\n\n#### 3.2 握手异常情况\n1. 客户端第一个SYN包丢了\n这种情况下，服务器不知道客户端曾经发过包，在TCP协议中，某端的一组请求-应答中，在一定时间范围内，只要没有收到应答的ACK包，无论是请求包对方没有收到，还是对方的应答包自己没有收到，均认为是包丢了，都会触发超时重传机制。所以此时会进入重传SYN包，根据协议，会尝试三次，间隔分别为5.8s，24s，48s，共76s左右，而大多数伯克利系统建立一个连接的最长时间，限制为75s。也就是说，第一个SYN包丢了，会重传，最长重试时间是75s。\n\n2. 服务器收到SYN，回复的SYN/ACK包丢了\n这种情况，从客户端来看，会认为是SYN丢了没发过去，处理方式就是上面1中所说的。对于服务器而言，发送完SYN/ACK后，在超时时间内没有收到ACK包，也会触发重传，此时服务器处于SYN_RCVD状态，依次等待3s，6s，12s后，重新发送SYN/ACK包。\n这个重传次数，不同的操作系统有不同的配置，Linux中默认重试次数是5次，重试间隔从1s开始倍增，1s，2s，4s，8s，16s，共31s。第5次发送完会等待32s才认为第5次也超时了，所以，一共需要31s+32s=63s，TCP才会断开这个连接。使用TCP的三个参数来调整行为：tcp_synack_retries减少重试次数；tcp_max_syn_backlog 增加SYN连接数量；tcp_abort_on_overflow 决定超出能力时的行为。\n同时由于客户端没有收到SYN/ACK，也会重传，当客户端重传的SYN被收到后，服务器会立即重新发送SYN/ACK包。\n\n3. 客户端最后一次回复的ACK包丢了\n发送完ACK后，客户端进入ESTABLISHED状态，服务器因为收不到ACK会走重传机制。客户端进入ESTABLISHED状态后，则认为连接已建立，会立即发送数据，但是服务器因为没有收到最后一个ACK，依然处于SYN_RCVD状态。那么，现在的问题是，处于SYN_RCVD的服务器，收到客户端的数据包后如何处理呢？有些资料写，此时服务器会直接回复RST包，表示服务器错误（我都还没建立连接，数据咋都发过来了），并进入CLOSE状态。但是，试想一下，服务器还在通过三次握手确定对方是否真实存在，此时对方的数据已经发过来了，那肯定是存在的。\n实际情况是，处于ESTABLISHED状态下的客户端，开始发送数据时，会带上ACK，所以即便是一个单独发ACK的包丢了，服务器在收到这个最新的包时，也能通过里面的ACK，正常进入ESTABLISHED状态。\n\n4. 客户端故意不发最后的ACK\n上面几种异常，都是客观因素导致，比如网络环境差等，而这种情况，就是故意而为之了。服务器发送完SYN/ACK后，收不到客户端的ACK，它会认为自己发出去的包丢了，就会走异常2的逻辑，进入重传，根据上面所说我们可以知道，此时这个连接处在服务器在listen时创建的SYN队列中。如果短时间内有大量这样的请求，SYN队列就会被占满，此时再来新的SYN请求，服务器就会自动丢弃，这就是所谓的SYN FLOOD攻击。针对这种情况，现在主要有两种应对方案，\n一个是syn cookie方案，在收到SYN包后，服务器根据一定的算法，以数据包的源地址、端口号等信息作为参数计算出一个cookie值作为SYN/ACK包的序列号发给客户端，但并不立即分配资源，等到收到ACK包，重新根据数据包的源地址、端口计算该包的确认号是否正确，正确则建立连接，否则丢弃。\n另一个方案是SYN Proxy防火墙，服务器防火墙会对收到的每一个SYN包进行代理和回应，并保持连接状态，等到发送方将ACK返回后，再重新构造SYN包发送到服务器，建立真正的TCP连接。\n\n#### 3.3 资源使用\n主机收到一个TCP包时，用两端的IP地址和端口号来标识这个TCP包属于哪个session，使用一张表来存储所有的session，表中的每条称作Transmission Control Block（TCB），tcb结构定义包括连接使用的源端口、目的端口、目的ip、序号、应答序号、对方窗口的大小、己方窗口的大小、tcp状态、tcp输入/输出队列，应用层输出队列、tcp的重传有关变量等。对于不能确认的包、接收但还没读取的数据，都会占用系统资源。\n\n#### 3.4 数据传输\n在TCP的数据传送状态中，很多重要的机制保证了TCP的可靠性和强壮型，它们包括：使用序号，对收到的TCP报文段进行排序以及检测重复的数据，使用校验和检测报文段的错误，即无错传输，使用确认和计时器来检测和纠正丢包或延时，流控制，拥塞控制，丢包重传等。\n\n#### 3.5 重传机制\nTCP为了实现可靠的传输，实现了重传机制，最基本的重传机制，就是超时重传，即在发送数据报文时，设定一个定时器，到达超时时间后还没有收到应答报文，就会重发该报文，那么这个时间设置多少合适呢？如果比较小，那很有可能数据没有丢失只是慢，就触发重传了，如果设置较大，那就会造成等待过长。一个数据包发出去来回的时间，即数据包的一次往返时间，叫做RTT（Round-Trip Time）。超时重传时间RTO（Retransmission Timeout），一般情况下略大于RTT，意思是在一个来回的时间内还没收到应答，发送发就重发。\n\n但是，实际情况是，RTO就是在RTT的基础上计算出来的，毕竟由于网络不是稳定不变的，所以RTT也是一直在变的，这个公式，叫做Jacobson/Karels算法，主要利用平滑移动的思想，具体不展开了。\n\n除了超时重传，还有快速重传机制，毕竟超时重传中每次都要等待RTO后才会触发重传，相比于此，快速重传则是基于接收端反馈的ACK来触发重传，接收方每次的应答包里ACK告知的是最大的有序报文段，当出现某个包丢失时，ACK就会卡在丢失包的前一个包，当发送方连着收到三个重复冗余的ACK后，也就是连着收到四个一样的ACK，就知道这个ACK后面的包丢失了，此时便会触发快速重传，重发丢失报文，而不用等待RTO。但这种方式会有个问题，因为发送方是连着发送多个包给接收方，发送方在收到3个冗余的ACK后，只知道接收方收到的最大有序报文是ACK，但不知道ACK之后有哪些收到了、哪些没收到，那么重传的时候，是只发送ACK后紧邻着的包，还是把ACK后面的所有的包都发一遍呢？\n\n于是，又有了一种重传方式，带选择的快速重传SACK（Selective)，它的机制就是，在快速重传的基础上，接收端返回最近收到的报文的序列号范围，这样发送方就知道接收方哪些数据没收到，很清楚就能知道需要重传哪些数据了，SACK标记是加在TCP头部的选项字段里面的。\n\n除此之外，还有一种，D-SACK，Duplicate SACK，即重复SACK，在SACK的基础上做了一些扩展，主要用来告诉发送方，有哪些数据自己重复接受了。目的是帮助发送方判断，是否发生了包失序、ACK丢失、包重复或伪重传，让TCP可以更好的做网络控流。\n\n#### 3.5 滑动窗口\nTCP发送一个数据，需要收到确认应答后，才会发送下一个数据，这样有个缺点，就是效率比较低。为了解决这个问题，TCP引入了窗口，它是操作系统开辟的一个缓存空间，窗口的大小表示无需等待确认应答，而可以继续发送的数据的最大值。\n\nTCP头部有个字段叫win，16位，它告诉对方本端的TCP缓冲区还能容纳多少字节的数据，这样对方就可以控制发送数据的速度，从而达到流量控制的目的。直白讲就是，一个包一个包发送太慢，那就多发几个，但是发的太多了，接收方可能处理不了，多出来的就被丢弃了，这样就白发了，所以，接收方在每次返回ACK的时候，顺带告诉发送方自己这边还剩下的窗口大小，这样发送方就可以根据这个窗口大小来决定发送多少数据了。\n\n#### 3.6 拥塞控制\n拥塞控制是作用于网络的，防止过多的数据注入到网络中，避免出现网络负载过大的情况，它的目标是最大化利用网络上瓶颈链路的带宽。它和流量控制的区别是，流量控制是作用于接收方，根据接收方的实际接受能力控制发送的流量，防止数据段丢失。\n\n发送方维护一个拥塞窗口（congestion window）的变量，用来估算在一段时间内这条链路可以承载和运输的数据的数量。它的大小代表着网络的拥塞程度，并且是动态变化的，为了达到最大的传输效率，最简单的方法就是不断增加传输的数据量，一直到出现丢包，实际上，拥塞控制主要有这几种算法：慢启动、拥塞避免、拥塞发生和快速恢复。\n\n慢启动，在TCP建立连接之后，一开始不要发送大量的数据，而是先探测一下网络的拥塞程度，由小到大逐渐增加拥塞窗口的大小，如果没有出现丢包，每收到一个ACK，就将拥塞窗口cwnd大小加1，单位MSS（max segment size）。每轮次发送窗口增加一倍，呈指数增长，如果出现丢包，拥塞窗口就减半，进入拥塞避免阶段。\n- TCP连接完成，初始化cwnd=1，表示可以传一个MSS单位大小的数据\n- 每当收到一个ACK，cwnd就加一\n- 每当过了一个RTT，因为每个ACK都会加1，所以cwnd就会增加一倍，呈指数增长\n\n但是，为了防止swnd增长过大引起网络阻塞，还需要设置一个慢启动阈值（slow start threshold）状态变量，当cwnd到达该阈值后，进入拥塞避免算法。一般来说，慢启动阈值是65535字节，cwnd到达阈值后\n- 每收到一个ACK，cwnd = cwnd + 1 / cwnd\n- 当每过一个RTT时，cwnd = cwnd + 1，呈线性增长\n\n当网络拥塞发生丢包时，会出现两种情况\n- RTO超时重传\n- 快速重传\n如果是RTO超时重传，就会使用拥塞发生算法\n- 慢启动阈值 = cwnd / 2\n- cwnd = 1\n- 进入新的慢启动过程\n如果是快速重传\n- 拥塞窗口cwnd = cwnd / 2\n- 慢启动阈值= cwnd\n- 进入快速恢复算法\n快速重传和快速恢复一般同时使用，快速恢复算法认为，还有3个冗余ACK收到，说明网络也没那么糟糕，所以没有别要想RTO超时那么反应强烈\n- cwnd = 慢启动阈值 + 3\n- 重传重复的那几个ACK（即丢失的那几个数据包）\n- 如果再收到重复的ACK，那么cwnd = cwnd + 1\n- 如果收到新的ACK后，cwnd = 慢启动阈值，表明恢复过程结束，再次进入拥塞避免算法，即线性增长\n\n#### 3.7 Nagle算法和延迟确认\nTCP/IP协议中，无论发送多少数据，总是要在数据钱带上协议头，同时，接收方收到数据，也需要发送ACK确认，为了尽可能利用网络带宽，TCP总是希望尽可能发送足够大的数据，Nagle算法便是为了发送尽可能大的数据块，避免网络中充斥着许多小数据块。基本定义是：任意时刻，最多只能有一个未被确认的小段，小段指的是小于MSS尺寸的数据块，未被确认指的是一个数据块发出去后，没有收到对方发送的ACK确认包。\n\n延迟确认是指，在接收方收到数据包后，如果暂时没有数据要发给对端，它可以等一段时间再发送确认包（Linux默认是40ms），如果在这段时间内刚好有数据要传给对端，ACK就随着数据包一起传输，如果超时后没有数据要发送，就单独发送ACK，避免对方以为丢包。有些场景不能延迟发送确认，比如出现乱包，要及时发送ACK告知\n\n一般二者不能同时使用，一个是延迟发送数据包，一个是延迟发送确认，二者一起会造成更大的延迟，产生性能问题。\n\n#### 3.8 保活定时器\n根据TCPI/IP协议的描述，TCP连接建立后，如果双方都没有通信。连接可以一直保存下去，例如中间路由器崩溃或者中间的某条线路断开，只要两端的主机没有被重启，连接就一直被保持着。TCP是面向连接的，不是说两个主机之间一直存在一个连接，而是在各自的主机上面分配了一些资源，如内存，以及上面提到的session表，来存储对端的一些信息，连接断开，对于端点则是意味着清理掉这些连接信息，释放掉所占用的资源。所以，如果连接中客户端突然掉线，服务器就需要能够感知这种变化，然而，TCP规范中并未规定连接的保活功能。\n\n尽管TCP协议中未做要求，但是在很多TCP协议的实现中，却提供了保活定时器。保活定时器一般配置的时间是2个小时，即服务器每2个小时就会想客户端发送探查消息，如果收到客户端的反馈消息，则在等2个小时再发，如果等不到反馈，则再等75s再发一次，这样连续发送10次，如果10次都没有收到反馈，就认为客户端异常断开了，此时，TCP层的程序就会向上层应用程序发送一条连接超时的反馈。\n\n由于TCP的很多实现中，保活定时器的时间比较长（一般大于2个小时），在实际的服务器开发中，很难利用该时间来判断客户端是否断开连接，因此，服务器程序多是在上层自己提供保活功能，常见的有，心跳连接，或者ping/pong消息等。\n\n#### 3.9. 终结通路\n连接终止使用了四次挥手过程。\n- 由客户端发起FIN请求，发出FIN后，客户端从ESTABLISHED进入FIN-WAIT-1状态，wait1，就是在等服务器的ACK\n- 服务器收到客户端的FIN后，回复ACK，并从ESTABLISHED进入CLOSED-WAIT状态，开始做一些断开连接前的准备工作。客户端收到ACK后，wait1结束，进入到FIN-WAIT-2状态，wait2是在等服务器的FIN\n- 服务器完成断开准备后，发送FIN/ACK给客户端，请求断开连接，服务器进入LAST-ACK状态，也就是等待最后一个ACK\n- 客户端收到FIN/ACK后，回复ACK，然后进入TIME_WAIT状态，等待2MSL（max segment lifetime）的等待，之后进入CLOSED状态。服务器收到ACK后进入CLOSED状态\n\n需要四次挥手的原因在于，双方都需要发送FIN表示可以断开，同时接收对方发的ACK，来保证自己和对端状态正确。而客户端想要断开的时候，服务器不一定准备好，所以服务器回复的ACK和自己要发的FIN没法合并，要先发ACK，等到自己准备好之后再发FIN/ACK，这样一来就是四次了。而握手只需要三次是因为，服务器的ACK和SYN可以合并，这样便减少一次。\n\n为什么服务器不需要等2MSL，而客户端需要等呢？状态同步是通信的首要基础，服务器给客户端发送了FIN，当它收到客户端发来的ACK时，对于服务器来说，他们双方都知道了服务器要关闭这件事，状态同步了，那么服务器就可以CLOSED。那么对于客户端来说呢，它在发出ACK之后，并不知道服务器是否成功接收，所以有两种可能\n- 服务器没收到自己发的ACK，那么服务器在等待超时后，会重传FIN\n- 服务器收到了自己发的ACK，那么服务器会关闭，不会再发任何消息\n不管哪种情况，客户端都要等，要取两种情况等待时间的最大值，以应对最坏的情况发生，这个最坏的情况是：\n- 去向ACK消息最大存活时间MSL + 来向FIN消息的最大存活时间MSL\n也就是客户端需要等待的2MSL。\n\n如果不等，客户端释放的端口可能会重连刚断开的服务器端口，这样依然存活在网络里的老的TCP报文段可能与新TCP连接报文段冲突，造成数据冲突，为避免此种情况，则需要耐心等待网络中老的TCP连接的活跃报文段全部超时无效。\n\n#### 3.10 四次挥手异常情况\n1. 客户端的FIN包丢了\n这个和前面的SYN包丢失类似，客户端会触发超时重传。对于服务器来说，客户端发来的FIN没有收到，就没有任何感知。会在一段时间后，断开连接。\n\n2. 服务器第一次回复ACK包丢了\n此时客户端没有收到ACK，会触发超时重传FIN，服务器收到后，会立即再重传。而此时，服务器已经处于CLOSED-WAIT状态，开始做断开连接前的准备工作，准备好之后，会发送FIN/ACK，这个消息是带了之前ACK的响应号的。只要这个消息没丢，客户端可以凭借FIN/ACK包中的响应号，直接从FIN-WAIT-1状态进入TIME-WAIT状态，开始2MSL的等待。\n\n3. 服务器发的FIN/ACK丢了\n服务器会在超时后触发重传，此时客户端有两种情况，要么处于FIN-WAIT-1状态（之前的ACK也丢了，wait1是在等ACK，还没等到），要么处于FIN-WAIT-2状态（收到了ACK，在等FIN），收到服务器的重传来的FIN后，发送ACK给服务器，然后开始2MSL的等待。\n\n4. 客户端最后的ACK丢了\n客户端回复ACK后，会进入2MSL的TIME-WAIT等待，服务器因为没有收到ACK，会重试一段时间，直到超时服务器主动断开。在服务器重试的期间内，客户端可能释放了端口，此时如有新的客户端连接服务器，就会收到服务器发的重试消息FIN，这时客户端会回复RST，服务器收到RST后，会复位状态。\n\n5. 客户端收到ACK后，服务器掉线了\n客户端收到ACK后，进入了FIN-WAIT-2状态，等待FIN，如果服务器不在了，那么这个FIN将永远等不到。在TCP协议中，是没有对这个状态的处理机制的，但是操作系统会接管这个状态，例如在Linux下，可以通过tcp_fin_timeout参数，来对这个状态设定一个超时时间。需要注意的是，当超过tcp_fin_timeout的限制后，客户端的状态不是切换到TIME_WAIT，而是直接进入到CLOSED状态\n\n6. 客户端收到ACK后，客户端掉线\n客户端掉线后，服务器发的FIN/ACK就得不到应答，会不断的走超时重传机制，在超过一定时间后，服务器主动断开。如果在重试期间，有新的客户端接入这个连接，发送SYN给服务器，表示想要建立连接，此时这个SYN会被服务器忽略，并直接回复FIN/ACK，新客户端收到FIN/ACK后不会认的，就会给服务器发送RST，服务器收到RST，会复位状态\n\n","tags":["TCP"],"categories":["网络协议"]},{"title":"正则环视","url":"/2022/04/5f12538f9d0e/","content":"记录一下常用又常忘的正则环视。\n\n<!--more-->\n\n### 1. 引言\n\n正则表达式，通常用来表示一种匹配规则，搜索出匹配的字符串，然后对该字符串做一些操作。环视，是正则表达式式中的一种语法，它用来判断字符，但是不占位置。还有种叫法，叫断言。\n\n### 2. 类型\n它分为先行（lookahead）和后行（lookbehind），以及正向（positive）和逆向（negative），先行后行的意思是判断前面的位置还是后面的位置，正向和逆向的意思是判断是或者不是，两两组和就有了四种类型。\n\n正则表达式引擎会从前向后扫描字符串，检查指针还未曾达到的地方，就叫做先行，即检查右边的字符，检查已经扫的字符时，叫做后行，即指针左侧的字符，这是先行和后行的由来。\n\n- (?=pattern) 正向先行，检查右侧相等\n- (?!pattern) 负向先行，检查右侧不想等\n- (?<=pattern) 正向后行，检查左侧相等\n- (?<!pattern) 负向后行，检查左侧相等\n\n### 3. 举例\n举几个例子，用下面的字符串\n```txt\n12abc34 56abc78\n```\n\n- 先行，正向（右侧相等），比如，想要匹配abc，并且只配置右侧是34的abc\n```reg\nabc(?=34)\n```\n这样便可以匹配到第一个abc，注意没有后面的34，因为断言不占位置，它只是对匹配内容的一种限制\n\n- 先行，逆向（右侧不相等），比如，匹配abc，但是不想要后面是34的abc\n```reg\nabc(?!34)\n```\n最后的结果是，匹配到了后面的abc\n\n- 后行，正向（左侧相等），比如，还是匹配abc，想要左侧是12的abc\n```reg\n(?<=12)abc\n```\n匹配到了前面的abc，同样只是abc，不包含12\n\n- 后行，逆向（左侧不相等），比如，依然还是abc，这次不想要左侧是12的abc\n```reg\n(?<!12)abc\n```\n这样就匹配到了后面的abc\n\n### 4. 在线工具\n推荐两个直观的在线校验工具，写完的放到上面，很直观的就知道是不是自己想要的了\n- [regexr](https://regexr.com/)\n- [regex-vis](https://regex-vis.com/)\n\n另外，经regexr友情提醒，不是所有的浏览器都支持后行逆向，但是有哪些浏览器它没说，所以要谨慎使用。","tags":["正则"],"categories":["正则"]},{"title":"Android之ConstraintLayout","url":"/2022/04/b5cec7344fde/","content":"ConstraintLayout，约束布局，是现在Android里面最常用的布局方式，也是系统默认的布局方式，说一说它的日常用法。\n\n<!--more-->\n### 1. 简介\n约束布局的出现，主要为了减少视图的层级深度，即减少嵌套。显而易见的是，层级深度越浅，绘制效率越高。之前常用的布局，有LinearLayout线性布局，RelativeLayout相对布局，FrameLayout层级布局，有时为了实现UI给出的页面效果，一个页面内ViewGroup套ViewGroup，ViewGroup里面再套个View，散发着正宗的俄罗斯套娃血统，效率低，代码量也大，\n\n### 2. 边界\n约束布局下的元素，都是本着和谁对齐的基本理念来设定位置，比如水平方向和谁的边界对齐、垂直方向又要和谁的边界对齐，两个方向都确定了，那么这个元素的位置自然就确定了，这其实就是在确定元素四条边界的位置，确定了四条边界的位置，那么这个元素的位置和大小也便都确定了。\n\n水平方向有两个边，左边和右边，即Start和End，垂直方向也有两个边，上边和下边，即Top和Bottom。\n\n每个方向，可以只指定一个边界，也可以两个边界的位置都指定。一个方向上，如果只限定一条边界的位置时，那么这个元素就会靠此边界对齐，比如水平方向只限定了右边界的位置，那么这个元素水平方向上就会紧贴着右边界，垂直方向也是一样的道理，同时，如果一个方向限定了两个边界的位置，那么这个元素就会在这两个边界间居中，比如限定一个元素上边界和父布局对齐，下边界也和父布局对齐，那么此元素在视觉上的效果就是，垂直方向处于父布局中间。\n\n### 3. 宽度，高度\n从上面的介绍可以看出，因为约束布局里的子元素设定的四条边界的位置，所以在设定宽度和高度时，没有match_parent这个值，只有0dp和wrap_content，但是在布局文件里写match_parent是不会报错的，只是系统在计算的时候会把parent_match替换成0dp。0dp的意思是，元素会充满该方向的边界约束，wrap_content为按需填充。\n\n这里有个问题，如果在一个方向上，只设定一个边界，但是设为0dp，那么会怎么样呢？如果设定了两个边界，那么0dp很好处理，直接填充两个边界间的距离即可，这个很好理解，只设定一个边界时，结果就未可知了，如果推断不出来时，那就是0dp，页面上就看不到了，如果能从其他参数判断出来，则可能得到预期的结果。所以，当需要设定为0dp时，就设定两个边界，最为稳妥。\n\n### 4. 边界对齐\n上面提到，约束布局里设定边界时，是指定和谁对齐，这里的对齐是指，水平方向边界只能和水平方向的边界对齐，垂直方向的边界也只能和垂直方向的边界对齐，而每个方向存在两个边界，两两组和，就有了多种对齐的选择\n- 上边界和目标元素的上边界对齐\n- 上边界和目标元素的下边界对齐\n- 下边界和目标元素的上边界对齐\n- 下边界和目标元素的下边界对齐\n这是垂直方向的，水平方向也是一样的道理，两两组和也会有四种选择。下面是其中的几个属性，属性的值写目标元素的id，如果是父布局就写parent。\n```xml\n <ImageView\n     android:layout_width=\"0dp\"\n     android:layout_height=\"0dp\"\n     android:src=\"@drawable/image\"\n     app:layout_constraintBottom_toBottomOf=\"parent\"\n     app:layout_constraintEnd_toEndOf=\"parent\"\n     app:layout_constraintStart_toStartOf=\"parent\"\n     app:layout_constraintTop_toTopOf=\"@id/title\" />\n```\n\n以上就是基本使用，是的，用这些就能实现线性布局、相对布局等的效果了。下来说一说约束布局独有的特点\n\n### 5. GuideLine\nGuideLine，引导线，这个在布局上是看不到的，但是可以帮助我们来指定其他空间的位置，比如，不管在哪种尺寸的屏幕上，你都需要在屏幕上30%的位置显示一行文字，在其他布局中，需要每次手动获取屏幕高度，计算出目标位置，然后再把文字放到这个位置上。但是在约束布局中，是用GuideLine就可实现。\n\n引导线有两个方向，水平方向和垂直方向。此外，它有两种模式，百分比模式，和距离模式\n- 百分比模式，percent指定的是百分比，水平方向时指距离左侧，垂直方向时指距离顶部\n```xml\n<androidx.constraintlayout.widget.Guideline\n    android:layout_width=\"0dp\"\n    android:layout_height=\"0dp\"\n    android:orientation=\"horizontal\"\n    app:layout_constraintGuide_percent=\"0.3\" />\n```\n- 距离模式，begin和end设定一个就好，两个都设定时begin生效end无效\n```xml\n<androidx.constraintlayout.widget.Guideline\n     android:layout_width=\"0dp\"\n     android:layout_height=\"0dp\"\n     android:orientation=\"horizontal\"\n     app:layout_constraintGuide_begin=\"30dp\"\n     app:layout_constraintGuide_end=\"30dp\" />\n```\n\n### 6. 位置百分比\n```xml\n <ImageView\n        android:layout_width=\"wrap_content\"\n        android:layout_height=\"wrap_content\"\n        android:src=\"@drawable/home_bg\"\n        app:layout_constraintBottom_toBottomOf=\"parent\"\n        app:layout_constraintEnd_toEndOf=\"parent\"\n        app:layout_constraintHorizontal_bias=\"0.0\"\n        app:layout_constraintStart_toStartOf=\"parent\"\n        app:layout_constraintTop_toTopOf=\"parent\"\n        app:layout_constraintVertical_bias=\"1.0\" />\n```\n上面有说到，当指定了一个方向的两个边界时，这个控件就会在边界间居中对齐，这其实是默认值。还是上面那个例子，但是多了两个属性，一个是Horizotal_bias，一个是Vertical_bias，这两个属性的默认值都是0.5，意味着居中对齐。\n\n当给一个方向设定了两条边界的时候，并且该空间在这个方向还没有填充满，也就是有可以移动的空间，比如这个例子，图片的横向是填充父布局的，宽度设定为wrap_content，图片的实际宽度只有屏幕宽度的一半，所以剩下的宽度就是可以动的空间，那么就可以通过Horizontal_bias来设定它在水平方向的位置，默认值0.5是居中，0是居最左，1是居最右，垂直方向同理。\n\n当不存在可以动空间时，这个属性就不会生效，比如只设定了一个边界，或者设定了两个边界，但是填充满了。\n\n### 7. 宽高比\n```xml\napp:layout_constraintDimensionRatio=\"9:7\"\n```\n这个属性多用于控制图片的大小，当需要动态设定图片的宽度或者高度，但又不希望改变图片的原始宽高比，相比于原始的在代码中计算，使用这个属性就方便多了，首先明确的是，属性值中的比例是width:height，也就是宽高比。\n\n在ConstraintLayout中，元素的边长有2种情况，一种是设为0dp，一种是设定具体的值，当然wrap_content也算具体的值，既然是宽高比所以，那么就需要确定一个值，根据比例去算另一个值。系统在根据这个属性计算宽和高时，要考虑多种情况：\n- 高固定，款固定：二者都固定时，这个属性不会生效\n- 宽固定，高动态：根据宽度和比例计算高度\n- 高固定，宽动态：根据高度和比例计算宽度\n- 宽动态，高动态：这个时候要想元素设置最大的大小并且不超出约束边界，即可以完全显示出来，那么在计算最终边长时，就要根据约束边界的宽高比和属性值做比较了。\n\n说说两个都是动态时的情况，可以这么想，这个约束边界就以一块720x1280（9:16）的屏幕为准，也就是有一张图片完全填充屏幕，如果图片的宽高比是4.5:16时，那么就要以屏幕的高为基准计算宽，也就是高占满1280，用比例计算出宽占360，相反，要是以屏幕宽为基准，占满720，那么计算出来的高就是2560，超出边界范围了；同理，当图片的宽高比是18:16时，就要以宽为基准，占满720，计算出高为640。\n\n当然，也可以在属性值中手动指定谁是需要动态计算的，像下面这样\n```xml\napp:layout_constraintDimensionRatio=\"h,9:7\"\n```\n这样写的意思就是说，h是动态的，所以要先计算出来w，然后根据9:7再计算出h。\n\n总结起来就是，比例值是宽高比，谁是固定的，就用谁去计算另一个。两个都不固定时，如果没有指定谁是动态计算的话，那么就以不超出约束的边为基准的原则，计算边长。\n\n### 8. 几点说明\n- 当宽或高设定为wrap_content，并且设定了两条边界时，此时边界的作用是用来限定控件的位置，而不是宽或高，也就说，宽或高是有可能超出边界的范围的。\n- 如果有重叠，布局文件中写在下面的控件会盖在上面的空间，这一点和FrameLayout类似。","tags":["Android","ConstraintLayout"],"categories":["Android"]},{"title":"清理MacOS","url":"/2022/04/0ca8f6faeb24/","content":"MacOS的系统清理，一直是个两极分化严重的话题。一边是硬盘小的人，内心极度热爱，一边是硬盘大的人，表示漠不关心。\n\n<!--more-->\n\n很显然，我就是前者，总共两百多的硬盘，用起来总是感觉紧紧巴巴吧，计划着过日子，能不装的就不装，能删除的就删除。\n\n关于清理，市面上做得好的都是收费的，最便的也要几百块钱一年，在电脑清理上每年都投资上几百块钱，我觉得，没必要的事。本着互联网开放的精神，选了一个评论稍好的，CleanMyMac X，很容易就便找到了破解版，怎么说呢，就是基本满足需求吧，确实可以扫描出来一些应用缓存文件、系统日志文件。但还是不够，随着时间流逝，可用空间每天都在减少，想着定然是有着它没有扫描到的路径，如果可以直观的看出来每个目录的大小，即便是自己清理，也是大为方便的，所以，在用这个软件的同时，我要需要搭配着命令行\n```shell\ndu -d 1 -h\n```\n- du，就是disk usage，磁盘使用情况的意思，这个命令会把当前目录下的所有文件，以及所有子目录下的所有文件，全部列出来，毫无可读性可言，所以需要加参数限定\n- d，depth，控制深度，1表示只罗列第一层\n- h，human，以人类可读的数据形式展示大小，直观且清晰，不然默认以字节为单位\n\n列出来后，过滤出哪个需要删除，删除即可。前提是，要知道每个目录是干嘛的，也就是归属于哪个应用，用来存储什么数据的，这个要求稍微有点门槛，如果删错了可能导致一些神奇的后果，为避免此情况，我总结了3个凡是\n- 凡是不认识的，不要删\n- 凡是带着apple的，不要删\n- 凡是删不掉的，不要删\n\n按此行事，一直以来也算是相安无事，它生成它的，我删除我的，能开机，能关机，一切正常。\n\n今天偶然发现了一个命令行工具，ncdu，这个在上面的这个du命令上，提供了一个可视化的操作窗口，大大提高了效率，优化了体验，节省了时间，安装只需一行命令\n```shell\n$ brew install ncdu\n```\n执行完，可能失败报错，反正我就是，报错信息里写的是没有编译好的，需要自己编译，还把方式写了出来\n```shell\n$ brew install --build-from-source ncdu\n```\n不出意外，等一会就好了，总共一百多K的样子\n\n使用的时候，输入ncdu并执行，然后就会把当前目录的所有文件和文件夹的大小列出来，移动选中光标使用键盘上的上下左右，或者用HJKL，和Vim倒是一样的方式，按d，就是删除，删除之前会弹出一个确认弹窗，这个弹窗可以关掉，但是最好不要关，人嘛，难免会有手滑的时候，要知道命令删除的文件是没有垃圾桶的，所以要再确认一次，因为这一删，那就是一辈子\n- 移动，上下左右，HJKL也可以\n- 删除，d\n- 占比显示，g\n- 排序，n：name，s：size，C：items\n- 帮助，？\n\n开始我还在想，这个ncdu的nc是什么意思呢，是代号吗？不像，倒是觉得像是脑残的缩写，意思就是即便来了个脑残，他也能玩得明白，简短的两个字母，却表达出了作者的自豪之情，好像也说得过去，很合情，但是不合理呀，起个名字跟闹着玩的一样。查了一下，原来是NCurses，curses-based，curses就是Linux下的图形库，是我想太多，打扰了，告辞。","tags":["MacOS"],"categories":["MacOS"]},{"title":"Hexo+Next主题配置","url":"/2022/04/3fdb8c08a69f/","content":"[Hexo+Github快速搭建个人博客](https://oynix.github.io/2021/09/33313fbab399/)\n这是之前写的一篇文章，说了怎么使用Hexo在Github上免费搭建一个个人博客，这篇文里面只写了博客从0到1的过程，这篇再来写一写从1到正无穷，博客的个性化设置。\n<!--more-->\n\n### 1. hexo的配置文件\n在博客的根目录，也就是Node.js的项目根目录下，有个名字是_config.yml的文件，这个是hexo的配置文件。在这个文件里可以配置网站的常规配置，比如主标题，副标题，语言，域名，等等，这个文件不用解释太多，因为里面每一项都有很详细的解释，只要打开看一眼便知。\n\n这里面有一项是theme，是用来配置主题的，在这里写主题的名字就可以，主题需要下载到根目录下的themes目录下，然后通过名字就会去这个目录下找对应的主题，所以名字不能写错，我用的next主题。\n\n### 2. 主题的配置的文件\n以我所用的next主题为例，在目录`themes/next/`下，也有个_config.yml文件，打开就可以看出来，这里的解释也很详细，而且都是中文，这对于国内的使用者算是相当友好了，这里面配置的都是一些个性化设置，比如图标，页脚，备案信息，颜色，大小，间距，等等，开始时用默认值就可以，可以在使用过程中不断优化、调整，形成一个自己喜欢的风格。\n\n### 3. 文章截断\n在首页上会按时间倒序展示所有的文章，如果不做处理，每篇文章的内容就会完整的显示出来，非常的不美观，按照往常的阅读经验，每篇文章只需要展示前面几行就可以了，所以需要在适当的地方截断，截断文章使用more标记\n```java\n<!--more-->\n```\n这个标记下面的内容就不会显示，除非点进到文章的详情。\n\n### 4. 增加左侧菜单\n左侧菜单就是指首页、标签、归档的那个栏目，如果默认的那几个满足不了设想需求，可以按需增加、删除，或者调整。菜单栏里的每个按钮，点击之后打开的都是一个页面，所以要想增加一个菜单，就要增加一个对应的页面。增加页面使用这个命令，\n```shell\nhexo new page 'message'\n```\n执行完之后，就会发现source目录下多了个message的目录，目录里又个index.md的文件，是的，刚刚的命令就是创建了这两个，如果不使用命令，也可以手动创建。假定message这个页面用来当作留言板用，现在页面有了，然后就是把它加到菜单栏里，打开next的配置文件，注意是next的，不是hexo的，在里面搜索menu关键词，就可以看到了，这个文件很长，每次想要配置哪个项，直接搜索关键字是最方便的，配置格式里面有说明，分隔符`||`前面的是路径，后面的菜单栏按钮前的小icon，icon去[这个网站](https://fontawesome.com)，然后把名字复制过来就可以\n```yml\nmenu:\n  home: / || fa fa-home\n  about: /about/ || fa fa-user\n  tags: /tags/ || fa fa-tags\n  categories: /categories/ || fa fa-th\n  archives: /archives/ || fa fa-archive\n  message: /message/ || fas fa-envelope-open-text\n```\n重新生成之后，发现菜单栏里已经多了一个按钮，但是按钮名字怪怪的，是英文单词message，也就是刚刚创建的文件夹的名字。这个的原因是，多语言，只要在配置一下多语言就可以了，我使用的是中文，所以需要打开next主题下的languages目录下的zh-CN.yml文件，在里面的menu下增加一个message，就可以了\n\n### 5. 增加评论\n打开next的配置文件，搜索关键词comments，可以看到它支持多种评论插件，changyan、disqus、disqusjs、gitalk、livere、valine。在这里，我用的gittalk，试了几个都要花钱，就这个是免费的，光这免费一点，就压过了所有，以绝对的优势胜出。稍微再往下滚几行，就会看到gittalk的配置了\n```yml\ngitalk:\n  enable: true\n  github_id: oynix # GitHub repo owner\n  repo: oynix.github.io # Repository name to store issues\n  client_id: xxxxxxxxxx # GitHub Application Client ID\n  client_secret: xxxxxxxxxxxxxx # GitHub Application Client Secret\n  admin_user: oynix # GitHub repo owner and collaborators, only these guys can initialize gitHub issues\n  distraction_free_mode: true # Facebook-like distraction free mode\n  # Gitalk's display language depends on user's browser or system environment\n  # If you want everyone visiting your site to see a uniform language, you can set a force language value\n  # Available values: en | es-ES | fr | ru | zh-CN | zh-TW\n  language:\n```\n它内部的流程就是，获取操作一个仓库的权限，然后每当有人留言的时候，就相当于给这个仓库提了一个issue，每篇文章下面展示的评论，其实就是所有issue中，和这篇文章相关联的issue。获取权限，打开Github首页，右上角个人信息里打开Settings，左侧菜单栏最下面有个Developer settings，进去就能看到OAuth Apps，创建一个新的OAuth App，Application name可随意写，Homepage URL和Authorization callback URL都填博客的域名就可以了，创建成功后把得到的client_id和client_secret填到上面gittalk的位置就可以了。\n\n### 6. 统计和分析\n通过第三方的统计分析插件，可以知道自己的网站的访问情况，比如今天有多少个人进来过，不做商业化的话，统计这数据就是图一乐。它支持多种三方渠道，比如Google Analytics、百度统计等，我加了一个GA的，还是老样子，打开next的配置文件，在里面搜索关键词google_analytics就可以看到，GA的比较好配置，在GA后台创建一个网页应用，把博客的域名填进去，然后把生成的id复制过来就可以了。而且，这个也是免费的\n\n### 7. 统计阅读人数\n还是那个标准，看谁是免费的，next也只支持了多个三方统计渠道，多数的路子都是你花钱买个云存储空间，然后调用他们提供的API接口，把访问数据传上去，就这么简单。但是有个插件特立独行，它把数据存到了本地，自然就不用花钱了，这就是busuanzi_count，还是在next的配置文件里\n```yml\nShow Views / Visitors of the website / page with busuanzi.\nGet more information on http://ibruce.info/2015/04/04/busuanzi\nsuanzi_count:\nenable: true\ntotal_visitors: true\ntotal_visitors_icon: fa fa-user\ntotal_views: true\ntotal_views_icon: fa fa-eye\npost_views: true\npost_views_icon: fa fa-eye\n```\n\n### 8. 开通打赏功能\n这个和现在的主流打赏方式类似，在文章底部有个按钮，点开就是收钱的二维码，next的配置文件里，搜索关键词reward，然后像下面这样\n```yml\nreward:\nwechatpay: /images/wechatpay.jpeg\nalipay: /images/alipay.jpeg\n```\n这两张图在next/source/images目录下，我只配置了这两个，还能配置别的，想配置什么收款方式就配置什么收款方式，但我觉得没有差别，至今尚未开张。\n\n### 9. 给文章添加通用结尾\n我在每篇文章最下面都加了这样一行\n```txt\n--------------完---------\n```\n在每篇文章结尾手动写上也不是不行，但是既然都是一样的，就可以配置到样式文件里。这种配置不在配置文件里写，需要稍微修改一下样式文件。在`next/layout/_macro`下有个post.swig文件，用个文本编辑器打开就可以看里面的内容，这个就是显示文章内容的，里面不是很长，可以清晰看到几个大大的标记\n```swig\n  {##################}\n  {### POST BLOCK ###}\n  {##################}\n\n    {#################}\n    {### POST BODY ###}\n    {#################}\n\n    {#####################}\n    {### END POST BODY ###}\n    {#####################}\n\n  {######################}\n  {### END POST BLOCK ###}\n  {######################}\n```\n成对出现的，很清晰吧，POST就是文章的意思，BODY中间夹着的部分就是我们写的文章，既然我想在文章后面加标记，那么加到END POST BODY后面就可以了，不需要懂swig，会一点html的语法知识就够用，在`_macor`目录下创建文件passage-end-tag.swig，里面写上\n```swig\n<div>\n    {% if not is_index %}\n        <div style=\"text-align:center;color: #ccc;font-size:14px;\">------------- (完) -------------</div>\n    {% endif %}\n</div>\n```\nis_index是在其他地方定义的一个变量，首页也会显示文章，文章详情页也会显示文章，用这个变量加以区分，当不是首页的时候，就加个div，这几行表达的就是这个意思，然后，在END POST BODY后面引用一下刚刚新建的这个文件，\n```swig\n    {#####################}\n    {### END POST BODY ###}\n    {#####################}\n    <div>\n       {% if not is_index %}\n       {% include 'passage-end-tag.swig' %}\n       {% endif %}\n      </div>\n```\n这几行表示，当不是在首页显示的时候，把刚才创建的这个文件包括进来，就这样，给每篇文章加个结尾的想法就实现了。\n\n### 总结\n就先说这么多吧，next的可配置修改项是在太多太多，同时还可以修改它的源码，相互配合，能玩出的花样层出不穷，具体的呢，还是要回到最初那句话，看自己有着什么样的个性化需求，只要能想到的，就尽管去改配置就好。","tags":["Hexo","Next"],"categories":["自建博客"]},{"title":"Android之FileProvider","url":"/2022/04/a19e8bb0ccff/","content":"FileProvider是ContentProvider的一个特殊子类，它通过为文件创建一个content://的URI，而不是file:///URI，来帮助应用间的文件安全分享。在Android 7.0及以上的系统中，尝试传递file:///URI可能会触发FileUriExposedException。\n\n<!--more-->\n一个content URI允许授权一个临时读写访问权限，当创建一个包含content URI的Intent时，就可以向其setFlags来增加权限。只要接收Activity的栈还存活，那么这个权限就是可用的，对于发送到Service的Intent，只要这个Service在运行，那么权限就一直是可用的。\n\n相比之下，为了控制file:///URI的访问，就不得不修改底层文件的文件系统权限。在改变权限之前，它会对任何一个应用来说都是可用的，这种级别的访问基本是不安全的。\n\ncontent URI 提供的文件访问安全级别的提高，使FileProvider成为Android安全基础设施的关键部分。\n\n### 1. 定义一个FileProvider\nFileProvider已经包含了基本的content URI生成功能，所以就不用再定义它的子类了，直接在XML中指定一个`<provider>`即可，其中`android:name`是固定的，`androidx.core.content.FileProvider`，`android:authorities`则是自己的域名加上fileprovider，`android:exported`设置为false，`android:grantUriPermissions`设置为true\n```xml\n<manifest>\n   ...\n   <application>\n       ...\n       <provider\n           android:name=\"androidx.core.content.FileProvider\"\n           android:authorities=\"com.mydomain.fileprovider\"\n           android:exported=\"false\"\n           android:grantUriPermissions=\"true\">\n           ...\n       </provider>\n       ...\n   </application>\n</manifest>\n```\n如果想重写FileProvider的行为，则继承FileProvider类，然后用全类名替换`<provider>`的name属性，即可\n\n### 2. 指定可用的文件\nFileProvider只能生成提前指定的目录下的文件的content URI。要想指定一个目录，则需要通过使用`<paths>`标签，在xml中指定它的存储区域和路径。下面这个例子，则是告诉FileProvider想要请求私有文件区域下名字为images的子目录的content URI\n```xml\n<paths xmlns:android=\"http://schemas.android.com/apk/res/android\">\n   <files-path name=\"my_images\" path=\"images/\"/>\n   ...\n</paths>\n```\n`<paths>`元素下，必须包含一个，或者多个`<files-path>`元素\n\n以下是所有可用的文件区域\n- Context.getFilesDir()下的子目录\n```xml\n<files-path name=\"name\" path=\"path\" />\n```\n- Context.getCacheDir()下的子目录\n```xml\n<cache-path name=\"name\" path=\"path\" />\n```\n- Environment.getExternalStorageDirectory()下的子目录\n```xml\n<external-path name=\"name\" path=\"path\" />\n```\n- Context.getExternalFilesDir(String)或者Context.getExternalFilesDir(null)下的子目录\n```xml\n<external-files-path name=\"name\" path=\"path\" />\n```\n- Context.getExternalCacheDir()下的子目录\n```xml\n<external-cache-path name=\"name\" path=\"path\" />\n```\n- Context.getExternalMediaDirs()下的子目录，注意，这个目录只在API 21+的设备上可用\n```xml\n<external-media-path name=\"name\" path=\"path\" />\n```\n\n`name=\"name\"`\nURI的路径片段，为了保证安全，子目录的名字被隐藏在了`path`属性中\n`path=\"path\"`\n分享的子目录的名字，name属性只是一个片段，path属性是真实的子目录名字。要注意，这个名字代表的是一个子目录的名字，而不是文件的名字，不允许通过名字分享一个单独的文件，或者使用通配符指定一个文件集合。\n\n必须为每个子目录指定一个`<paths>`元素，如下就是指定了两个目录\n```xml\n<paths xmlns:android=\"http://schemas.android.com/apk/res/android\">\n   <files-path name=\"my_images\" path=\"images/\"/>\n   <files-path name=\"my_docs\" path=\"docs/\"/>\n</paths>\n```\n\n将`<paths>`元素和它的子元素写到一个XML文件里，放到项目中，例如可以这样做，`res/xml/file_paths.xml`，然后将这个文件设置给`<provider>`，像下面这样\n```xml\n<provider\n   android:name=\"androidx.core.content.FileProvider\"\n   android:authorities=\"com.mydomain.fileprovider\"\n   android:exported=\"false\"\n   android:grantUriPermissions=\"true\">\n   <meta-data\n       android:name=\"android.support.FILE_PROVIDER_PATHS\"\n       android:resource=\"@xml/file_paths\" />\n</provider>\n```\n\n### 3. 为文件生成content URI\n为了把文件分享给其他应用，你需要生成一个content URI，就要通过FileProvider的getUriForFile方法获取一个URI，然后通过Intent传给其他应用，当其他应用拿到这个URI后，通过ContentResolver.openFileDescriptor就可以获得一个ParcelFileDescriptor\n```java\nFile imagePath = new File(Context.getFilesDir(), \"my_images\");\nFile newFile = new File(imagePath, \"default_image.jpg\");\nUri contentUri = getUriForFile(getContext(), \"com.mydomain.fileprovider\", newFile);\n```\n前面的结果，就是得到一个`content://com.mydomain.fileprovider/my_images/default_image.jpg`的URI\n\n### 4. 授予URI临时权限\n可以把权限授予给一个指定的package，也可以在Intent中包含权限。\n\n调用方法Context.grantUriPermission(package, Uri, mode_flags)来为content URI授予权限，mode_flags可以设为FLAG_GRANT_READ_URI_PERMISSION或者FLAG_GRANT_WRITE_URI_PERMISSION，也可以设置两个flag。这个权限会一直有效，直到调用了revokeUriPermission()方法，或者设备重启。\n\n当想把权限包含在Intent中时，\n- 调用Intent.setData()把URI设给Intent\n- 调用Intent.setFlags设置FLAG_GRANT_READ_URI_PERMISSION、FLAG_GRANT_WRITE_URI_PERMISSION，或者两个都设置。为了兼容4.1（API 16）和5.1（API 22）之间的设备，包括5.1，使用ClipData\n```java\nshareContentIntent.setClipData(ClipData.newRawUri(\"\", contentUri));\nshareContentIntent.addFlags(Intent.FLAG_GRANT_READ_URI_PERMISSION | Intent.FLAG_GRANT_WRITE_URI_PERMISSION);\n```\n- 将Intent发给其他应用，通常可用调用setResult()来完成\nIntent里权限在接收Activity栈活跃前都是可用的，当栈完成被销毁后，权限自动移除。授予给某个应用的一个Activity的权限，会自动扩展至该应用的其他组件。\n\n### 5. 将content URI提供给另一个应用\n有多种方式可讲content URI提供给客户端应用。一个常用的方式，客户端应用通过Intent启动你的应用里的一个Activity。作为回应，你的应用应该立即返回一个content URI给客户端应用，或者展示一个页面允许用户选择一个文件，这种情况下，一旦用户选择了一个问价，你的应用就可以返回这个文件的URI。在这两种情况中，你的应用都是通过setResult()返回一个Intent。\n\n还可以把content URI放到一个ClipData对象中，然后将这个对象添加到发送给客户端应用的Intent中，可通过调用Intent.setClipData()实现。当使用这种方式时，可添加多个ClipData对象到Intent中，每一个都有着它自己的URI，当通过Intent.setFlags()设置访问权限时，所有的content URI都将获得同样的权限。\n\n注意，Intent.setClipData()只在API 16及之后的平台上可用。如果需要在更早版本上的兼容性，应该一次在一个Intent里只发送一个conent URI。设置Intent的action为ACTION_SEND，然后通过调用setData()来添加URI。\n\n### 6. 总结\n妈呀，终于轮到我说话了。上面这些都是翻译的官方文档，本想用Google翻译一键转换，发现Google翻译并不是太懂Android官方写的文档，虽然Android也是Google的，同进一家门，不认自家人，所以只要自己动手，一句一句来，太累了。\n\n感觉老外写文档很详细，用简短的话来概括就是，为了安全，所以官方不再让用file:///，而是用content://来替代，因为后者可以更好的管理访问授权，要想分享文件，就要先把文件所在目录写到一个xml里，然后再提供一个FileProvider，如果没有特殊需求就用官方的就可以，然后后面的事，通过Intent来操作了。\n\n最后附上[文档地址](https://developer.android.com/reference/kotlin/androidx/core/content/FileProvider)。","tags":["Android","FileProvider"],"categories":["Android"]},{"title":"Java之synchronized关键字","url":"/2022/04/e7ef9e7b20bc/","content":"原计划写Java中的锁，但篇幅可能会过长，降低阅读性，所以先从synchronized这个关键字开始。\n<!--more-->\n\n> 这是一个最好的时代，我们拥有自由，可以去做很多想做的事，我们要珍惜。\n\n在并发编程中，当需要只能有一个线程执行某段代码时，一般将代码放到synchronized的代码块里，或者用synchronized修饰方法，以此来保证同一时刻只会有一个进程执行对应的代码，那么为什么加个synchronized就可以，这其中的原理是什么呢？这还是要从Object类说起。\n\n### 1. Object\nObject中一共声明了11个方法，作为所有类的父类，那么这些方法一定是所有类都会用到的，其中有5个，就是和并发编程相关的通知和等待系列方法，\n```java\nvoid notify();\nvoid notifyAll();\nvoid wait();\nvoid wait(long timeout);\nvoid wait(long timeout, int nanos);\n```\n\n### 2. wait系列方法\n看下Object.java源码就知道，wait()和wait(long, int)最终都会调用wait(long)，所以这三个重载方法，本质上就是一个方法，我们只看这一个就好。\n\n源码里关于这个方法，写了长长的一串方法说明，具体意思就是在说：当一个线程调用一个共享变量的wait方法时，该调用线程会被阻塞挂起（注意这里是调用线程），直到发生了下面这4件事中的一件事才会返回，\n- 其他线程调用了该共享对象的notify方法，并且该线程被选中成为被唤醒的线程\n- 其他线程调用了该共享对象的notifyAll方法\n- 其他线程调用了该线程的interrupt方法\n- 到达了传入的timeout，如果没传则默认是0，0就会一直等待notify了\n\n### 3. 对象的监视器锁\n调用wait方法或者notify方法时，如果没有获取到该对象的监视器锁，那么就会抛出异常IllegalMonitorStateException.\n\n那么如何才能获取到一个共享对象的监视器锁呢？具体的，源码中notify的方法说明中有着详尽的说明，一共有3种方式，现在终于轮到synchronized登场了～\n- 调用这个对象中被synchronized修饰的方法\n- 调用在这个对象上的synchronized的代码块\n- 上面两种都是同一对象，如果对于同一类型的多个对象，可调用synchronized修饰的静态方法\n\n综合来看wait和notify，可以看出，在调用时需要事先占有对象的监视器锁，调用wait就是释放监视器锁，阻塞挂起等待，调用notify就是释放监视器锁，并通知所有在等着这把锁的线程。\n\n### 4. 总结\n上面说了这么多，主要是为了说明对象的监视器锁，而synchronized则可以获取该锁，通过独占锁来保证不会有多个线程并发执行。\n\n### 附录一：进程和线程\n线程是进程中的一个实体，不会独立存在。而进程，是代码在数据集合上的一次运行活动，是系统进行资源分配和调度的基本单位，线程则是进程的一个执行路径，一个进程中至少有一个线程，进程中的多个线程共享进程资源。除去CPU资源是分配到线程，操作系统分配资源时，都将分配到进程，在Java中启动main方法时便是启动了一个JVM进程，而main方法所在的线程就是进程中的一个线程，也成主线程，一个进程只有一个主线程，这就是进程和线程的关系。\n\n每个线程有自己的程序计数器和栈，程序计数器是一块内存区域，用来记录线程要执行的指令地址，因为线程是占用CPU执行的基本单位，CPU按照时间片轮转的方式分配到各个线程，程序计数器就是为了记录线程让出CPU时的执行地址，等到再次分配占用到CPU时就可以从计数器的指定位置继续执行，所以程序计数器是线程私有。此外，如果执行的native方法，pc计数器记录的是undefined地址，执行Java代码时pc计数器记录的是下一条指令的地址。除了程序计数器，线程还有私有的栈资源，用于存储线程的局部变量，其他线程无法访问，此外还可以存放线程的调用栈帧。\n\n操作系统在创建进程后，会给其分配堆和方法区。堆是进程中最大的一块内存，被进程中的所有线程共享，主要存放new出的对象。方法区则是用来存放JVM加载的类、常量及静态等信息，也是线程共享的。\n\n### 附录二：Thread.join\n我们都知道，启动一个线程T之后，如果调用这个线程T的join方法，那么调用线程就会阻塞挂起，直到T线程执行完毕，便会恢复，以此可以保证多线程的有序执行，那么这里面是怎么做到的呢？打开Thread.java的源码，就可以看到，join一共有3个重载方法，\n```java\npublic final join()\npublic final synchronized void join(long millis)\npublic final synchronized void join(long millis, int nanos)\n```\n最终，join()和join(long, int)都会走到join(long)方法里，看到这是不是这一幕有些熟悉了？没错，这和wait系列方法的设计是一样的，而且，join(long)里最终调用的就是wait方法，我们来分析一下。\n\n看到join(long)方法前synchronized修饰符就可以知道，只要能进入到join方法，该线程便拥有监视器锁，方法内最终又调用了wait方法，便会释放监视器锁，并阻塞挂起等待，那么是谁，又是在什么时候，调用了共享对象的notify来通知调用线程，来打破这挂起状态呢？\n\n我们知道，在创建线程对象后，要调用start方法来启动线程执行，那么就来看看这个方法吧\n```java\n// Thread.java\npublic synchronized void start() {\n    ...\n    try {\n        start0();\n        started = true;\n    } finally {\n        try {\n            if (!started) {\n                group.threadStartFailed(this);\n            }\n        } catch (Throwable ignore) {\n           \n        }\n    }\n}\n\nprivate native void start0();\n```\n这里面啥都没做，就是调用了start0方法，而start0方法由是个本地方法，那就再去找找cpp的代码吧，\n```cpp\nvoid JavaThread::exit(bool destroy_vm, ExitType exit_type) {\n  assert(this == JavaThread::current(),  \"thread consistency check\");\n  ...\n  // Notify waiters on thread object. This has to be done after exit() is called\n  // on the thread (if the thread is the last thread in a daemon ThreadGroup the\n  // group should have the destroyed bit set before waiters are notified).\n  ensure_join(this); \n  assert(!this->has_pending_exception(), \"ensure_join should have cleared\");\n  ...\n```\n我没下CPP源码，这是从网上找的。上面这段是thread.cpp中，线程退出时的代码，可以看到有用的只有一句ensure_join函数的调用，代码注释里写着唤醒处于等待的线程对象，感觉对头，看看这个里面做了什么\n```cpp\nstatic void ensure_join(JavaThread* thread) {\n  // We do not need to grap the Threads_lock, since we are operating on ourself.\n  Handle threadObj(thread, thread->threadObj());\n  assert(threadObj.not_null(), \"java thread object must exist\");\n  ObjectLocker lock(threadObj, thread);\n  // Ignore pending exception (ThreadDeath), since we are exiting anyway\n  thread->clear_pending_exception();\n  // Thread is exiting. So set thread_status field in  java.lang.Thread class to TERMINATED.\n  java_lang_Thread::set_thread_status(threadObj(), java_lang_Thread::TERMINATED);\n  // Clear the native thread instance - this makes isAlive return false and allows the join()\n  // to complete once we've done the notify_all below\n  //这里是清除native线程，这个操作会导致isAlive()方法返回false\n  java_lang_Thread::set_thread(threadObj(), NULL);\n  lock.notify_all(thread);//注意这里\n  // Ignore pending exception (ThreadDeath), since we are exiting anyway\n  thread->clear_pending_exception();\n}\n```\n看到了吧，在这里调用了notifyAll，挂起的地方就会打破阻塞，继续执行了。所以，总的来看，线程的阻塞和唤醒，用的就是synchronized，调用join来挂起等待监视器锁，线程结束时通知唤醒所有阻塞的线程。\n\n","tags":["Java","synchronized"],"categories":["Java"]},{"title":"DialogFragment的onViewCreated未调用问题","url":"/2022/04/883c18ac2ae1/","content":"\n在用DialogFragment写弹窗时，遇到了一个问题，就是onViewCreated回调没走，在此做个记录。\n<!--more-->\n\n正常情况下，DialogFragment的生命周期是这样的\n```java\nonAttach -->onCreate-->onCreateDialog-->onCreateView-->onViewCreated-->onSaveInstanceState\n```\n创建Dialog有两种方式，一是重写onCreateDialog，另一个是重写onCreateView，具体还要看需求。\n\n我用的是前者，返回Dialog可定制性稍微强一些，但是写在onViewCreated里的逻辑却没走，检查下来发现了之前疏忽的一个点：onCreateView默认返回的null，而onViewCreated只有在onCreateView返回不为null时才会调用，就像超市里的捆绑销售，create view之后，才能在view created中拿到create的view，这样也合理，之前我一直以为onViewCreated里拿到的就是窗口view。\n\n源码大概是这样写的，其实也很好排查，就看下onViewCreated在哪调用的，查一下引用就很容找到了这个方法，\n```java\n// Fragment.java\nvoid performViewCreated() {\n    // since calling super.onViewCreated() is not required, we do not need to set and check the\n    // `mCalled` flag\n    onViewCreated(mView, mSavedFragmentState);\n    mChildFragmentManager.dispatchViewCreated();\n}\n```\n接着，再查一下performViewCreated在哪调用的，然后就来到了这，\n```java\n// FragmentStateManager.java\nvoid createView() {\n    ...\n    mFragment.performCreateView(layoutInflater, container, mFragment.mSavedFragmentState);\n    if (mFragment.mView != null) {\n    \t...\n    \tmFragment.performViewCreated();\n    \t...\n    }\n    ...\n}\n```\n最后，一下就触碰到了最底层柔软的答案，performCreateView之后，如果mView不为null，则执行performViewCreated。","tags":["Android","DialogFragment"],"categories":["Android"]},{"title":"go mod命令","url":"/2022/04/763efd0f8d01/","content":"\nmod，即module，golang的模块管理工具。Node.js有npm，Python有pip，Golang现在也有了go mod。\n<!--more-->\n起因是，许久不写go了，前几天拿到一个go写的项目，发现里面依赖管理已经不是早前的方式，而多了一张新面孔，`go.mod`文件，趁此机会了解学习一下。\n\n[原文在这](https://blog.csdn.net/weixin_42099302/article/details/112431899)\n\n### 简介\n如果配置过golang开发环境，应该还记得GOPATH这个环境变量，指向一个目录，这个目录下有三个子目录，bin、pkg和src，我们写的代码都在src里，除此之外，所依赖的模块也在src目录下，我们在依赖别人的同时，也可以成为别人的依赖，这是官方给的建议，可能他们觉得一家人就是要整整齐齐的，这是最早期的包管理机制。如果我们开发了10个项目工程，那么这10个项目的所有依赖都在这里面，你中有我，我中有你，随着项目增多，这个目录会越来越大。\n\n但是，每个依赖模块都是有着不同版本，多个工程会存在依赖不同版本的情况，共享GOPATH下的项目，就变得难以操作，于是就衍生出了vendor。每个工程下都有个叫vendor的子目录，直接翻译就是供货商的意思，项目所有的依赖都放到各自的vendor子目录中，互不干涉，互不影响。我的印象中，就是这种管理机制，使用godep命令来管理依赖，这个是当时最实行的方式，毕竟go module还没问世呢。\n\n随着时间发展，技术的进步，go module出来了，它比vendor多了依赖版本记录管理的功能，同时也提升了其他一些vendor体验不好的功能，比如依赖包升级，这些都写在了go.mod文件里，这个文件就和Node.js里的package.json、Python里的requirements.txt功能是一样的。此外，go mod还提供了一个特性，就是项目工程可以不再放在GOPATH/src下了，这样就可以不被其他项目所依赖。\n\n### go mod 使用\n执行一下go mod，就可以看到命令的说明了\n```shell\n$ go mod\nGo mod provides access to operations on modules.\n\nNote that support for modules is built into all the go commands,\nnot just 'go mod'. For example, day-to-day adding, removing, upgrading,\nand downgrading of dependencies should be done using 'go get'.\nSee 'go help modules' for an overview of module functionality.\n\nUsage:\n\n\tgo mod <command> [arguments]\n\nThe commands are:\n\n\tdownload    download modules to local cache\n\tedit        edit go.mod from tools or scripts\n\tgraph       print module requirement graph\n\tinit        initialize new module in current directory\n\ttidy        add missing and remove unused modules\n\tvendor      make vendored copy of dependencies\n\tverify      verify dependencies have expected content\n\twhy         explain why packages or modules are needed\n\nUse \"go help mod <command>\" for more information about a command.\n```\n常用的有这几个\n- go mod init：初始化，一般创建新工程后使用\n- go mod tidy：更新项目依赖，没有的下载，没用的删除\n- go mod vendor：创建vendor目录，并将依赖复制至此目录\n\n添加新依赖，其中branch指定版本\n```shell\ngo get github.com/repo/package@branch\n```\n\n### GO111MODULE 说明\n这是个环境变量，有3个可选值：off、on和auto，用来控制go modules功能，看这个名字就知道，是在1.11版本添加的\n- off：关闭，编译时仍旧是用老方式，也就是GOPATH/src，或者vendor中的依赖\n- on：开启，编译时不会在GOPATH/src下找依赖，而是使用项目中的go.mod文件，依赖包放在pkg/mod下，多项目共享缓存的modules，项目名后面跟着@符号以及版本号\n- auto：默认值，在1.13之后，如果工程下存在go.mod文件，则自动开启。1.11中，工程需要在src之外的目录才会开启，以确保兼容\n\n### go build -mod 说明\n上面有提到，GOPATH/pkg下是生成的中间包.a文件，编译时它的优先级最高，也就是最先被查找，如果找到目标依赖的中间包，则不会再去编译源文件从而再生成.a中间包。\n\nmod有3个值，readonly、vendor和mod。\n- readonly：所需依赖不在go.mod中时，或checksum不在go.mod中时，则报错。\n- vendor：将使用vendor下的package，而不是pkg/mod下的，不会检查go.mod中的版本\n- mod：这个mod就是pkg/mod，也就是用会使用pkg/mod中的package，不存在则下载对应版本的package\n\n### 附录：go build 和 go install\ngo build是用来编译、在项目目录下生成可执行的文件，每一个package main都会在相同位置生成一个可执行文件，但不会生成包文件，也就是pkg下的文件。\n\ngo install则是用来生成库和工具。没有package main的包，编译后的文件会放到pkg对应的名称下，扩展名.a，如果有package main，就会生成可执行文件，并放到GOPATH/bin下。\n\n所以，二者的相同点是都会生成可执行文件，不同点是生成位置不同，同时instal还会生成中间包文件.a。","tags":["Golang"],"categories":["Golang"]},{"title":"leetcode76 最小覆盖字串问题","url":"/2022/04/0467bc32461c/","content":"这是之前刷题时遇到到的一眼懵问题，就是看完第一眼整个人都是懵的，不知道在问什么。所以就习惯性的加到了待办事项中，想来已数月有余，这两天在清理待办事项列表，今天就轮到它了。\n<!--more-->\n### 题目\n[原地址](https://leetcode-cn.com/problems/minimum-window-substring/)\n\n原题是这样的,给一个字符串s，一个字符串t。返回s中涵盖t所有字符的最小子串。如果s中不存在涵盖t所有的字符的子串，则返回空字符串“”。\n\n### 分析\n我自己本身是没有思路的，后来查了网上的解析，简单说就一句话，使用双指针，都从左侧开始，指针区间不满足条件时，右移r，当满足条件时右移l，并记录每次的子串，保存最小子串。\n\n做法不难理解，困难的是要具有这种动态处理问题的思想。\n\n首先，子串必连续，s中每个字符作为子串的开头时，要么不存在目标子串，要么仅存在一个最短的目标子串，原因是，当其符合条件时，再向右扩张，则不是最短的了。当以某个字符开头的所有子串中，不存在符合条件的，那么，其右侧的字符作为开头的子串中，也不会存在符合条件的，原因是，右侧字符开头的字符串是该字符开头的字符串的子集，超集不存在符合条件的字符串，那么子集必然不会存在。\n\n两个指针的移动规则确定了，那么接下来的问题就是，如何对比两个指针之间的子串是否满足目标字符串，最直接的方法就是每次更新完指针的位置后，统计出区间的字符数量，然后再和目标字符串的字符数量，循环一一对比看是否可以覆盖。但是，我们可以容易的发现，在每次移动完指针之后，指针之间字符的变化只有指针所指向的字符，左指针右移动，减少一个对应字符数量，右指针右移，增加一个对应字符的数量，所以，就不必每次都重新计算区间情况，而是做一个缓存，每次只更新必要的字符计数。\n\n### 代码\n代码中写了较为详尽的说明\n```kotlin\nimport kotlin.collections.HashMap\nimport kotlin.math.max\n\nfun minSubStr(s: String, t: String): String {\n    if (s.length < t.length || s.isEmpty()) return \"\"\n\n    var subStart = 0\n    var subLength = s.length + 1\n\n    // 记录t的每个字符的数量\n    // 统计sub时，只统计t中有的字符\n    // 不满足右移r时，可能需要增加计数\n    // 满足右移l时，可能需要减少计数\n    // 每次移动后，对比t的字符统计和sub的字符统计\n\n    val tDict = HashMap<Char, Int>()\n    for (i in t.indices) {\n        increment(tDict, t[i])\n    }\n\n    var left = 0\n    var right = 0\n    // 两个指针都指0，所以要先把0加进去\n    val subDict = HashMap<Char, Int>().apply { put(s[0], 1) }\n\n    while (left < s.length && right < s.length) {\n        val ok = compare(subDict, tDict)\n        if (!ok) {\n            right++\n            if (right < s.length) {\n                increment(subDict, s[right])\n            }\n        } else {\n            val interval = right - left\n            if (interval < subLength) {\n                subStart = left\n                subLength = interval\n            }\n            decrement(subDict, s[left])\n            left++\n        }\n    }\n\n    return if (subLength <= s.length) s.substring(subStart, subStart + subLength + 1) else \"\"\n}\n```\n下面是3个辅助方法，很简单，便不多言\n```kotlin\n// 加1\nfun increment(d: HashMap<Char, Int>, k: Char) {\n    if (d.containsKey(k)) {\n        d[k] = d[k]!! + 1\n    } else {\n        d[k] = 1\n    }\n}\n\n// 减1，最小是0\nfun decrement(d: HashMap<Char, Int>, k: Char) {\n    if (d.containsKey(k)) {\n        d[k] = max(0, d[k]!! - 1)\n    }\n}\n\n// src里的字符数量，是否可以覆盖target里的字符数量\nfun compare(src: HashMap<Char, Int>, target: HashMap<Char, Int>): Boolean {\n    for (key in target.keys) {\n        if (!src.containsKey(key)) return false\n        if (src[key]!! < target[key]!!) return false\n    }\n    return true\n}\n```\n测试用例是从题目里找来的，一共有3个\n```kotlin\nfun main() {\n    println(\"hello leetcode 76\")\n\n    val s1 = \"ADOBECODEBANC\"\n    val t1 = \"ABC\"\n    println(\"s:$s1, t:$t1, sub:${minSubStr(s1, t1)}\")\n\n    val s2 = \"a\"\n    val t2 = \"a\"\n    println(\"s:$s2, t:$t2, sub:${minSubStr(s2, t2)}\")\n\n    val s3 = \"a\"\n    val t3 = \"aa\"\n    println(\"s:$s3, t:$t3, sub:${minSubStr(s3, t3)}\")\n}\n\n// 运行结果\ns:ADOBECODEBANC, t:ABC, sub:BANC\ns:a, t:a, sub:a\ns:a, t:aa, sub:\n```","tags":["LeetCode"],"categories":["LeetCode"]},{"title":"算法之二分法","url":"/2022/04/a643cca35940/","content":"\n说一说二分法，上次看到了，一直没做总结，跻身于待办事项里有些日子了，今天看它不顺眼，给它解决掉\n<!--more-->\n二分法，用来查找目标值，前提是有序数组。顾名思义，就是定义两个指针，一个指向最低位置，另个指向最高位置，每次取中以求减少循环次数，时间复杂度是O(logn)。二分法查找时，会有3种情况，一个是找到目标值即返回，一个是找到最左值，还有一个自然是找到最右值。后两者存在于数组中存在多个目标值的情况。\n\n接下来的几段代码中，都用下面这个数组，长度是14\n```kotlin\nval arr = intArrayOf(2, 3, 4, 4, 8, 12, 21, 21, 21, 23, 45, 54, 54, 98)\n```\n\n### 1. 查找目标值\n这个时候，不关心有几个，只关心有，还是没有，找到就返回，找不到就算了\n```kotlin\nfun findValue(target: Int): Int {\n    var low = 0\n    var high = arr.size - 1\n    // point 0\n    while (low <= high) {\n    \t// point 1\n        val med = low + (high - low) / 2\n        if (arr[med] == target) {\n            return med\n        }\n        if (arr[med] > target) {\n        \t// point 2\n            high = med - 1\n        } else {\n        \t// point 3\n            low = med + 1\n        }\n    }\n    return -1\n}\n\nfun main() {\n    val target = 54\n    val index = findValue(target)\n    println(\"find value of $target, size:${arr.size}, index:$index\")\n}\n\n// 输出：find value of 54, size:14, index:12\n```\n需要有几点注意的地方，\n- 一个是while的停止条件，因为在这low和high都是数组的角标，所以它们是可能相等，所以是小于等于。我觉得不要考虑太多的情况，记的多了反而容易乱\n- 再一个就是计算med时，为防止溢出，不要把两个相加再除以2\n- 最后一个就是更新low和high的值时，要跳过med，因为med已经比较过了，不要再重复\n\n### 2. 找最左值\n当数组中存在多个目标值的时候，找到处于最左边的那个，\n```kotlin\nfun findLeftValue(target: Int): Int {\n    var low = 0\n    var high = arr.size - 1\n    while (low <= high) {\n        val med = low + (high - low) / 2\n        // point 0\n        if (arr[med] < target) {\n            low = med + 1\n        } else {\n            high = med - 1\n        }\n    }\n    if (low < arr.size && arr[low] == target) {\n        return low\n    }\n    return -1\n}\n\nfun main() {\n    val target = 1\n    val index = findLeftValue(target)\n    println(\"find value of $target, size:${arr.size}, index:$index\")\n}\n\n// 输出：find value of 54, size:14, index:11\n```\n与上面的不同，这个不是找到就返回，而是将high不停的向左靠，直到和low相遇，这个时候才会结束while循环\n- 只有在target比med大的时候，移动low，剩下的情况，移动high，逼近low。\n- 情况一，med命中target，且数组中只有一个target，但这时会移动high，到med-1，在接下来的循环中，low就会不停的向high靠拢，直到和high相遇，因为target在high的右边，这个时候med的值小于target，移动low到med+1，超过了high，退出循环，此时low就是target的位置\n- 情况二，target不在数组中，比最左还要小，此时，循环结束后，high会移动到low的左边-1的位置\n- 情况三，target不在数组中，比最右还要大，此时，循环结束后，low会移动到high的右边arr.size的位置，超出数组范围\n结合这几种情况，在while结束后，再加一个判断，就可以得到最后的结果了\n\n### 3. 找最右值\n这个和找最左值刚好相反，如果上面的能明白，这个就也可以明白\n```kotlin\nfun findRightValue(target: Int): Int {\n    var low = 0\n    var high = arr.size - 1\n    while (low <= high) {\n        val med = low + (high - low) / 2\n        if (arr[med] > target) {\n            high = med - 1\n        } else {\n            low = med + 1\n        }\n    }\n    if (high >= 0 && arr[high] == target) {\n        return high\n    }\n    return -1\n}\n\nfun main() {\n    val target = 21\n    val index = findRightValue(target)\n    println(\"find value of $target, size:${arr.size}, index:$index\")\n}\n\n// 输出：find value of 21, size:14, index:8\n```\n\n### 题外话\n想着用kotlin写，顺便练习一下，就打开了IntelliJ IDEA，发现破解无效了，可能是太久没用了吧。其实也不是破解，就是无限重置30天试用的那个时间，以达到长期白嫖的目的。现在这个版本要登陆账号了，门槛又高了，心想着登陆了账号后，不出意外肯定会把试用时间和账号关联，这不就成一次性的了吗？于是，就开始往下降版本，一路卸载、下载安装包、再安装，直到2021.1，才可以，这熟悉的味道又回来了。\n\n2021.1，记住这个版本，这是一个不可跨越的分水岭。","tags":["二分法","算法"],"categories":["算法"]},{"title":"C中的几个关键字","url":"/2022/04/7ab8f9ee189a/","content":"\n《C Primer Plus》\n<!--more-->\n\n这几天抽空看了这本书，看名字就知道，讲的是C语言基础，有70多万字，可谓相当之多。不过好在多数内容都还算基础，所以很粗糙的阅读了一遍，常识性的内容就略过去了，比如什么是语句，什么是表达式，什么是注释，调了几个常用的基础点写一写。\n\n### 1. define\ndefine关键字用来定义宏，基本的格式是\n```c\n#define NAME VALUE\n\n#define PI 3.1415\n```\nNAME是给宏的定义，比如常见的PI，VALUE就是这个定义的值，这个关键字是在预编译阶段处理的，具体的操作就是复制VALUE，然后替换掉NAME，对，就是这么简单的操作，NAME中不可以含有空格，VALUE没有这个限制\n\n### 2. typedef\ntypedef可以声明新的类型名称，来代替已有的类型名，但是却不能增加新的类型。多用来定义结构体\n```c\nstruct node\n{\n\tint id;\n\tstruct node * next;\n};\n```\n正常情况，在声明时需要写完整，\n```c\nstruct node n1;\n```\n使用typedef定义一个新的类型，来代替struct node\n```c\ntypedef struct node Node;\n\nNode n1;\n```\n当然，也可以连在一起写\n```c\ntypedef struct node\n{\n\tint id;\n\tstruct node * next;\n} Node;\n\nNode n1;\n```\n也可以省略掉node，因为这样写就用不到它了\n```c\ntypedef struct\n{\n\tint id;\n\tstruct node * next;\n} Node;\n\nNode n1;\n```\n可以再加一个类型，形成链表\n```c\ntypedef Node * List;\n\nList links;\n```\nNode和List并不是新的类型，它只是替代了struct node和Node类型的指针。\n\n### 3. 函数指针\n```c\nvoid f(char*);\n```\nf是一个函数，输入参数为字符指针，输出为空\n```c\nvoid *f(char*);\n```\nf还是一个函数，输入参数为字符指针，输出为void指针，在C里，void指针被当作字符指针来处理\n```c\nvoid (*f)(char*);\n```\n这时，f是一个函数指针，输入参数为字符指针，输出为空。\n\n要声明一个指向特定类型函数的指针，可以先声明一个该类型的函数，然后把函数名替换成`(*pf)`形式的表达式。然后，pf就成为指向该类型函数的指针。\n\n### 4. 文件操作\n总结几个和文件操作相关的函数，包含在stdio.h\n- fopen()：打开一个文件，支持多种模式，如文本模式，字节模式b，追加模式a，读取模式r，写入模式w等\n- getc()：get char，读取字符\n- putc()：写入字符\n- fclose()：关闭打开的文件\n- fgets()：同上面的，获取多个\n- fputs()：同理\n- rewind()：返回到文件开始处\n- fseek()：三个参数，FILE，long，int mode，从哪个位置开始移动多少个字节，正前负后\n- ftell()：报告FILE现在的位置\n- fgetpos()：上面的升级版，如果长度超出long了，就用这个\n- fsetpos()：同理\n- fflush()：FILE带有缓冲区，将缓冲区的内容刷新到文件\n- feof()：不为0则表示到末尾了，end of file\n- ferror()：不为0则表示出错了\n- ungetc()：把字符串放回去，假装一切都没有发生过\n- setvbuf()：设置缓冲区的\n- fread()：以二进制读取\n- fwrite()：以二进制写入"},{"title":"Android命令之sdkmanager","url":"/2022/04/be304f3ab35d/","content":"\n直到最近需要在Linux机器打包，才发现sdkmanager这个命令。\n<!--more-->\n在Windows或者Mac上，这种有图形化界面的系统上，我们可以使用AndroidStudio打包，在里面可以管理sdk、ndk、build tools、platfrom等的版本，这也是官方推荐的方式。但是在Linux这种全是命令行的系统上，就没法用这个，这个时候就要用sdkmanager命令了。\n\n有个叫commandlinetools的工具包，在官网可以下载，[这是地址](https://developer.android.com/studio)。如果装了完整的sdk，那么这个命令在\n```shell\n~/Libarary/Android/sdk/tools/bin/sdkmanager\n```\n用起来很简单，常用的有list，install，uninstall和update。\n\n```shell\nsdkmanager --list\n```\n执行完这条命令，就会打印出所有已安装的包信息，和所有可安装的包的信息\n\n```shell\nsdkmanager --install \"ndk;21.3.6528147\"\n```\n安装指定版本的ndk，中间用分号隔开，整体用引号包上。如果不指定版本，则安装最新的，如果不知道版本号是多少，就从list的结果里面找，里面列出了所有可用的版本。uninstall的用法和install同理。\n\n在不同的系统上list出来的结果有所不同，我在MacOS上列出来的可用包，要比在Linux上的多很多。\n\n```shell\nsdkmanager --update\n```\n这个就很简单了，更新所有已安装的软件包。\n\n另外，还有几个可选参数，具体用法，就看[官方文档](https://developer.android.com/studio/command-line/sdkmanager)吧。","tags":["Android"],"categories":["Android"]},{"title":"Shell脚本调试","url":"/2022/04/a230c65a4578/","content":"\n几个调试shell脚本时常用小技巧。\n<!--more-->\n\n- xtrace\n打印执行的每一条命令\n```shell\nset -o xtrace # 打开\n\nset +o xtrace # 关闭\n\n# 或者这样\nset -x\nset +x\n```\n\n- e\n出错后立即停止执行。每一条命令在执行成功后多会返回0，返回非0时代表出错。打开e之后，遇到非0返回值后会立即结束，而不会继续执行，这在一条命令需要在上一条成功执行的基础上才能执行时很有用。在某些时候也不会关心执行结果，比如，删除一个文件或文件夹，当删除目标不存在时，返回的就是一个非0结果，这个时候也不影响，所以，按需打开/关闭。\n```shell\nset -e # 打开\n\nset +e # 关闭\n```","tags":["Shell"],"categories":["Shell"]},{"title":"MacOS命令之sed","url":"/2022/04/76096e764448/","content":"\n写自动化脚本时，会需要修改其他的配置文件，将某些配置值替换成本次的配置，手动改完再去执行脚本不是不可，只不过一两次还可以，次数多了就有些浪费时间了，这时就用到了sed命令，这是个强大的文本编辑命令。\n\n<!--more-->\n\nsed命令和vi命令有些像，主要体现在命令的格式上，最大的区别在于vi需要把文件打开之后才可编辑，而sed则不需要打开即可编辑，当文件的体量特别大的时候，比如上万行、上十万、百万行，sed的优势就体现出来了。\n```shell\nman sed\n```\n来一下man命令，就可以看到sed的详尽介绍了，这里说几个常用的用法。总的来说，无非就是删除、增加、查找替换，其他的需求就没要用sed了。\n\n### 1. 删除\n```shell\nsed -e 'm,nd' test.txt\n```\n- e: expression，表达式，也就是指后面引号里的内容\n- m,nd: 删除第m到第n行，d，delete\n\n### 2. 增加\n```shell\nsed -e 'ni\\\ncontent to insert or append\n' test.txt\n```\n- e: 同上\n- ni: 在第n行前面插入一行，a表示在第n行后面插入一样\n\n### 3. 查找替换\n```shell\nsed \"s/pattern/replace/\" test.txt \nsed \"n,ms/pattern/replace/g\" test.txt\n```\n- s: substitute，替换\n- n,ms: 指定行范围\n- pattern: 支持正则\n\n### 4. 替换原文件\n以上命令在执行后，都是以打印的方式输出，而不会修改原文件，如果要修改原文件，则要使用-i命令，举个例子\n```shell\nsed -i '' -e '1,5d' test.file\n```","tags":["MacOS","sed"],"categories":["MacOS"]},{"title":"Kotlin基础","url":"/2022/04/bde5bd66c95d/","content":"\n今天看了篇文章，写点东西做个总结，也算是没有白花时间。\n<!--more-->\n> [原文地址在这](https://mp.weixin.qq.com/s/q60HuenJ8YmtrP-JbH-q4g)\n\n相对于写惯了Java的人来说，Kotlin算是相当友好的，因为在看完基础语法之后，就完全可以按照写Java的习惯来写Kotlin，并且可以达到一样的效果，这还不算友好吗，这可以算是相当友好。但是，Kotlin还是有着自己一些独特的特点，可以不用，但是了解还是要了解的，相同的就不再啰嗦，这里就把不一样的抽出来说一说。\n\n### 1. 嵌套类和内部类\n在Java里，在类内部声明的类叫做内部类，内部类默认持有外部类的引用，例如，可以在内部类里调用外部类的方法，原因就是持有外部类的引用，自然可以调用其方法，除此之外，通过外部类的实例，才能创建内部类的实例，原因也是在此。要想解除这种引用，那么就要用static修饰，使其变成静态内部类，此时便不再持有外部类的引用，与普通的类无异，唯一的区别就是全类名中含有外部类的名字，依此来定位到自己。\n\n在Kotlin里，大致也是如此，依然是内部类默认持有外部类的引用，但是，声明内部类时需要用inner关键词修饰class，使其变成内部类方可。当没有inner修饰时，和Java中的静态内部类等同，不持有外部类的引用。\n\n平常叫惯了内部类，查了查发现这样是不严谨的，严格来说是叫嵌套类，和静态嵌套类，Static Nested Class。\n\n### 2. lambda调用外部临时变量\nJava7之前，匿名内部类要想使用外部临时变量，必须是final的，到了Java8，引入了lambda，在匿名内部类和lambda中使用外部的临时变量时，可不加final，但是依然不能修改。原因在于，内部类会被编译成一个新的类，其中保留外部类的引用，以及临时变量的副本，所以内部类修改的是变量的副本，这就会造成歧义，所以禁止修改。但这种问题只局限于基本类型变量，如果是引用型变量，就没有这种问题，引用的地址不变，但其指向的内存的数据是可变的。\n\n但是，在Kotlin中，lambda外部的基本类型临时变量也能引用并且可以修改，这就和Java有些不同了。非内联的lambda在编译后会生成一个内部类，这一点同Java，但是对于基本类型也会自动包裹一层，kotlin提供了Ref类，例如IntRef、BooleanRef等，这样基本类型就转成了引用类型，所以也可以在内部类中也可以修改。\n\n### 3. let/run/apply/also\n还是这4个方法，之前写了[一篇文章](https://oynix.github.io/2021/08/517bb194f5b9/)专门介绍，发现分析地再细致，对比的越全面，等到用的时候，还是容易一脸懵：这个和这个的区别是什么来着？现在想了个新角度，如果需要返回自身，就用apply和also，返回lambda的值就用let和run。这样好记了吗，还不好记吗，那就来个更简单的，3个字母的返回lambda，剩下的返回调用者本身。至于lambda内部的参数，不是this就是it，试一下就知道了。\n\n### 4. 操作符\nkotlin里面提供了好大一堆操作符，都是为了方便日常开发使用，要是能记住，用的时候可以少写几行代码，记不住也没关系，就自己写呗，也没几行。这里列举几个出来：\n- any：list.any，有一个符合就返回true，any就是任一的意思，与之相反的是none\n- all：同上，但相反，必须都符合\n- count：统计符合条件的数量\n- flod：带初始值，叠加，flodRight，是从最后一项开始；reduce不带角标，reduceRight从最后开始\n- forEach：不多说，forEachIndexed，带角标遍历\n- max：最大，maxBy，指定对比值，min和minBy同理\n- sumBy：求和\n- drop：丢掉前n个元素，dropWhile，碰到符合条件后则将剩下的返回，dropLastWhile，从后开始\n- filter：过滤，filterNot，取反，filterNotNull，滤掉空\n- silce：指定角标\n- take：拿前多少个，takeLast，从后面开始拿，takeWhile，返回false时停止拿\n- map：映射\n- flatMap：展开\n- zip：返回由Pair组成的list，unzip将pair list转成`Pair([],[])`\n\n### 5. 委托\n在kotlin使用委托在代码上简化了不少，使用by关键字即可\n- 接口委托，InterfaceImple虽然实现了接口，但是都是通过调用agent的方法\n```kotlin\ninterface InterF {}\nclass InterfaceImpl(val agent: InterF) : InterF by agent\n```\n- 属性委托，将属性委托给一个有getValue和setValue方法的类，val只有get没有set\n```kotlin\nclass Delegate {\n\toperator fun getValue(thisRef: Any?, property: KProperty<*>): String {}\n\n\toperator fun setValue(thisRef: Any?, property: KPropergy<*>, value: String) {}\n}\n\nvar strValue: String by Delegate()\n```\n- 延迟委托，一般使用lazy方法，也可以自己写一个方法，返回`Lazy<T>`即可，在第一次调用get时，会调用初始化方法\n```kotlin\n// LazyThreadSafeMode.SYNCHRONIZED，同步锁\n// LazyThreadSafeMode.PUBLICATION，多线程\n// LazyThreadSafeMode.NONE，不关心\nval lazyValue: String by lazy {\n\t\"hello world\"\n}\n```\n- 可观察属性，Delegates.observable(initValue, {})，在调用set时会被调用\n```kotlin\nclass Example {\n    var age: Int by Delegates.observable(-100) { kProperty: KProperty<*>, oldValue: Int, newValue: Int ->\n        println(\"kProperty.name: ${kProperty.name} , oldValue: $oldValue , newValue: $newValue\")\n    }\n}\n```\n- 拦截属性值，Delegates.vetoable(initValue, {})\n```kotlin\nclass Example {\n    var age: Int by Delegates.vetoable(-100) { kProperty: KProperty<*>, oldValue: Int, newValue: Int ->\n        println(\"kProperty.name: ${kProperty.name} , oldValue: $oldValue , newValue: $newValue\")\n        age <= 0 //返回true 则表示拦截该赋值操作\n    }\n}\n```\n- 把属性存储在映射中\n```kotlin\nfun main() {\n    val student = Student(\n        mapOf(\n            \"name\" to \"leavesCZY\",\n            \"age\" to 24\n        )\n    )\n    println(student.name)\n    println(student.age)\n}\n\nclass Student(val map: Map<String, Any?>) {\n    val name: String by map\n    val age: Int by map\n}\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["Android","Kotlin"],"categories":["Kotlin"]},{"title":"c/c++指针与数组","url":"/2022/04/67fb7c494fc5/","content":"说一说指针在使用过程中容易混淆不清、出问题的点。\n<!--more-->\n\n### 1. 引入\n若要说清楚指针，就要先说说内存。内存，每一个字节都有着自己的地址，早年间有个词常说，那就是32位机器，和64位机器（现在32位的机器越来越少），其中的32位和64位，指的便是内存寻址的位数，直白点说就是机器的系统用来存储内存地址的位数。32位，最多能表示2^32个字节，也就是4G个字节，所以在32位机器上运行的程序最多能使用的内存大小就是4G字节。但随着技术发展，4G字节的内存已渐渐不能满足生产生活需求，于是，64位机器应运而生，最多能表示16E个字节，这是一个相当大的数字，虽然目前64位的机器已能满足需求，但也说不定哪天，128位的机器就展露了头脚。\n\n而指针，存储的就是这个地址。\n\n定义一个char类型的变量，它存储的是字符，长度是1个字节。定义一个int类型的变量，它存储的整数，抛开不同类型机器因素，这里认为它的长度是4个字节。定义一个指针类型的变量，在32位的机器上，它存储的就是一个32位的地址，长度为4个字节（1byte=8bits），在64位机器上为8个字节。这里还要说明一点，不管一个变量在内存中占用几个字节，占用4个字节的int也好，占用8个字节的double也罢，它的地址都是低位的第一个地址。比如，一个int占用的4个字节为，0x0000_0001,0x0000_0002,0x0000_0003,0x0000_0004，那么它的地址就是低位的0x0000_0001，double等其他类型，同理。\n\n### 2. 指针的类型\n上面有提到，只要是指针类型的变量，那么它存储的值便是一个内存地址，既然存储的都是地址，那为什么还要有不同的类型呢，比如int型的指针`int*`、char型的指针`char*`？主要目的有两个，其一，是用指针类型来限定指针如何解释它所指向的内存，其二，便是限定指针的移动。\n\n先说指针如何解释它所指向的内存。假定32位机器的大顶端机器，\n```\n内存地址为0x0000_0001的字节，存储的值是0x41\n内存地址为0x0000_0002的字节，存储的值是0x41\n内存地址为0x0000_0003的字节，存储的值是0x41\n内存地址为0x0000_0004的字节，存储的值是0x41\n```\n简单说就是4个连续的字节，存储的都是0x41。上面有提，不管什么类型的指针，存储的值都是这个变量的低位字节的地址，现定义一个int类型的指针`int* pi`令它指向0x0000_0001，再定义一个`char* pc`，也令它指向0x0000_0001，也就是定义两个不同类型的指针，但是让它们都指向同一个地址。当把它们的值打出来的时候，你会发现pi指向的值为0x4141_4141，pc指向的值为'A'，也就是0x41。指向同样的地址，值却不同，这就是指针类型对内存解释的限定。\n\n再说如何限定指针的移动。就像我们知道的，指针加1就是向后移动，指向下一个值，指针减1就是向前移动，指向前一个值，那么问题来了，每次移动要移动的长度是多少呢，即，每次要移动多少字节呢？指针的类型便会限定指针移动的字节数量，还是上面那个例子，pi加1之后，它会向高位内存移动int的长度，4个字节，随后指向0x0000_0005，而pc加1后，它只会移动1个字节，指向0x0000_0002，因为char的长度为1个字节。关于此，也可以将指针的类型，理解为它的跳跃能力，pi的跳跃能力是4个字节，而pc的跳跃能力是1个字节。\n\n好了，关于指针的类型就说这么多，因为不想写代码，所以假定了一个很直白、也很理想的例子，仅供参考。\n\n### 3. 数组和指针\n数组由相同类型的一些列元素组成，使用中括号`[]`声明，关于定义不多赘述，主要还是说数组和指针。\n\n```c\nint arr[5] = {1, 2, 3, 4, 5};\nint* pa = arr;\nint* pa0 = &arr[0];\nint(* parr)[5] = &arr;\ncout << \"arr = \" << arr << endl;\ncout << \"&arr = \" << &arr << endl;\ncout << \"arr[0] = \" << arr[0] << endl;\ncout << \"&arr[0] = \" << &arr[0] << endl;\ncout << \"pa = \" << pa << endl;\ncout << \"*pa = \" << *pa << endl;\ncout << \"pa的大小:\" << sizeof(pa) << endl;\ncout << \"arr的大小:\" << sizeof(arr) << endl;\ncout << \"*(&arr)[0] = \" << *(&arr)[0] << endl;\ncout << \"*parr[0] = \" << *parr[0] << endl;\n\n\n// 运行结果\narr = 0x7ff7b661e460\narr的地址 = 0x7ff7b661e460\narr[0] = 1\n&arr[0] = 0x7ff7b661e460\npa = 0x7ff7b661e460\n*pa = 1\npa的大小:8\narr的大小:20\n*(&arr)[0] = 1\n*parr[0] = 1\n```\n像上面这样，一眼看上去，是不是有些迷乱，甚至还有点不知所措？不要担心，路是要一步一步走，让我们逐一击破。\n\narr是声明的一个长度为5的整型数组，arr的值就是数组第一个元素的地址，也就是`arr[0]`的地址，第一个元素是个int，所以int型的指针pa是可以指向这个元素的，同时，int型指针pa0，也可以指向`arr[0]`，这个应该不难理解。\n\n用中括号`[]`从数组中取值的操作，本质上和指针操作，是一样的，也就是说，\n```c\narr[0] = *pa;\narr[1] = *(++pa);\n```\n但是，还是有一点区别，数组是有长度的，也就是`sizeof(arr)/sizeof(arr[0])`的值，这里等于5，指针只要不超过最大内存地址，便可以一直加1向高位移动，但数组一旦超过了声明时的长度，便会报错数组脚标越界。\n\n接下来说容易让人疑惑的对数组取地址：`&arr`。对数组取地址后，返回的值的类型是数组型指针，如果用一个int型的指针来接收这个值就会报错，而是需要声明一个数组型的指针来接收此值，也就是\n```c\nint(* parr)[5] = &arr;\n```\n注意这里的括号，如果不加括号，那么parr的类型就是一个普通数组，里面元素的值是int型指针，要用int型指针来初始化，如果觉得乱，那么横向对比着看就很清晰\n```c\nint value = 5;\n// int型指针\nint* p = &value; \n\n// int型数组，元素类型是int\nint arr[5] = {1, 2, 3, 4, 5};\n// int*型数组，元素类型是int*\nint* parr[5] = {p, p, p, p, p};\n\n// 数组型指针\nint(* arrp)[5] = &arr;\n```\nint型数组和`int*`型数组，相同点都是数组，不同点，一个元素类型是int，一个元素类型是int型指针。\n\nint型指针和数组型指针的区别在于，跳跃能力不同，int型指针加1后向高位内存移动一个int的长度，即4个字节，而数组指针在加1后，会向高位内存移动一个数组的长度，即，4x5=20个字节。数组型指针取值，和数组取值相同，这也算对得起名字里的数组，这么看来，数组型指针是不是很像二维数组了，\n```c\nint arr2[2][3] = {{1, 2, 3}, {11, 12, 13}};\n// arr2[0]即为数组{1, 2, 3}\nint(*arr2p)[3] = &arr2[0];\n// arr2p是数组指针，那么(*arr2p)自然是所指向的数组\ncout << \"二维数组，[0][0]:\" << (*arr2p)[0] << endl;\ncout << \"二维数组，[0][1]:\" << (*arr2p)[1] << endl;\ncout << \"二维数组，[0][2]:\" << (*arr2p)[2] << endl;\narr2p++; // 加1之后，移动到下一个数组\ncout << \"二维数组，[1][0]:\" << (*arr2p)[0] << endl;\ncout << \"二维数组，[1][1]:\" << (*arr2p)[1] << endl;\ncout << \"二维数组，[1][2]:\" << (*arr2p)[2] << endl;\n\n// 运行结果\n二维数组，[0][0]:1\n二维数组，[0][1]:2\n二维数组，[0][2]:3\n二维数组，[1][0]:11\n二维数组，[1][1]:12\n二维数组，[1][2]:13\n```\n\n### 4. const\n调用函数时，经常看到返回值或是参数的类型是`const char*`，还有`char const*`，关于const，其实有个很好记的小窍门：const修饰谁，谁就不可变\n```c\nint a = 10;\nint b = 20;\n\n// const修饰int，表示cap指向的这个值不能变\nconst int* cap = &a;\n// Yes，可以只声明不初始化赋值，后续再赋值\nconst int* cap;\n// No，不可以，指向地址的值不能变\n*cap = 15;\n// Yes，可以，cap指向地址的值没变，但是可以指向别的值\ncap = &b;\n\n// const不能修饰*，所以，这个时候const修饰的它前面的int，也就是说，\n// int const* 和 const int* 两种写法是一样的\nint const* acp = &a;\n\n// const修饰指针，表示这个指针指向的地址不能变，所以声明的时候必须初始化赋值\nint* const apc = &a;\n// No，不可以，声明时必须初始化\nint* const apc;\n// Yes，可以，虽然改变了a的值，但是apc指向的地址没变，\n*apc = 15;\n// No，不可以，apc指向的地址不能变\napc = &b;\n```\n\n### 5. void*\n前文写JNI的时候有提到过，类型是void的指针，表示这个指针的跳跃能力未可知，需要在使用的时候手动指定，以便能解释它所指向的内存，多用于通用函数的参数，如内存复制的memcpy，函数本身并不关心传进来的是什么类型的指针，跳跃能力如何，它只负责把从src指针指向的位置开始，复制指定数量的字节的值，到dst指针指向的位置，即可。","tags":["c/c++"],"categories":["c++"]},{"title":"把代码藏到png里","url":"/2022/04/cbb587a9b5cc/","content":"\n之前有提到，最近因需求特殊，所以需要把代码藏起来，想着想着就盯上了资源图。为了把代码藏到png里，所以专门研究了png的文件格式。\n<!--more-->\n宏观来看，文件都是以字节为单位存储在介质上，如电脑硬盘，手机ROM，而字节无非就是010101的形式，那么既然都是010101的格式，为什么有的文件是png，有的文件是jpg，还有的文件是webp呢？这里面，一定有着什么规则，就像是网络里的各种协议，是同样的道理。\n\n要查看这些，首先就要把文件以二进制的形式打开，我用的是UltraEdit，也可以用其他的。\n\n### 1. png文件结构\n关于png文件结构，白皮书有着详细介绍，[这里是官方文档](https://www.w3.org/TR/PNG/)。这个文档里面对png进行了十分详尽的介绍。总的来说，png文件的结构就是一个文件头，加上若干了chunk块组成，\n```\n[文件头][chunk][chunk][chunk][chunk][chunk]\n```\n\n### 2. 文件头\n正如白皮书中所说，png文件头是固定的\n```\n89 50 4E 47 0D 0A 1A 0A\n```\n这是16进制格式，每个数字代表4个bit，所以每两个数字代表一个byte，文件头的长度是8个字节。第一个字节0x89是规定的，用一个超过ASCII字符范围的值，为的就是防止被当作文本文件处理。紧接着的3个字节，查一下ASCII表就知道了，50=P，4E=N，47=G，剩下的0D 0A 1A 0A是什么没说，文档上就一句话，这个签名表明是png图片\n> 5.2 PNG signature\n> The first eight bytes of a PNG datastream always contain the following (decimal) values:\n>\n>   137 80 78 71 13 10 26 10\n> This signature indicates that the remainder of the datastream contains a single PNG image, consisting of a series of chunks beginning with an IHDR chunk and ending with an IEND chunk.\n\n### 3. chunk结构\n结构如下\n```\n[LENGTH][CHUNK TYPE][CHUNK DATA][CRC]\n```\n当chunk data的长度是0时，chunk的结构是这样的，就是去掉了DATA部分\n```\n[LENGTH][CHUNK TYPE][CRC]\n```\n其中，LENGHT的长度是4个字节，TYPE的长度也是4个字节，DATA的长度对于不同的TYPE是不同的，LENGTH的值就是DATA的长度，CRC的长度也是4个字节，下面一一自报家门。\n\n### 4. chunk type\ntype表明了chunk块的类型，目前png一共定义了18个类型，然后又把这18个类型分为两大种，一个是关键chunks，另个是辅助chunks。关键chunks一共有4个，剩下的都是辅助类型，有些类型的位置是固定的，这些都写在白皮书的5.6小节。\n\n关键chunks，\n\nchunk name|multiple allowed|optinal|order constraint\n:|:|:|:\nIHDR|No|No|Shall be first\nPLTE|No|Yes|Before first IDAT\nIDAT|Yes|No|Multiple IDAT chunks shall be consecutive\nIEND|No|No|Shall be last\n\n辅助chunks，所有辅助chunk都是可选的，意思即使png文件里可能有也可能没有\n\nchunk name|multiple allowed|order constraint\n:|:|:\ncHRM|No|Before PLTE and IDAT\ngAMA|No|Before PLTE and IDAT\niCCP|No|Before PLTE and IDAT. If the iCCP chunk is present, the sRGB chunk should not be present.\nsBIT|No|Before PLTE and IDAT\nsRGB|No|Before PLTE and IDAT. If the sRGB chunk is present, the iCCP chunk should not be present.\nbKGD|No|After PLTE; before IDAT\nhIST|No|After PLTE; before IDAT\ntRNS|No|After PLTE; before IDAT\npHYs|No|Before IDAT\nsPLT|Yes|Before IDAT\ntIME|No|None\niTXt|Yes|None\ntEXt|Yes|None\nzTXt|Yes|None\n\n### 5. chunk data\nchunk的数据都存放在data里，data的长度，也就是字节数量，等于LENGTH的值。\n\n### 6. chunk crc\ncrc存放的是该chunk块的校验码，采用的是crc32的计算方式，将type和data输入，输出的结果就是crc\n```\nchunk crc = crc32([CHUNK TYPE][CHUNK DATA])\n```\n白皮书里是这么介绍的，另外[这个文档里有介绍png所使用的crc算法](http://www.libpng.org/pub/png/spec/1.2/PNG-Structure.html#CRC-algorithm)\n```\n5.5 Cyclic Redundancy Code algorithm\nCRC fields are calculated using standardized CRC methods with pre and post conditioning, as defined by ISO 3309 [ISO-3309] and ITU-T V.42 [ITU-T-V42]. The CRC polynomial employed is\n\nx32 + x26 + x23 + x22 + x16 + x12 + x11 + x10 + x8 + x7 + x5 + x4 + x2 + x + 1\n\nIn PNG, the 32-bit CRC is initialized to all 1's, and then the data from each byte is processed from the least significant bit (1) to the most significant bit (128). After all the data bytes are processed, the CRC is inverted (its ones complement is taken). This value is transmitted (stored in the datastream) MSB first. For the purpose of separating into bytes and ordering, the least significant bit of the 32-bit CRC is defined to be the coefficient of the x31 term.\n\nPractical calculation of the CRC often employs a precalculated table to accelerate the computation. See Annex D: Sample Cyclic Redundancy Code implementation.\n```\n看完了计算原理之后，便开始自己实现算法，写着写着发现python有现成的lib提供crc32的算法，带入了几组数据之后发现，结果竟然都正确，既然如此，那我还吭哧吭哧的实现什么呢。\n\n### 7. 关键chunk块，IHDR\nIHDR块一般都紧跟在文件头那8个字节后面，其中chunk data部分每个字节存储的数据表示的含义都是固定的，如下\n\nName|Bytes Length|Description\n:|:|:\nwidth|4 bytes|宽度，单位像素\nheight|4 bytes|高度，单位像素\nbit depth|1 byte|图像深度\ncolor type|1 byte|颜色类型\ncompression method|1 byte|压缩方法\nfilter metho|1 byte|滤波器方法\ninterlace method|1 byte|隔行扫描\n\n我找了个一个png图片的前几个字节，一起对着来看看\n```\n89 50 4E 47 0D 0A 1A 0A \n00 00 00 0D \n49 48 44 52 \n00 00 02 D0 00 00 05 00 08 06 00 00 00 \n6E CE 65 3D\n```\n为了便于观察，我给它断成了几行，第一行就不用多说了，是png文件头，后面的都是IHDR chunk块。前4个字节00 00 00 0D代表着chunk length，计算出来是13，接下来的个4个字节，就是ASCII码，49=I，48=H，44=D，52=R。然后就是最长的一行，数一数可以发现，正好是13个byte，和chunk length的值是一致的，根据上表可知，00 00 02 D0为图片宽度，算出来是720像素，00 00 05 00是高度1280像素，后面的图像深度、颜色类型什么的，就不看了，直接看chunk crc部分的6E CE 65 3D，计算一下\n```python\nimport zlib\nif __name__ == '__main__':\n    data = [0x49, 0x48, 0x44, 0x52, 0x00, 0x00, 0x02, 0xD0, 0x00, 0x00, 0x05, 0x00, 0x08, 0x06, 0x00, 0x00, 0x00]\n    crc = zlib.crc32(bytearray(data))\n    print(hex(crc))\n```\n运行结果：0x6ece653d。可见，截止至此，一切看起来都是正常的。\n\n### 7. 关键chunk块，IDAT、IEND\n这两个的chunk块和IHDR是一样的，如果能明白上面的IHDR，这两个就也能明白。这里单独说一句IEND，因为这个chunk块没有chunk data部分，所以，所有png的IEND块都是一样的，一样的length，一样的type，以及一样的crc。\n\n### 8. 插入代码\n好了，有了上面的基础知识准备，开始干点正事。\n\npng中，像素的数据存在连续的IDAT chunk中，一长串的IDAT数据，根据IHDR中width和height参数，再解析出来。\n\n我开始的想法，是把代码藏在辅助chunk中，那么多可选的辅助类型，照片的地理位置、镜头、光圈等信息，都是存放在这些辅助chunk里，随便选几个，把数据插入到data部分，然后再计算一下crc不就完美了吗？冷静下来后，觉得此法尚有不妥之处，你想啊，一个png图片，辅助信息占了好大一个比例，但是这个辅助信息又不是正常的文本，或是数字，除了自己知道怎么解析，别人都看不懂，让人易生疑心：你这里面是不是藏了什么不能见人的东西？这浑身是嘴也说不清楚。\n\n有个同事是把代码直接拼在了文件的末尾，因为width和height没变，中间的IDAT也没变，所以完全不影响png文件的读取，遇到IEDN就停了，即便你后面还有数据也不妨事。当代码很少时，难以看出端倪，但是代码一旦很多，画风就会很诡异：一个几十像素乘几十像素的图片，文件大小却足足有上百kB，这就好比，你E盘存储进度条都变红了，点进去一看，发现里面只有一集蜡笔小新的动画，还是渣画质，大小为20MB，你可以说这里一切正常，但要是有人信了，就当你没说。这个时候，只要一打开png文件，就会看到后面跟着的那条长长的尾巴。\n\n思索再三，我还是决定把代码伪装成IDAT块，插入到最后一个IDAT和IEND之间，且，如果代码很大，就切成片段，插入到多个png图片中，以保证起码看上去显得很和谐。比如IHDR中width是720，height是1280，所以IDAT中，只有720x1280=921,600个像素会被显示出来，后面的IDAT是不会影响png解析的。但是为了以防万一，在插入之前，是需要把代码加密的，一般是和一个数字做异或操作，等到解析时，从png中取出代码，再与同一个数字做异或操作即可，这样一来，即便是被一些小机灵鬼发现端倪，找到隐藏的秘密，也不至于造成代码泄漏。\n\n除此之外，还有一些简单的方式，比如直接把代码的.jar改成.ttf，伪装成字体文件，放在项目中，我觉得这种方式就是在靠天吃饭，看命，但凡遇到个勤劳的人，就会发现这个ttf并不简单，再顺着这个ttf找引用，顺藤摸瓜，就让人抄了老巢。\n\n### 补充\n最新发现，在开启了minifyEnabled后，drawable里的图片会被压缩，这个事是aapt在做，根绝结果来看，它是根据png IHDR里的长和宽计算出数据的总长度，然后把超出的IDAT切掉。如果不想被无情阉割，那么就要修改IHDR里的长和宽，让额外的IDAT成为png的一部分，但是这样的问题是，无法正常解析出额外的部分的像素值，折衷的策略是，找一个View引用这张图，但是这个View永远不会显示。还有个退而求其次的方式，那就是放到raw目录中，这个目录下的图片不会被阉割，都是完整的。\n\n### 附录\nhttps://www.cnblogs.com/esestt/archive/2007/08/09/848856.html\n一个介绍crc算法原理的文章，写的非常详细，才看了一遍我就看明白了，虽然也没算出来，但我觉得这和文章没有关系，一定是我的问题，遇到问题要多反思自己。\n\n最后，再推荐一个网站，用来压缩png图片，无损或接近无损，[TinyPng](https://tinypng.com/)。但是，每次上传下载效率很差，所以有不愿透露姓名的热心市民写了一个客户端，效率指数加倍，[在这里](https://github.com/kyleduo/TinyPNG4Mac)。","tags":["Python"],"categories":["Python"]},{"title":"AndroidStudio logcat过滤器","url":"/2022/04/f58f06543ab2/","content":"\n最近在用一个红米的手机测试，简直就是个log轰炸机，果然为发热而生。\n<!--more-->\n\n一般来说，常规方式可以在logcat里限定进程，只显示当前进程的log，大多是时候这样是可以拦住不需要的log信息的，但也不是每个时候都好使，这个时候可以手动添加一些过滤器，拦住那些漏网之鱼。\n\n在logcat右边的过滤器选择菜单里，点击Edit Filter Configuration，就可以增加/删除过滤器了。它支持多个维度过滤，比如Log Tag，Log Message，Package Name，PID，Log Level，前三者还可以支持正则表达式。\n\n我用的是Log Tag和Log Message的正则过滤，二者配合效果更佳，总结下来，就是一个正则表达式，配上多个关键词。来看看正则的编写过程，\n\n首先，是开头结尾的标记\n```regex\n^$\n```\n然后，文本内容\n```regex\n^.*$\n```\n接着，从开头环视，要求不能是某个词，比如miui\n```regex\n^(?!(miui)).*$\n```\n想到，miui可能不是在第一个位置出现，再处理一下\n```regex\n^(?!.*(miui)).*$\n```\n继续，再多加几个关键词\n```regex\n^(?!.*(miui|Battery|HBM)).*$\n```\n最后，完成。\n\n经过我长达几分钟聚精会神盯着，总共找到了这么多不需要的关键词，还我一个清净的logcat\n```regex\n^(?!.*(subsystem_ramdump|NsdService|MDnsDS|system/bin/netd|subsystem_ramdu|CloudMusicNativePlayer|QSTile|MiuiNetworkPolicy|IDM-BonjourGovernor|NtpTrustedTime|netd|MI_STAT|chatty|OemNetd|Bluetooth|Battery|IdProviderImpl|ui-mini|PowerCheckerService|QtiCarrierConfigHelper|qdlights|CompatibilityInfo|MicroMsg|KeyguardUpdateMonitor|Miui|Audio|Matrix|xiaomi|libc|KeyguardIndication|PowerChecker|tycenter|hwservicemanager|CloudControlHelper|Launcher|ScreenView|HwcComposer|SDM|Ethernet|Traffic|PushService|MiBridge|StatusBar|miui|HotPool|ACDB|msm|Zeus|TeaLog|WifiService|Dhcp|Power|HBM|light|QSControl|SharedPreferences|ResolverController|cnss|systemui|mars|Track|PackageManager|Connectivity|Perf|kloadclassifie|HwBinder|Gesture|MiShare|tftp_server|SplashConfigModel|EventBus|ForceDarkHelper|Looper|ls|AggregateListener|octvm)).*$\n```","tags":["Android"],"categories":["Android"]},{"title":"获取文件的md5/sha1/sha256","url":"/2022/04/f52cc498815a/","content":"\n在网站下载文件时，经常会看到后面跟着一个校验码，它的作用是用来校验下载下来的文件是否发生改变，方式是在本地对文件用相同的算法计算效验码，如果和提供的一致，则说明文件完整且正确。\n\n<!--more-->\n\n校验码的算法有多种，常用的有md5、sha1、sha256等，MacOS上自带了几个命令可以计算出这些值。新建个文本文件a.txt，将字符串abc写入，用这个文件来测试。\n\n### 1. md5\n- md5命令\n```sh\n$ md5 a.txt\nMD5 (a.txt) = 900150983cd24fb0d6963f7d28e17f72\n```\n- openssl命令\n```sh\n$ openssl md5 a.txt\nMD5(a.txt)= 900150983cd24fb0d6963f7d28e17f72\n```\n给a.txt改个名字，你会发现结果还是一样的，甚至，直接计算字符串abc的md5，你会发现结果还是一样的\n```sh\n$ mv a.txt ab\n$ md5 ab\nMD5 (ab) = 900150983cd24fb0d6963f7d28e17f72\n\n$ md5 -s 'abc'\nMD5 (\"abc\") = 900150983cd24fb0d6963f7d28e17f72\n```\n由此可以验证，md5计算的是文件内容的校验值，只要内容不变，不管以何种形式，最终结果都是一致的。\n\n### 2. sha\nSecure Hash Algorithm，安全哈希算法，本质上和md5类似。它有多种类型SHA-1、SHA-224、SHA-256，等。查一查百科，可以知道，后者出现的原因，是因为前者可以被破解，虽多是碰撞方式，但也是能破解，所以一个被破解，就设计更复杂的算法，久而久之就有了这么多种，相信随着时间发展，科技进步，后续会有更多的类型出现。\n- shasum命令\n```sh\n$ shasum -a 1 a.txt\na9993e364706816aba3e25717850c26c9cd0d89d  ab\n\n$ shasum -a 256 a.txt\nba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad  ab\n```\n参数-a，指定算法类型，默认是SHA-1，可选值有1，224，256，384，512，512224，512256，可以通过`shasum -h`命令查看\n- openssl命令\n```sh\n$ openssl sha1 a.txt\nSHA1(ab)= a9993e364706816aba3e25717850c26c9cd0d89d\n\n$ openssl sha256 a.txt\nSHA256(ab)= ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad\n```\n第二个参数sha1，就是用来指定算法，openssl毕竟是老大，支持的比shasum多了很多，可以通过`openssl sha1 -h`查看\n\n### 3. 其他\n这里多说一句，这几个命令都支持管道方式，也就是可以对上一个命令的结果，直接计算目标值\n```sh\n$ cat a.txt | md5\n900150983cd24fb0d6963f7d28e17f72\n\n$ cat a.txt | openssl md5\n900150983cd24fb0d6963f7d28e17f72\n\n$ cat a.txt | shasum -a 256\na9993e364706816aba3e25717850c26c9cd0d89d  -\n\n$ cat a.txt | openssl sha256\na9993e364706816aba3e25717850c26c9cd0d89d\n```","tags":["Linux","MacOS"],"categories":["MacOS"]},{"title":"keytool命令使用","url":"/2022/04/283f20eed8de/","content":"\n之前生成签名时，都是在Android Studio里点，点几下一个签名就出来了，作为一个开发者，学会使用keytool工具，手动进行一些签名相关的操作，如生成、查看、导出等，还是很能提供很多方便的。\n\n<!--more-->\n\njava key store的管理方式为，签名一个应用需要一个key，一个key存在于一个keystore中，一个keystore中可以存在多个key。keystore拥有密码，同时，key也拥有密码。二者之间的关系可以这样理解，keystore相当于一个大房子，key则相当于房子里的一个房间，房子里可以有多个房间，进入房子需要钥匙，也就是密码，再想进入到某个房间，也需要这个房间的钥匙，也就是密码。不过，话说回来，一般常用的方式，都是一对一的形式，也就是一个keystore只存储一个key，这个key只用来签名一个应用，没有将keystore中的store的价值体现出来。\n\n### 1. 支持的命令\n\nkeytool提供了很多的命令，通过help可以查看，其中，常用的只有生成、查看、导入导出，其他的就不说了\n\n```sh\n$ keytool help\nIllegal option:  help\nKey and Certificate Management Tool\n\nCommands:\n\n -certreq            Generates a certificate request\n -changealias        Changes an entry's alias\n -delete             Deletes an entry\n -exportcert         Exports certificate\n -genkeypair         Generates a key pair\n -genseckey          Generates a secret key\n -gencert            Generates certificate from a certificate request\n -importcert         Imports a certificate or a certificate chain\n -importpass         Imports a password\n -importkeystore     Imports one or all entries from another keystore\n -keypasswd          Changes the key password of an entry\n -list               Lists entries in a keystore\n -printcert          Prints the content of a certificate\n -printcertreq       Prints the content of a certificate request\n -printcrl           Prints the content of a CRL file\n -storepasswd        Changes the store password of a keystore\n\nUse \"keytool -command_name -help\" for usage of command_name\n```\n\n### 2. 生成\n\n使用genkeypair命令\n\n```sh\nkeytool -genkeypair -alias key0 -keypass 123456 -keystore test.jks -storepass 1234 -keyalg RSA -validity 2000 -keysize 2048 -dname \"CN=abc,OU=def\"\n```\n\n参数说明\n\n- alias：给key起个名字，一个keystore中key的名字不允许重复\n- keypass: 给key设置一个密码\n- keystore：生成的key要存放的目标keystore，如果不存在则会创建\n- storepass：keystore的密码，访问keystore就需要密码\n- keyalg：生成使用的算法，默认是DSA，常用RSA\n- validity：key的有效期，单位是天\n- keysize：key的长度，RSA2048，DSA2014，EC256，DES56，AES128\n- dname：key的详细信息，完整的是：CN=名字与姓氏,OU=组织单位名称,O=组织名称,L=城市或区域名称,ST=州或省份名称,C=单位\n\n### 3. 查看\n\n使用list命令，这个命令会把keystore中所包含的所有key都展示出来\n\n```sh\nkeytool -list -keystore test.jks -storepass 123456 -v\n```\n\n参数说明\n\n- keystore：要查看的keystore\n- storepass：keystore的密码\n- v：verbose 展示所有信息\n- rfc：以rfc的格式展示，和-v不能同时使用\n\n### 4. 导出\n\n使用exportcert命令，导出的是一个证书文件，也就是key\n\n```sh\nkeytool -exportcert -alias key0 -keystore test.jks -storepass 123456 -file key0.crt\n```\n\n参数说明\n\n- alias：要导出的key的名字\n- keystore：同上\n- storepass：同上\n- file：导出的文件\n\n### 5. 导入\n\n使用importcert命令，将一个crt文件，也就是key，导入到keystore中\n\n```sh\nkeytool -importcert -alias key0 -keypass 123456 -file key.crt -keystore test.jks -storepass 123456\n```\n\n参数说明\n\n- alias：给导入的key起个名字，不能和已存在的重复\n- keypass：给导入的key设置个密码\n- file：待导入的key的证书\n- keystore：目标keystore\n- storepass：密码\n\n### 其他\n\ngenkeypair适用非对称加密，包括私钥和公钥。genseckey适用于对称加密，只有一个密钥。jks文件只能存储非对称加密。","tags":["Android","Java"],"categories":["Android"]},{"title":"shell常用语法","url":"/2022/04/8be3dad076cd/","content":"平常经常写一些shell脚本，来执行一些自动化任务，比如打包、连接等，记录下常用到的语法和命令。\n<!--more-->\n\n### 1. 格式和运行\n格式是指开头第一行\n```sh\n#! /bin/bash\n```\n其中的#!叫shebang，也叫hashbang，后面跟着的这个脚本解释器的绝对路径，我的电脑上用的是bash。运行的时候直接使用sh后面跟上脚本的名字即可，如果给脚本文件加上可执行的权限，用./也可执行，如果不写第一行的话，你会发现也可以执行，如果不光是给自己用，建议还是要写上的。\n\n### 2. 获取参数\n有时一些参数是不固定的，需要每次运行的时候传入。方式有两种，一种是直接在后面写参数的值，如\n```sh\nsh command.sh arg1 arg2 arg3\n```\n这种方式在读取时，是凭借参数的位置顺序读取的，$0为command.sh，$1为参数一arg1，$2为参数二arg2，依次类推。这种方式方便传入和读取，但是受到位置的限制，有时可能只需要传入参数二，而参数一使用缺省值便可，这时使用-argName的方式会更方便，按需指定并传入，如\n```sh\nsh command.sh -a argA -b argB -c argC\n```\n读取时，要这样，getopts，即get options，获取所有的可选参数，通过循环读取每个参数的值\n```sh\nwhile getopts \"a:b:c:\" opt\ndo\n    case $opt in\n        a ) argA=$OPTARG ;;\n        b ) argB=$OPTARG ;;\n        c ) argC=$OPTARG ;;\n    esac\ndone\n```\n\n### 3. 条件判断\n判断是脚本中最常见的命令语句了，基本语法为\n```sh\nif [ command ]; then\n    # do something\nelif [ command ]; then\n    # do something\nelse\n    # do something\nfi\n```\n其中的command有很多，按类型可以分为：判断文件/目录、判断字符串和判断数值大小，举几个常用的\n```sh\n# 文件/目录\n[ -e FILE ] 文件存在 \n[ -s FILE ] 文件存在且长度不为0\n[ -f FILE ] 普通文件存在 -b：二进制文件 -c：字符文件 -r：可读文件 -x：可执行文件\n[ -d DIR ] 目录存在\n[ FILE1 -nt FILE2 ] newer than，也就是1比2更新 同理，-ot：older than\n\n# 字符串\n[ -z STRING ] zero长度为0\n[ -n STRING ] not zero长度不为0，-n也可以省略，即等同于 [ STRING ]\n[ S1 = S2 ] 相同，同理 !=为不同\n\n# 数值\n[ INT1 -eq INT2 ] equals，相等，同理 -ne：not equals\n[ INT1 -gt INT2 ] greater than,大于，也可以写成大于号: >，同理 -lt：less than\n[ INT1 -ge INT2 ] greater or equals, 即为>=，同理 -le：<= 小于等于\n\n# 多个条件\n[ (条件1) -a (条件2) ] all，与，也可以写成 &&\n[ () -o () ] or，或，也可以写成 ||\n[ ! () ] not，非\n```\n\n### 4. 服务器\nssh连接服务器，如果已经把自己的公钥id_rsa.pub添加到了服务器的authorized_keys里，那么可以直接连接，就可以了\n```sh\nssh username@server-ip\n```\n如果没有添加，则需要指定服务器的私钥的pem文件作为参数\n```sh\nssh -i identification.pem username@server-ip\n```\n原理很简单，一是服务器信任了自己的公钥，二是拿着服务器的私钥的pem，pem的获取方式为\n```sh\n# 服务器生成公钥匙私钥对，这会得到一个私钥private，和公钥private.pub\nssh-keygen\n# 转换私钥，传入私钥，得到pem格式，凡是拿着这个pem的客户端都可以连接\nopenssl rsa -in private -outform pem > private.pem\n```\n当然，光连上服务器不是目的，这些如果写到shell脚本里会中断执行，而我的目的是在服务器上执行命令，连到服务器只是前提，若执行命令，如下\n```sh\nssh username@server-ip \"[command]\"\n# e.g。\nssh user@server-ip \"cd documents && ls -la\"\n```\n有时还会需要在本地和远程之间传递文件命令，从本地到远程如下（远程到本地就反过来），注意server-ip后面的冒号，\n```sh\nscp [options] /local/source/file/path user@server-ip:/path/to/destination\n-C 要大写，压缩\n-P 要大写，端口号，默认22\n-r recursive递归\n-p 保留访问修改时间\n```\n服务器的IP地址经常会变，每次通过ssh连接一个不存在于.ssh/known_hosts中的ip时，都会弹出一个警告，问是否要将这个正在连接的主机添加到已知设备中，中断自动化脚本的执行。\n\n在这里，都要连接登陆了，所以肯定是要加的，可以通过指定一个参数，让其自动添加，而不中断自动化流程\n```shell\nssh -o StrictHostKeyChecking=no -i identificaiton.pem username@host\n```\n\n### 5. 编译shell脚本\n有时写完一个shell脚本，需要给别人使用，但是又不想让别人看到里面的代码，可能因为里面有重要数据，也可能没有为什么，就是不想，这时可以把shell脚本编译成可执行文件，这样一来，既可以执行，但又无法查看了。一共有两种方式，一是系统自带的gzexe，二是使用shc命令，\n```sh\ngzexe command.sh\n```\n这会在目录下生成两个文件，一个是command.sh，另个是command.sh~，前者是压缩之后的，带～的是原文件，打开压缩之后的文件，可以发现里面有不少内容还是可以看懂的，尽管多数都不沾边了。\n```sh\nshc -f command.sh\n```\n这也会在目录下生成两个文件，一个是command.sh.x，这是可执行文件，另个是command.sh.x.c，这是个c文件，打开可执行文件后，会发现完全看不懂，都是乱码，推测可能先生成了c文件，然后再将c编译成二进制可执行文件。[这是shc的github地址](https://github.com/neurobin/shc)\n\n### 6. 脚本里调用其他脚本\n当有多个shell文件，其中相互调用的时候，要用source命令\n```shell\n#! /bin/bash\necho 'first shell scripts'\n\nsource other.sh\n```\n虽然写在多个shell文件里，但是因为运行在同一个shell会话中，所以变量是可以共用的，也就是first里声明的变量，在other里可以读取，我一般用这种方式来处理脚本的参数，当一个脚本需要多个参数时，就把这些参数都单独写在一个shell里，然后再最后通过source调用真正的执行文件就好。\n\n### 7. $相关的变量说明\n\n变量|含义\n:|:\n$0| 脚本的名字，即文件名\n$n(n ≥ 1)|参数名字\n$#|传给脚本的参数个数\n$*|传来的所有参数\n$@|传来的所有参数\n$?|上个命令的退出值\n$$|shell进程ID\n\n其中，`$@`和`$*`，没有引号包围时，二者完全一样，当有双引号包围时，`$@`依然无变化，而`$*`则是把所有参数合并成了一个变量\n```shell\nsh test.sh p1 p2 p3\n\n# 读取参数代码\nfor p in []\ndo\n    echo $p\ndone\n\n$@ $* \"$@\" 输出的都是\np1\np2\np3\n\n\"$*\" 输出的是 p1 p2 p3\n```","tags":["shell"],"categories":["Linux"]},{"title":"JNI使用总结","url":"/2022/03/4cd01e062b9d/","content":"\n由于业务特殊，最近的需求都是藏代码，把业务逻辑代码藏到工程里的各个层面，这就离不开JNI开发了，这篇来具体说一说。\n\n<!--more-->\n\nJNI（Java Native Interface），是Android开发中在原生java层调用c/c++ native方法的一种方式，也可以在native层调用java层的方法。JNI库一般是以扩展名为so（shared object）的文件存在，通过`System.load`就可以将其加载到应用进程中，之后java层和native层便可以相互调用。\n\n### 1. 基础数据类型\n\n既然可以互相调用，那么二者在数据结构上的就有着对应关系，具体如下：\n\n| Java    | JNI      | Desc           |\n| ------- | -------- | -------------- |\n| boolean | jboolean | usigned 8 bit  |\n| byte    | jbyte    | unsigned 8 bit |\n| char    | jchar    | unsigned 8 bit |\n| short   | jshort   | signed 16 bit  |\n| int     | jint     | signed 32 bit  |\n| long    | jlong    | signed 64 bit  |\n| float   | jfloat   | signed 32 bit  |\n| double  | jdouble  | signed 64 bit  |\n\n### 2. javah方式\n在java文件NativeLib.java中，声明一个native修饰的方法，也可以声明多个，然后在这个文件所在目录执行\n```sh\njavac -h . NativeLib.java\n```\n于是，在这个目录下就会生成NativeLib.class文件，和一个.h的header文件，你会发现里面都是些又臭又长的函数声明，然后在cpp文件中实现header文件里的函数，将其打包成so文件，在程序运行时，jvm便可以根据名字找到native修饰的方法对应的jni中的函数，这是写在jvm介绍里面的，具体的[这个Oracle文档](https://docs.oracle.com/javase/6/docs/technotes/guides/jni/spec/design.html#wp615)里有介绍。\n\n### 3. JNI_OnLoad方式\n这是个特殊的函数，在调用System.load方法加载so库文件后，最终会调用库文件里的JNI_OnLoad方法，前提是已定义了这个方法\n```java\nSystem.load -> Runtime.loadLibrary -> nativeLoad(java_lang_Runtime.cpp) -> \nDalvik_java_lang_Runtime_nativeLoad -> dvmLoadNativeCode(dalvik/vm/Native.cpp) ->\n- dlopen(pathName, RTLD_LAZY) (把so mmap到进程空间，并把func等相关信息填充到soinfo中)\n- dlsym(handle, \"JNI_OnLoad\") (查找JNI_InLoad) 方法，找到则调用\n- JNI_OnLoad\n```\n所以，我们可以在这个函数中注册函数，JNI也提供了注册函数的方法RegisterNatives。这种方式需要两步，首先找到目标Class，然后再调用Register方法即可，以下是Android官网[示例代码](https://developer.android.com/training/articles/perf-jni#native-libraries)\n```cpp\nJNIEXPORT \njint JNI_OnLoad(JavaVM* vm, void* reserved) {\n    JNIEnv* env;\n    if (vm->GetEnv(reinterpret_cast<void**>(&env), JNI_VERSION_1_6) != JNI_OK) {\n        return JNI_ERR;\n    }\n\n    // Find your class. JNI_OnLoad is called from the correct class loader context for this to work.\n    jclass c = env->FindClass(\"com/example/app/package/MyClass\");\n    if (c == nullptr) return JNI_ERR;\n\n    // Register your class' native methods.\n    static const JNINativeMethod methods[] = {\n            {\"nativeFoo\", \"()V\", reinterpret_cast<void*>(nativeFoo)},\n            {\"nativeBar\", \"(Ljava/lang/String;I)Z\", reinterpret_cast<void*>(nativeBar)},\n    };\n    int rc = env->RegisterNatives(c, methods, sizeof(methods)/sizeof(JNINativeMethod));\n    if (rc != JNI_OK) return rc;\n\n    return JNI_VERSION_1_6;\n}\n```\n注意，RegisterNatives做的事是把本地函数和一个java类方法关联起来，不管之前是否关联过，一律会把之前的替换掉，也就是多次给一个java类关联本地函数时，只有最后一次关联的是有效的。\n\n### 4. 两种方式对比\n如果没有调用Register方法提前注册，则无法把so中实现的函数在进程中的地址增加到ClassObject中的directMethods中，那么只有到了调用native方法时，才会解析这些又臭又长的javah风格的函数，这个事在dumResolveNativeMethod(dalvik/vm/Native.cpp)中进行，根据native方法签名，在所有打开的so中寻找函数实现，找到后并调用，所以从调用效率上来看，Register更高效。\n\n### 5. 方法签名\n上面提了好几次的方法签名，这来说一说。简单说，方法签名就是由方法返回值类型和参数类型组成的一个字符串：”(参数列表)返回值“，每种类型都有一个唯一的标记，如下\n\n字符|数据类型|说明\n:|:|:\nV|void|方法返回值\nZ|boolean|\nB|byte|\nC|char|\nS|short|\nI|int|\nJ|long|\nF|float|\nD|double|\n[|数组|以[开头，配合其他的特殊字符，表示对应数据类型的数组，几个[表示几维数组\nL全类名|引用类型|以L开头、;结尾，中间是引用类型的全类名\n\n如果懒得写，还可以用javap命令，注意这里传入的是class文件，所以要先用javac编译一下\n```sh\njavap -p -s NativeLib.class\n```\n\n### 6. CMakeLists.txt\n用Android Studio创建NativeLibrary时，会自动生成CMake文件。根据官网说，NDK构建一共有三种方式：基于Make的ndk-build、CMake和已经弃用的独立工具链，[原文在这](https://developer.android.com/ndk/guides/build)。可见AS默认使用的CMake方式，自动生成的CMakeLists.txt文件里写了很详细的介绍，这里直接拿过来看一看\n```cmake\n# For more information about using CMake with Android Studio, read the\n# documentation: https://d.android.com/studio/projects/add-native-code.html\n\n# Sets the minimum version of CMake required to build the native library.\n\ncmake_minimum_required(VERSION 3.18.1)\n\n# Declares and names the project.\n\nproject(\"nativelib\")\n\n# Creates and names a library, sets it as either STATIC\n# or SHARED, and provides the relative paths to its source code.\n# You can define multiple libraries, and CMake builds them for you.\n# Gradle automatically packages shared libraries with your APK.\n\nadd_library( # Sets the name of the library.\n             nativelib\n\n             # Sets the library as a shared library.\n             SHARED\n\n             # Provides a relative path to your source file(s).\n             nativelib.cpp )\n\n# Searches for a specified prebuilt library and stores the path as a\n# variable. Because CMake includes system libraries in the search path by\n# default, you only need to specify the name of the public NDK library\n# you want to add. CMake verifies that the library exists before\n# completing its build.\n\nfind_library( # Sets the name of the path variable.\n              log-lib\n\n              # Specifies the name of the NDK library that\n              # you want CMake to locate.\n              log )\n\n# Specifies libraries CMake should link to your target library. You\n# can link multiple libraries, such as libraries you define in this\n# build script, prebuilt third-party libraries, or system libraries.\n\ntarget_link_libraries( # Specifies the target library.\n                       nativelib\n\n                       # Links the target library to the log library\n                       # included in the NDK.\n                       ${log-lib} )\n```\nfind_library就是从ndk里找，具体位置在\n```sh\n~/Library/Android/sdk/ndk/21.4.7075529/platforms/android-30/arch-x86_64/usr/lib64\n```\n名字掐头去尾，所以log库对应的就是这个目录下的liblog.so文件。同时，build.grade里也多了两个块，分别在android里，指定了版本和路径，和android的defaultConfig里，可以添加编译时的配置\n```gradle\nandroid {\n    defaultConfig {\n        externalNativeBuild {\n            cmake {\n                cppFlags \"\"\n            }\n        }\n    }\n\n    externalNativeBuild {\n        cmake {\n            path \"src/main/cpp/CMakeLists.txt\"\n            version \"3.18.1\"\n        }\n    }\n}\n```\n\n### 7. 几个关键字 JNIEXPORT JNICALL extern\n- JNIEXPORT和JNICALL\n这是两个宏定义，在不同平台对应不同的定义。JNIEXPORT的作用是保证在本库中声明的函数能够在其他项目中可以调用，一般export的作用都是如此，而JNICALL则是用于定义函数入栈规则和堆栈清理规则，[这篇文章有详细说明](https://blog.csdn.net/shulianghan/article/details/104072587)。\n\n- extern\n它有两个作用，一个是用来修饰变量或是函数，这时它的作用就是声明函数或全局变量的作用范围的关键字，其声明的函数和变量可以在本模块或是其他模块中使用。虽然它只是声明，但在编译阶段，找不到定义也不会报错，因为连接器在连接阶段会在生成的目标代码中找到定义。另个作用是和“C”一起连用，此时它的作用是告诉编译器用C的规则编译而不是C++的规则，因为C++支持重载，所以编译后的名字是不同的。例如，void foo(int x, int y);，C编译器编译后在符号库中的名字为_foo，而C++编译后的结果是_foo_int_int之类的名字，具体取决于编译器的类型，所以，如果把一个用C编译的目标代码和一个用C++编译器编译的目标代码进行链接，就会出现连接失败的错误。同时，只有C++编译器认识extern \"C\"，常用写法为\n```cpp\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n// code here\n#ifdef __cplusplus\n}\n#endif\n```\n\n### 8. 指针void*\n指针是种常用的形式，提供了很多便利，如`int*`为int型指针，`char*`为字符型指针，经常还会遇到一种指针，`void*`。指针存储的是地址，它本身的大小就是系统寻址的大小，不同类型的指针的所占用的内存大小都是一样的，那为什么还要区分类型呢？从某个角度来看，指针的类型可以理解为它的跳跃能力，比如一个int类型的指针在加1后，会指向紧邻的下一个int，一个int按照占用4个字节来计算的话，那么它的跳跃能力就是4个字节，同理，一个long型的指针在加1后，也会指向紧邻的下一个long，一个long占用8个字节，那么它的跳跃能力就是8个字节。这样来看的话，void类型的指针就是跳跃能力未知的指针，它需要我们手动强转之后，才具有跳跃能力，强转为int型指针后，跳跃能力为4字节，转为long则为8字节。多用于通用函数的参数，比如memcpy，不关心传入是什么类型的指针，我只管把src位置的🈯️数量的字节复制到dst，即可。`void*`就是个这样的存在。\n\n### 9. 反射调用\n在JNI里调用java的方法，基本都是通过反射的方式。先获取jclass，通过jclass获取jmethod或者jfield，然后再调用方法或字段\n```cpp\n// 获取class，JNI提供两种方式，通过方法名，或者通过jobject\njclass jc = env->FindClass(\"java/lang/String\");\njclass jc = env->GetObjectClass(jo);\n\n// 获取method\njmethodID jm = env->GetMethodID(jc, \"method name\", \"method signature\");\njmethodID jm = env->GetStaticMethodID(jc, \"method name\", \"method signature\");\n\n// 获取字段\njfieldID jf = env->GetFieldID(jc, \"field name\", \"field signature\");\njfieldID jf = env->GetStaticFieldID(jc, \"field name\", \"field signature\");\n\n// 方法调用 每种返回值类型JNI都有一个对应的方法\nenv->CallVoidMethod(jo, jm);\njobject jo = env->CallObjectMethod(jo, jm, methodArg);\n// 同时，每种类型都有一个静态方法对应的方法\nenv->CallStaticObjectMethod(jc, jm, methodArg);\n\n// 字段调用，同方法\njint i = env->GetIntField(jo, jf);\n// 静态字段同理\njint i = env->GetStaticIntField(jc, jf);\n\n```\n\n\n### 附录\n- https://blog.csdn.net/fireroll/article/details/50102009\n- https://blog.csdn.net/kgdwbb/article/details/72810251\n- https://www.jianshu.com/p/1229580b2356\n- https://www.jianshu.com/p/6cbdda111570\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["Android","JNI"],"categories":["Android"]},{"title":"Android基础之Service","url":"/2022/03/324ae03bb52e/","content":"\nService的使用。\n\n<!--more-->\n### 1. 启动方式\nService有两种启动方式，startService和bindService。\n\n### 2. 生命周期\n这里应该放一张官网的图，但是加图有些麻烦，还是用文字代替吧。\n\nService在通过startService启动时：onCreate -> onStartCommand。一个Service系统只会创建一个实例，多次调用start方法时，onCreate不会重复调用，只在第一次创建时调用一次，而onStartCommand会被多次调用。停止时调用stopService，此时会调用onDestroy\n\nService在通过bindService启动时：onCreate -> onBind，onCreate在创建时调用，Service是用来通过服务的server，想要bind Service的是client。一个server可以同时给多个client提供服务。只有在client第一次调用bindService时，才会回调onBind方法。当client调用unbindService时，此时会回调Service的onUnbind方法，当此server的client数量为0时，会调用onDestroy进行销毁。\n\n混合调用时，即创建一个Service实例后，既调用过startService，也调用过bindService，那么这时即便bind的client为0时，Service也不会停止，只有通过stopService才能停止该Service，可以理解为start的等级更高些。\n\n### 3. onStartCommand(intent: Intent?, flags: Int, startId: Int): Int\n这个方法有3个参数1个返回值，摘点官方文档的介绍\n- intent：启动时，启动组件传递过来的Intent，如Activity可利用Intent封装所需要的参数并传递给Service\n- flags: 表示启动请求时是否有额外数据，可选值有 0，START_FLAG_REDELIVERY，START_FLAG_RETRY，0代表没有，它们具体含义如下：\n  - START_FLAG_REDELIVERY: 这个值代表了onStartCommand方法的返回值为START_REDELIVER_INTENT，而且在上一次服务被杀死前会去调用stopSelf方法停止服务。其中START_REDELIVER_INTENT意味着当Service因内存不足而被系统kill后，则会重建服务，并通过传递给服务的最后一个 Intent 调用 onStartCommand()，此时Intent时有值的。\n  - START_FLAG_RETRY: 该flag代表当onStartCommand调用后一直没有返回值时，会尝试重新去调用onStartCommand()。\n- startId: 指明当前服务的唯一ID，与stopSelfResult (int startId)配合使用，stopSelfResult 可以更安全地根据ID停止服务。\n\nonStartCommand的返回值int类型，它有三种可选值， START_STICKY，START_NOT_STICKY，START_REDELIVER_INTENT，它们具体含义如下：\n- START_STICKY: 当Service因内存不足而被系统kill后，一段时间后内存再次空闲时，系统将会尝试重新创建此Service，一旦创建成功后将回调onStartCommand方法，但其中的Intent将是null，除非有挂起的Intent，如pendingintent，这个状态下比较适用于不执行命令、但无限期运行并等待作业的媒体播放器或类似服务。\n- START_NOT_STICKY: 当Service因内存不足而被系统kill后，即使系统内存再次空闲时，系统也不会尝试重新创建此Service。除非程序中再次调用startService启动此Service，这是最安全的选项，可以避免在不必要时以及应用能够轻松重启所有未完成的作业时运行服务。\n- START_REDELIVER_INTENT: 当Service因内存不足而被系统kill后，则会重建服务，并通过传递给服务的最后一个 Intent 调用 onStartCommand()，任何挂起 Intent均依次传递。与START_STICKY不同的是，其中的传递的Intent将是非空，是最后一次调用startService中的intent。这个值适用于主动执行应该立即恢复的作业（例如下载文件）的服务。\n\n首次startService时，flags的值是0，其他情况启动时，flags的值根据其返回值决定。\n\n### 4. startService示例\n```kotlin\n// Sevice，作为四大组件之一，需要在AndroidManifest中声明\nclass SampleService : Service() {\n\n    val TAG = SampleService::class.java.canonicalName\n\n    override fun onCreate() {\n        super.onCreate()\n        Log.d(TAG, \"on create invoked\")\n    }\n\n    override fun onStartCommand(intent: Intent?, flags: Int, startId: Int): Int {\n        Log.d(TAG, \"on start command invoked, flag:${flags}\")\n        return super.onStartCommand(intent, flags, startId)\n    }\n\n    override fun onDestroy() {\n        super.onDestroy()\n        Log.d(TAG, \"on destroy invoked\")\n    }\n}\n\n// 在Activity中启动\nval intent = Intent(this, SampleService::class.java)\nstartService(intent)\n\n// 在Activity中停止\nvar intent = Intent(this, SampleService::class.java)\nstopService(intent)\n```\n\n### 5. bindService示例，同一进程\n```kotlin\n// BindService\nclass BindService : Service() {\n\n    val TAG = BindService::class.java.canonicalName\n\n    private lateinit var runner: Thread\n\n    // 写一个Binder的子类，用来返回给client\n    inner class ServerBinder : Binder() {\n\n    \t// 在Binder中写一个获取server的方法，当client拿到Binder时，通过\n    \t// 这个方法就可以获取到server实例\n        fun getService() : BindService {\n            return this@BindService\n        }\n    }\n\n    override fun onCreate() {\n        super.onCreate()\n        Log.d(TAG, \"on create invoked\")\n    }\n\n    override fun onBind(intent: Intent?): IBinder? {\n        Log.d(TAG, \"on bind invoked\")\n        return ServerBinder()\n    }\n\n    fun getData() : Int = 4\n\n    override fun onUnbind(intent: Intent?): Boolean {\n        Log.d(TAG, \"on unbind invoked\")\n        return super.onUnbind(intent)\n    }\n\n    override fun onDestroy() {\n        super.onDestroy()\n        Log.d(TAG, \"on destroy invoked\")\n        runner.interrupt()\n    }\n}\n\n// 在Activity中，创建一个ServiceConnection，用来响应连接到Service的回调\nprivate val conn = object : ServiceConnection {\n\n    // 连接成功后回调，返回的Binder就是Service中onBinder的返回值\n    override fun onServiceConnected(name: ComponentName?, service: IBinder?) {\n        Log.d(TAG, \"on service connected\")\n        val binder = service as BindService.ServerBinder\n        val server = binder.getService()\n        val data = server.getData()\n    }\n\n    // Android 系统会在与服务的连接意外中断时（例如当服务崩溃或被终止时）调用该方法。注意:当客户端取消绑定时，系统“绝对不会”调用该方法。\n    override fun onServiceDisconnected(name: ComponentName?) {\n        Log.d(TAG, \"on service disconnected\")\n    }\n}\n\n// 绑定\nval intent = Intent(this, BindService::class.java)\nbindService(intent, conn, BIND_AUTO_CREATE)\n\n// 解除绑定\nval intent = Intent(this, BindService::class.java)\nunbindService(conn)\n```\n\n### 6. bindService示例，不同进程\n想要实现client和server的双向通信，那么就需要双方都有发送/接收消息，即Handler+Messenger\n```kotlin\n// MessengerService，同样需要在AndroidManifest中声明，同时增加process=\":process\"属性来指定进程\nclass MessengerService : Service() {\n\n    val TAG = MessengerService::class.java.canonicalName\n\n    // Handler用来处理client发送过来的消息\n    private val handler =  object : Handler(Looper.myLooper()!!) {\n\n        override fun handleMessage(msg: Message) {\n            Log.d(TAG, \"service handle message:${msg.what}\")\n            val reply = Message.obtain()\n            reply.what = 45456\n            msg.replyTo.send(reply)\n        }\n    }\n\n    // Messenger用来发送消息给client\n    private val messenger = Messenger(handler)\n\n    override fun onCreate() {\n        super.onCreate()\n        Log.d(TAG, \"messenger service on create\")\n    }\n\n    override fun onBind(intent: Intent?): IBinder? {\n        Log.d(TAG, \"messenger service on bind\")\n        return messenger.binder\n    }\n\n    override fun onUnbind(intent: Intent?): Boolean {\n        Log.d(TAG, \"messenger service on unbind\")\n        return super.onUnbind(intent)\n    }\n\n    override fun onDestroy() {\n        super.onDestroy()\n        Log.d(TAG, \"messenger service on destroy\")\n    }\n}\n\n// Activity中，同上，Handler用来处理server发送的消息，Messenger用来发消息给server\nprivate val handler = object : Handler(Looper.getMainLooper()) {\n    override fun handleMessage(msg: Message) {\n        Log.d(TAG, \"client handle message:${msg.what}\")\n    }\n}\n\nprivate val messenger = Messenger(handler)\n\nprivate val ipcConn = object : ServiceConnection {\n\n    override fun onServiceConnected(name: ComponentName?, service: IBinder?) {\n        val server = Messenger(service)\n        val msg = Message.obtain()\n        msg.what = 12123\n        msg.replyTo = messenger\n        server.send(msg)\n    }\n\n    override fun onServiceDisconnected(name: ComponentName?) {\n    }\n}\n\n// 绑定Service\nval intent = Intent(this, MessengerService::class.java)\nbindService(intent, ipcConn, BIND_AUTO_CREATE)\n\n// 解除绑定\nval intent = Intent(this, MessengerService::class.java)\nunbindService(ipcConn)\n```\n\n### 7. ForegroundService前台服务\n通俗理解，后台任务多是用来做一些不需要用户看到的任务，比如静默下载，而前台任务则是做些需要给用户展示一些提示的任务，比如下载文件的进度条、播放音乐的进度条，等。摘一段官方的说明：\n> 前台服务被认为是用户主动意识到的一种服务，因此在内存不足时，系统也不会考虑将其终止。 前台服务必须为状态栏提供通知，状态栏位于“正在进行”标题下方，这意味着除非服务停止或从前台删除，否则不能清除通知。例如将从服务播放音乐的音乐播放器设置为在前台运行，这是因为用户明确意识到其操作。 状态栏中的通知可能表示正在播放的歌曲，并允许用户启动 Activity 来与音乐播放器进行交互。如果需要设置服务运行于前台， 我们该如何才能实现呢？Android官方给我们提供了两个方法，分别是startForeground()和stopForeground()。\n\n可以通过onStartzCommand方法传递命令，来回切换控制服务是否置于前台，这里只演示了如何切换。\n```kotlin\n// ForegroundService\nclass ForegroundService : Service() {\n\n    val TAG = ForegroundService::class.java.canonicalName\n\n    override fun onCreate() {\n        super.onCreate()\n        Log.d(TAG, \"on service create\")\n        // 8.0出了NotificationChannel，不设置就会报错：bad notification\n        val builder = if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.O) {\n            // make channel\n            val channelId = \"default\"\n            val channel = NotificationChannel(channelId, channelId, NotificationManager.IMPORTANCE_DEFAULT)\n            val nm = getSystemService(Context.NOTIFICATION_SERVICE) as NotificationManager\n            if (nm.getNotificationChannel(channelId) == null) {\n                nm.createNotificationChannel(channel)\n            }\n            NotificationCompat.Builder(this, channelId)\n        } else {\n            NotificationCompat.Builder(this)\n        }\n        // make notification\n        builder.setSmallIcon(R.mipmap.ic_launcher)\n            .setLargeIcon(BitmapFactory.decodeResource(resources, R.mipmap.ic_launcher))\n            .setOngoing(true)\n            .setAutoCancel(false)\n            .setShowWhen(true)\n            .setContentTitle(\"Foreground Service\")\n        val notification = builder.build()\n        startForeground(1, notification)\n    }\n\n    override fun onStartCommand(intent: Intent?, flags: Int, startId: Int): Int {\n        Log.d(TAG, \"on service start command\")\n        return super.onStartCommand(intent, flags, startId)\n    }\n\n    override fun onBind(intent: Intent?): IBinder? {\n        return null\n    }\n\n    override fun onDestroy() {\n        super.onDestroy()\n        Log.d(TAG, \"on service destroy\")\n        stopForeground(true)\n    }\n}\n\n// 启动Service，启动有两种放，第一种就和正常启动无异，startService，这样启动的就是的正常的Service，只有在Service中调用startForeground后方为前台服务；\n// 第二种方式是API26，也就是8.0 Oreo新加的：startForegroundService，它和startService的区别就是，启动之后5秒内若是没有调用startFroeground，则crash\nval intent = Intent(this, ForegroundService::class.java)\nstartForegroundService(intent) // 必须在Service中调用startForeground\nstartService(intent)\n\n// 停止Service，同正常停止\nval intent = Intent(this, ForegroundService::class.java)\nstopService(intent)\n```\n\n### 8. IntentService\n和Service相比，特点是自带一个工作线程，可以用来做一些阻塞线程的任务，阻塞任务需要写在onHandleIntent里。现在已经显示弃用了，推荐使用androidx里的WorkManager\n```kotlin\n// 构造方法里面传入的是子线程的名字\nclass DIntentService : IntentService(\"download\") {\n    \n    override fun onHandleIntent(intent: Intent?) {\n        // do something\n    }\n}\n```\n\n### 9. 显示启动和隐式启动\n以上通过指定Service类的启动方式，均为显示启动。隐式启动指定Intent的action为全类名即可，此时需要service在Manifest中的exported属性为true。同一应用中两种方式均可，不同的应用只能用隐式。\n```kotlin\nval intent = Intent(ForegroundService::class.java.canonicalName)\nstartService(intent)\n```\n5.0之前隐式启动只会发送一个警告，5.0之后官方出于安全考虑禁止了隐式启动，直接报错：Service Intent must be explicit，意思就是指定的Service必须精确\n```java\nprivate validateServiceIntent(Intent service) {\n\tif (service.getComponent() == null && service.getPackage() == null) {\n\t\tif (getApplicationInfo().targetSdkVersion >= Build.VERSION_CODES.LOLLIPOP) {\n\t\t\tIllegalArgumentException ex = new IllegalArgumentException(\"Service Intent must be explicit: \" + service);\n\t\t\tthrow ex;\n\t\t} else {\n\t\t\tLog.w(TAG, \"Implicit intents with startService are not safe: \" + service + \" \" + Debug.getCallers(2, 3));\n\t\t}\n\t}\n}\n```\n解决方式，很简单，给Intent指定component，或者package，或者两者都指定，便可通过检查。\n```kotlin\n// 指定package\nval intent = Intent(ForegroundService::class.java.canonicalName)\nintent.setPackage(getPackageName())\nstartService(intent)\n\n// 指定component\nfun getExplicitServiceIntent(context: Context, intent: Intent) : Intent? {\n\tval pm = context.packageManager\n\tval resolveInfo = pm.queryIntentServices(intent, 0)\n\tif (resolveInfo == null || resolveInfo.size != 1) {\n\t\treturn null\n\t}\n\tval serviceInfo = resolveInfo[0]\n\tval packageName = serviceInfo.serviceInfo.packageName\n\tval className = serviceInfo.serviceInfo.name\n\tval component = ComponentName(packageName, className)\n\tval explicitIntent = Intent(intent);\n\texplicitIntent.component = component\n\treturn explicitIntent;\n}\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["Android","Service"],"categories":["Android"]},{"title":"Java volatile关键字","url":"/2022/03/30197999d29a/","content":"\nvolatile是Java的一个关键字，用来修饰变量，被volatile修饰的变量，在每次更新之后会立刻刷新到主内存中，令缓存行无效，其他线程从主内存读取的会是最新值，保证变量的可见性，常用于并发编程中。\n\n这么一说有些抽象，要想说明白这其中原理，还要从Java内存模型说起。\n\n<!--more-->\n\n### 1. CPU、内存和高速缓存\n我们都知道，在计算机中指令由CPU执行，这个过程就包括读取数据、操作数据和写出数据。程序在运行时，数据是存储在物理内存中的，也就是平时说的内存条。CPU在执行指令时，将数据从内存读入，操作之后，再将数据写出到内存，而CPU读写速度之快，远远超过内存的读写速度，这势必会大大拉低CPU的速度，所以高速缓存应运而生。\n\n程序在运行时，先将需要的数据复制一份到高速缓存中，等到CPU执行指令时从高速缓存中读入数据，操作完之后写出到高速缓存中，程序执行完成后，再将高速缓存中的数据刷新到内存中，这样一来更好的利用了CPU的性能，提高了整体的运行速度。\n\n这种设计，在单线程编程中是可以的，但是到了多线程并发编程时，就会有意想不到的结果。比如，两个线程同时操作内存中的一个值为0的变量，同时将其读入到各自的高速缓存中，CPU先将线程一的变量加1，结果为0+1=1，然后刷新到内存中；然后再将线程二的变量加1，由于在这个线程读入变量时并没有加1，所以读进来的值也是0，加1后为1，然后再写入到内存中，两个线程各自执行了一次加1，但最后结果却是1，问题就来了。\n\n### 2. 并发编程中的三个概念\n原子性：原子不可分割，顾名思义，一个或多个操作要么全部执行，要么就全部不执行。在Java中，对原始类型变量的读取和赋值操作是不可中断的原子操作，这里的赋值是指将一个确定的值赋给变量，如a=1，而不是将另一个变量的值赋给另一个变量，如a=b，这里面包含两步操作，需要先读取b的值，然后再将值赋给a。比如使用new关键字实例化对象时，需要先请求分配地址空间，然后再给地址空间了每一个变量赋默认值\n\n可见性：如同上面那个例子，两个线程同时修改一个变量时，之所以会出现错误的结果，是因为当线程一修改完变量的值时，线程二并不知道，以至于在一个旧的值上继续操作。多个线程同时操作一个变量，一个线程修改了它的值后，其他线程能够读到最新的值，这就是可见性，被volatile修饰的变量，就具有这种可见性。\n\n有序性：为了进一步提高执行效率，JVM虚拟机会对指令的顺讯重现排列，所以代码可能并不会按照定好先后顺序来执行代码。但这其中也有一些规定，如果语句2不依赖于语句1的结果，那么本位于后面的语句2可能会先于语句1执行，如果语句2依赖于语句1，则不会前置执行。举一个指令重排在并发编程中的问题：线程一种执行两个语句，语句1是初始化资源，语句2是将是否初始化标志位置为true，一般来说，当执行到语句2，也就是标志位为true时，就可以认为语句1已经执行过，资源已经初始化完成；线程2则是一直等待标志位，直到为true时，开始进行后续的操作。线程一中，由于只修改标志位不依赖初始化操作，所以可能会先于初始化执行，这时线程二判断已经初始化，就会开始后面的操作，而实际上并没有完成初始化，程序就不会按照设计的执行。\n\n因此，要想多线程并发时能够正确执行，就必须保证这三个特性。\n\n### 3. Java内存模型JMM（Java Memory Model）\nJava虚拟机JVM规范中定义了一种内存模型，用以来屏蔽不同硬件平台和操作系统间的差异，从而实现其跨平台的特性。简而言之，Java内存模型规定所有的变量都是存在主内存当中，每个线程都有自己的工作内存，线程对变量的所有操作都必须在工作内存中进行，而不能直接对主内存进行操作，同时，每个线程不可访问其他线程的工作内存。\n\n主内存可以看作是上面提到的物理内存，而每个线程的工作内存可以看作是高速缓存，每个线程在执行程序时，需要先将数据从主内存复制一份到自己的工作内存中，等待CPU处理完之后，再将工作内存中的数据刷回到主存中，到此执行完成。\n\n### 4. volatile在并发编程中\n第一点，原子性。volatile无法保证原子性。\n```\npublic volatile int inc = 0;\n```\n线程一和线程二同时对变量inc执行自增操作100次，能保证最后的结果是200吗？不能。可能觉得不对，刚刚不是才说过，被volatile修饰的变量在修改之后会立刻刷新回主存，同时让其他线程的工作内存中的缓存无效，那为什么执行200次结果却不是200呢？这便是volatile无法保证原子性。\n\n程序开始执行时，线程一从主存中把inc的值复制到一份到其工作内存中，此时线程一被挂起。为什么有可能会被挂起呢，因为在多线程并发编程中，分到CPU时间片的线程才能执行操作，没有分到时间片时就要挂起等待，而CPU时间片的分配是由系统决定的。这时，线程二开始执行，根据JMM同样需要将主存中inc的值复制一份到自己的工作内存中，由于此时线程一还没有修改inc的值，所以读到的还是0，然后继续执行自增操作，最后再将inc的最新值1刷回到主存中。此时线程一释放，继续执行，因为已经将inc加载进来，便不会再去加载，而是执行增加操作，得到1，最后将1刷新回主存中。\n\n因为自增操作包含读取、操作、再赋值多个操作，被或不被volatile修饰的区别在于，被修饰的变量在操作后会立即刷新到主存中，没有被修饰的变量在修饰后刷回到主存的时机不确定。每个线程只能操作自己的工作线程而不能操作其他线程的，故而主存是它们的交互通道，volatile只能保证主存中的值一定是最新的，却不能保证其他线程的值是最新，如果在中间的某个步骤被阻塞挂起，就无法保证最终结果的准确性。\n\n要解决这个问题，有多重方式，比如synchronized、Lock等，另自增操作同一时刻只有一个线程在操作便可。\n\n第二点，可见性。这一点在上面也已基本上说明，这里就不再重复。\n\n第三点，有序性。volatile能够禁止指令重排，它会形成一个内存屏障，也称内存栅栏。在volatile变量读写操作前的指令，一定会先执行，在其后面的指令一定会后执行。屏障前的指令可能会重排，但是不会越过屏障，同样，屏障后面的指令也可能会重排，但是也不会越过屏障。\n\n### 5. volatile的原理和实现机制\n观察加入vlatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令，lock前缀即位内存屏障，有3个功能：\n- 它确保屏障前后的指令不会跨越屏障\n- 它强制对缓存的修改操作立即写入主存（缓存即为线程的工作内存）\n- 如果是写操作，会导致其他CPU中对应的缓存行无效（缓存行无效后便会从主存读取，保证可见性）\n","tags":["Android","Java"],"categories":["Java"]},{"title":"Android之EventBus","url":"/2022/02/25900530192f/","content":"\n现在虽然也不再常用，但当年的风采依旧\n<!--more-->\n\n### 一. EventBus\n算是很常见了，事件总线库，采用发布/订阅模式和单例模式，用于解耦组件通信。这里主要介绍3点：注册、事件和线程。\n\n1. 注册\nEventBus是一个单例，采用注解的方式，接收事件的方法需要用@Subscribe注解标记，然后通过单例里的方法register将自己以及需要订阅的事件注册到其中，有事件到来时EventBus便会通过反射调用订阅者。\n在调用register时，有两种方式：JIT和AOT。如果使用了APT(Annotation Processor Tool)，在编译阶段所有被@Subscribe修饰的方法都会被单独处理生成对应的代码，在调用register时直接将订阅者的方法添加到集合中；如果没有使用APT，那么在调用register时，便会通过反射遍历订阅者及其父类的所有方法，找到被@Subscribe修饰的方法，然后将这些方法添加到集合中。\n各自的优缺点，看到JIT和AOT其实就很明显了，时间换空间。使用APT的会更快一些，因为省去了耗时的反射操作，但是可能会把用不到的订阅者也添加到集合中；若不使用APT则是按需添加，但是速度上就慢了一些。\n\n2. 事件\n分为两种：普通事件和粘性事件。普通事件需要先注册后才能接收，而粘性事件在发送时会被保存最后一次的事件，所以如有有人注册订阅粘性事件，那么在调用register时，会使其接收一次上一次的粘性事件。\n\n3. 线程\n在订阅时可在@Subscribe中指定接收线程，在发送事件的线程、在主线程、在后台线程、在异步线程。主线程和后台线程的事件都是顺序被处理的，而异步线程中维护了一个线程池Executors.newCachedThreadPool()，每次接收到新事件都会交给线程池处理，因此无法保证有序性，但是实效性相对更高，有得有失。\n\n4. 总结\nEventBus简单、易用，无延迟，可满足大部分开发需求，但是只限于单进程，且消息不可持久化，只限存在于内存之中。\n\n\n\n\n","tags":["Android"]},{"title":"Android通信机制Binder宏观介绍","url":"/2022/02/ba3c10e704f8/","content":"\nBinder简介，摘选自《Android系统源代码情景分析》\n\n<!--more-->\n\n### 1. 整体关系\nLinux内核的进程间通信机制：管道Pipe，信号Signal，消息队列Message，共享内存ShareMemory，插口Socket等。\n\nAndroid独特的IPC，Binder，基于CS架构，优势：进程间传输数据时，只需要执行一次复制操作，提高效率，节省内存空间。\n\n提供服务的是Server进程，访问服务的进程是Client进程，一个Server进程可以运行多个组件来（Service组件）给Client进程提供服务，一个Client进程可以运行多个组件（Client组件）来请求服务。Server进程和Client进程都维护了一个Binder线程池，用来处理进程间通信请求，可并发操作。\n\nServer进程和Client进程间的通信依靠运行在内核空间的Binder驱动程序来进行。Binder驱动程序向用户空间暴露了一个设备文件/dev/binder，使得应用程序进程可以间接地通过它来建立通信通道。\n\nService组件在启动时，会将自己注册到一个ServiceManager组件中，已便Client组件可以该组件找到它。因此，我们将ServiceManager组件称为Binder进程间通信机制的上下文管理者，同时由于它也需要与普通的Server进程和Client进程通信，我们也将它看作是一个Service组件，只不过它是一个特殊的Service组件。\n\nClient、Service和ServiceManager运行在用户空间，Binder驱动程序运行在内核空间，其中，ServiceManager和Binder驱动程序由系统负责提供，Client和Service组件由应用程序来实现。\n\nClient、Service和ServiceManager均是通过系统调用open、mmap和ioctl来访问设备文件/dev/binder，从而实现与Binder驱动程序的交互，从而达到间接地执行进程间通信的目的。\n\n每一个Service组件在Binder驱动程序中都有一个对应的Binder实体对象binder_node，用来描述它在内核中的状态。\n\n### 2. Service Manager\nService Manager是Binder进程间通信机制的核心组件之一，它扮演着Binder进程间通信机制上下文管理者的角色，同时负责管理系统中的Service组件，并且向Client组件提供获取Service代理服务对象的服务。\n\nService Manager运行在一个独立的进程中，因此，Service组件和Client组件也需要通过进程间通信机制来和它交互，也就是Binder进程间通信机制，所以，Service Manager也是一个特殊的Service组件。\n\nService Manager是由init进程负责启动的，而init进程是在系统启动时启动的，因此，Service Manager也是在系统启动时启动的。启动过程由三个步骤组成：第一步是调用函数binder_open打开设备文件/dev/binder，以及将它映射到本进程的地址空间；第二步是调用函数binder_become_context_manager将自己注册为Binder进程间通信机制的上下文管理者；第三步是调用函数binder_loop来循环等待和处理Client进程的通信请求。\n\n### 3. Service代理对象的获取过程\nService组件将自己注册到Service Manager中之后，它就在Server进程中等待Client进程将进程间通信请求发送过来。Client进程为了和运行在Server进程中的Service组件通信，首先要获得它的一个代理对象，这是通过Service Manager提供的Service组件查询服务来实现的\n","tags":["Android","Binder"],"categories":["Android"]},{"title":"Android系统启动过程","url":"/2022/01/f6c3174008b0/","content":"从按下开机键，到手机完全启动，系统做了哪些事。\n\n<!--more-->\n\n> 摘录自「Android进阶解密」。\n\n### 系统架构简介\n说到系统架构，就离不开官方的那张图，这里就不贴了。Android系统架构分为五层，从上到下依次是\n- 应用层(System Apps)、\n- 应用框架层(Java API Framework)、\n- 系统运行库层(Android Runtime, Native C/C++ Libraries)、\n- 硬件抽象层(Hardware Abstraction Layer, HAL)、\n- Linux内核层(Linux Kernel)\n\n### 系统启动流程\n1. 启动电源以及系统\n当电源按下时，将引导芯片代码从预定义的地方（固化在ROM）开始执行。加载引导程序BootLoader到RAM，然后执行。\n\n2. 引导程序BootLoader\n引导程序BootLoader是在Android操作系统开始运行前的一个小程序，它的主要作用就是把系统OS拉起来并运行。\n\n3. Linux内核启动\n当内核启动时，设置缓存、被保护存储器、计划列表、加载驱动。当内核完成西戎设置时，它首先在系统文件中寻找init.rc文件，并启动init进程。\n\n4. init进程启动\n初始化和启动属性服务，并且启动Zygote进程，也就是孵化进程\n\n5. Zygote进程启动\n创建Java虚拟机并为Java虚拟机注册JNI方法，创建服务器Socket，启动SystemServer进程。\n\n6. SystemServer进程启动\n启动Binder线程池和SystemServiceManager，并且启动各种系统服务。这其中包括WindowManagerService、PackageManagerService、CameraService、SensorService，以及ActivityManagerService等。\n\n7. Launcher启动\n被SystemServer进程启动的AMS会启动Launcher，Launcher启动后会将已安装应用的快捷图标显示到屏幕上。","tags":["读书笔记"],"categories":["Android"]},{"title":"Linux命令--cat","url":"/2021/12/4c4e081a5efb/","content":"\n连接多个文件并打印到标准输出\n\n<!--more-->\n\n### 三大功能\n- 显示文件内容，如果没有文件或者文件为-则读取标准输入。\n- 从键盘创建一个文件。\n- 将多个文件的内容进行连接并打印到标准输出。\n\n### 读取内容\n1. 读取到标准输出，也就是终端窗口\n```sh\n# 读取file1.txt文件\n$ cat file1.txt\n\n# 读取多个文件\n$ cat file1.txt file2.txt\n```\n\n2. 读取到其他输出流，如文件\n```sh\n# 单个文件\n$ cat f1.txt > sum.txt\n\n# 多个文件\n$ cat f1.txt f2.txt f3.txt > sum.txt\n```\n\n\n### 创建/追加\n1. 创建使用 `>`\n```sh\n$ cat > file1.txt << EOF\nline1\nline2\nEOF\n```\n\n2. 追加使用 `>>`\n```sh\n$ cat >> file1.txt << EOF\nline3\nline4\nEOF\n```\n3. EOF，end of file，结束标记，换成其他的也可以\n\n4. 结束标记和文件名的位置无所谓前后，这样也可以\n```sh\n$ cat << EOF >> file1.txt\nline3\nline4\nEOF\n```\n\n### 其他常用选项\n```sh\n# -n --number 加行号\n$ cat -n f1.txt\n\n# -b --number-noblank 加行号，但空白行不编号\n$ cat -b f1.txt\n\n# -s --squeeze-blank 当有两行以上的空白行，变成一行空白行\n$ cat -s f1.txt\n```","tags":["Linux"],"categories":["Linux"]},{"title":"iPhone数据备份到移动硬盘","url":"/2021/12/43f9db48ed86/","content":"\niPhone备份方式中，算是最省钱的方式了。\n\n<!--more-->\n\n### 前言\n首先明确的是，备份还是很有必要性的，在设备丢失，或是坏掉的时候，可以快速恢复数据而不影响使用。\n\niPhone里苹果官方推荐的是把数据备份到iCloud中，但是区区5GB的免费空间换了谁都不够用，除非花钱买。退一步的方式，就是把数据备份到电脑上，不用花钱，但是于我来讲，本就不够用的电脑存储已经是寸土寸金，没有太多空间分给手机备份。最省钱的方式，就是单独买块移动硬盘，现在的市场价，1TB的在300块钱上下，相比之下很划算了。\n\n### 分区\n也可以不分。\n\n在硬盘上分一块和手机大小相当的分区用来备份手机数据，单独一块出来的好处是，方便抹除数据，比手动删除不知道快了多少倍。\n\n### 制作替身\n能把数据备份到外接设备的原理就是，把默认的系统目标位置映射到移动硬盘上，就这么一个操作。系统默认的备份位置在\n```\n~/Library/Application\\ Support/MobileSync/Backup\n```\n把这个Backup目录删掉，然后在此制作一个同名的替身，映射到移动硬盘。在移动硬盘上创建同名目录即可：`MobileSync/Backup`，然后链接\n```\n$ ln -s /Volumes/{name_of_dish}/MobileSync/Backup ~/Library/Application\\ Support/MobileSync/Backup\n```\n操作完成之后，电脑里的MobileSync下就会出现一个替身Backup，指向外接硬盘的Backup。\n\n这一步操作可能需要给终端App增加访问系统全盘的权限，在系统偏好设置中、安全性与隐私的隐私里，不然可能无权限在MobileSync下创建替身\n\n### 备份\n老版本的MacOS还有个iTunes用来管理手机的数据，升级到最近的几个版本后就和Finder合并了，目前最新的是Monterey。插上手机，在Finder中就能看到，然后就可以备份了。\n","tags":["iPhone"],"categories":["MacOS"]},{"title":"Android之事件传递","url":"/2021/10/b897ec3baf06/","content":"\n触摸事件，主要有三种类型，ACTION_DOWN、ACTION_MOVE和ACTION_UP，分别指点击、移动和抬起。这篇文章主要来说一说一个事件产生之后，在控件间的传递。\n\n<!--more-->\n与其说是事件传递，不如说是事件序列的传递。一个事件序列，是由一个ACTION_DOWN和一个ACTION_UP组成，中间可能包含0个至多个ACTION_MOVE事件。手指按下时，会产生一个ACTION_DOWN事件，手指抬起时，会产生一个ACTION_UP事件，如果按下和抬起的位置偏移超过系统设定的阈值，便会产生一个或多个ACTION_MOVE事件，这便是一个事件序列。\n\n事件序列，是按照视图树由根到枝叶的顺序传递的，意思就是说，最外层的View或ViewGroup最先接收到事件，然后向内传递。其中事件流经的控件主要分为两种：ViewGroup和View。\n\n### ViewGroup\nViewGroup是View的子类，其中有3个和事件相关的方法：dispatchTouchEvent、onInterceptTouchEvent和onTouchEvent，分别是分发事件、拦截事件和处理事件。\n\n简单来说就是，系统通过dispatchTouchEvent方法将事件传入，在dispatchTouchEvent内根据onInterceptTouchEvent来判断是否拦截该事件，如果拦截了，则不再将其沿着视图树向内传递；如果拦截，则根据onTouchEvent方法来判读是否处理，如果处理了，则表示消费了该事件。\n\n### View\nView没有onInterceptTouchEvent，因为View无子View，是在视图树的最内层了，不需要拦截。当事件通过dispatchTouchEvent传入，根据onTouchEvent方法来判断是否消费。\n\n### 事件流转\n因为事件都是以事件序列的形式传递的，单独看某个事件意义不大，这里分析事件序列，先看ACTION_DOWN事件，这里的向内和向外都是针对视图树的结构而言的。\n```shell\n// 视图树\nDecorView\n|-FrameLayout\n|-TextView\n|-LinearLayout\n  |-ImageView\n  |-FrameLayout\n```\n\n1. 向内分发ACTION_DOWN\n- ViewGroup接收到事件后，会根据onInterceptTouchEvent方法来判断是否拦截，如果拦截，则根据onTouchEvent方法来判断是否消费事件。\n- View接收到事件后，根据onTouchEvent方法判断是否消费事件。\n- 如果ViewGroup没有拦截事件，则根据坐标，依次遍历该事件命中的子View/ViewGroup，重复上面这个过程\n- 当事件被拦截，或者传递到视图树最内层时，便不会继续向内传递，转而开始回传。\n\n2. 向外回传ACTION_DOWN\n- 事件回传，传递的是dispatchTouchEvent方法的返回值，true/false\n- 如果回传的false，父ViewGroup的onTouchEvent方法会被调用，可理解为本着事件不浪费的原则，既然子视图都没消费，那么就看看自己是否可以消费掉\n- 如果回传到视图根时，依然是false，表示没有子视图消费ACTION_DOWN事件，则该序列的后续事件不再向内传递，都由根视图处理\n\n3. 事件序列的后续事件\n- 系统本着一个事件序列只由一个视图处理的原则\n- 后续事件都将传递至消费掉ACTION_DOWN事件的ViewGroup/View，且在dispatchTouchEvent内直接调用onTouchEvent，不经过onInterceptTouchEvent方法，如果有的话\n- 当然，后续事件在传递过程中也可以被拦截和消费，但不建议这么做，比如一个按钮只接收了一个按下事件，则在逻辑上可能会不完整\n- 后续事件在回传时，即便是false，父ViewGroup的onTouchEvent也不会被调用，因这与第一点相悖\n\n### 根视图\n根据上一篇文章的介绍可以知道，DecorView是我们看到的视图的根，它继承自FrameLayout，是一个ViewGroup，所以它有3个和事件相关的方法。此外，Activity对应一个PhoneWindow，PhoneWindow对应一个DecorView，所以在事件序列产生的时候，最新接收到的是DecorView。\n\n根据源码，DecorView将事件转给了Window.Callback，这个Callback是Window在Activity中初始化时传入的，就是Activity本身，Activity实现了Callback接口，即，在DecorView中调用了Activity的dispatchTouchEvent。\n\nActivity的dispatchTouchEvent方法中，先将事件传给了Window的superDispatchTouchEvent方法，若没消费，再调用自己的onTouchEvent。而Window的superDispatchTouchEvent很简单，就是直接调用了DecorView的superDispatchTouchEvent，最终调用了ViewGroup的dispatchTouchEvent方法。\n\n总结下来就是，DecorView将事件转给了Activity，在Activity的dispatchTouchEvent方法中判断，若DecorView没有消费，则交给Activity的onTouchEvent。\n\n所以，从处理事件顺序来看，真实的事件流转顺序应该是：Activity -> DecorView -> ... -> DecorView -> Activity。\n\n```java\n// DecorView.java\n@Override\npublic boolean dispatchTouchEvent(MotionEvent ev) {\n    final Window.Callback cb = mWindow.getCallback();\n    return cb != null && !mWindow.isDestroyed() && mFeatureId < 0\n            ? cb.dispatchTouchEvent(ev) : super.dispatchTouchEvent(ev);\n}\n\n// Activity.java\nfinal void attach(Context context, ActivityThread aThread,\n            Instrumentation instr, IBinder token, int ident,\n            Application application, Intent intent, ActivityInfo info,\n            CharSequence title, Activity parent, String id,\n            NonConfigurationInstances lastNonConfigurationInstances,\n            Configuration config, String referrer, IVoiceInteractor voiceInteractor,\n            Window window, ActivityConfigCallback activityConfigCallback, IBinder assistToken) {\n\tmWindow = new PhoneWindow(this, window, activityConfigCallback);\n    mWindow.setWindowControllerCallback(mWindowControllerCallback);\n    mWindow.setCallback(this);\n}\n\npublic boolean dispatchTouchEvent(MotionEvent ev) {\n    if (ev.getAction() == MotionEvent.ACTION_DOWN) {\n    \t// 在Activity中可以重写该方法，来监听用户的操作\n        onUserInteraction();\n    }\n    if (getWindow().superDispatchTouchEvent(ev)) {\n        return true;\n    }\n    return onTouchEvent(ev);\n}\n\n// PhoneWindow.java\npublic boolean superDispatchTouchEvent(MotionEvent event) {\n    return mDecor.superDispatchTouchEvent(event);\n}\n```\n\n### 总结\n1. 将事件传递分为向内分发和向外回传两个过程更便于理解，这里的向内和向外都是针对视图树的结构而言的。\n2. 向内分发过程中，事件一旦被拦截，或者传到了最内层，便会开始回传事件的消费结果，也就是入口dispatchTouchEvent方法的结果\n3. 当回传结果是false，且事件是序列事件的头事件ACTION_DOWN时，会调用父ViewGroup的onTouchEvent来尝试消费事件\n4. 系统本着一个事件序列只交给一个View/ViewGroup来处理的原则\n\n### 扩展之滑动冲突\n当在列表内部内嵌可滑动视图时，内部的可滑动视图常常监听不到滑动事件，这是因为列表作为内嵌视图的父ViewGroup会拦截滑动事件，所以内部自然感知不到。比较好的体验是，内部可滑动视图向上滑动到顶时，后续的滑动事件交给父列表处理，让父列表滑动来响应用户的滑动操作；当内部视图向下滑动到底时，后续的滑动事件也是交给父列表处理，让父列表滑动个来响应用户怼滑动操作。\n\n为了解决这个问题，就必须要让事件序列传到最内层，根据上面内容可以知道，要想让事件序列传到内部，那么ACTION_DOWN事件就要交给内部视图来处理。\n\n再看后续事件，作为内部视图的父视图，后续的每一个事件在传到内部视图之前，都会流经外部的列表，因此，就有两种方式来处理后续事件\n- 由父视图来判断当前事件是由自己消费，还是交给内部视图消费\n- 由内部试图来判断当前事件是由自己消费，还是让父视图消费\n\n第一种比较简单，在父视图内对ACTION_DOWN之外的后续事件判断，需要则拦截，不需要则通过；\n\n通过源码可以看到，在子视图中，是可以控制父视图是否可以拦截事件的，所以上述的第二种方式也是可行的。内部视图在收到ACTION_DOWN事件后，通过`parent.requestDisallowInterceptTouchEvent(true)`来禁止父视图拦截事件，当自己不再需要后续事件时，通过`parent.requestDisallowInterceptTouchEvent(false)`来让父视图拦截处理后面的滑动事件，来响应用户的操作即可。\n\n```java\n// ViewGroup.java\n// Check for interception.\n@Override\npublic boolean dispatchTouchEvent(MotionEvent ev) {\n\t....\n\t// Check for interception. 判断是否拦截\n    final boolean intercepted;\n    if (actionMasked == MotionEvent.ACTION_DOWN || mFirstTouchTarget != null) {\n    \t// 当设置了FLAG_DISALLOW_INTERCEPT时，则直接不拦截事件\n    \t// 没有设置FLAG_DISALLOW_INTERCEPT时，才会去调用onInterceptTouchEvent来判断\n    \t// FLAG_DISALLOW_INTERCEPT通过requestDisallowInterceptTouchEvent来设置\n        final boolean disallowIntercept = (mGroupFlags & FLAG_DISALLOW_INTERCEPT) != 0;\n        if (!disallowIntercept) {\n            intercepted = onInterceptTouchEvent(ev);\n            ev.setAction(action); // restore action in case it was changed\n        } else {\n            intercepted = false;\n        }\n    } else {\n    \t// 当不是ACTION_DOWN事件，且ACTION_DOWN没有被消费，则直接拦截，不再向内分发\n        // There are no touch targets and this action is not an initial down\n        // so this view group continues to intercept touches.\n        intercepted = true;\n    }\n}\n```","tags":["Android","TouchEvent"],"categories":["Android"]},{"title":"Activity、Window和DecorView的关系","url":"/2021/09/dab1a10731eb/","content":"\n在Android的视图框架体系，主要由这三者组成。\n\n### 前言\n我们在实际开发中，接触的最多的是Activity，至于Window和DecorView遇到的时候便会相对少一些。虽然不常用，但如果能厘清它们之间的关系，能帮助我们更好的理解Android系统的框架体系设计。\n\n<!--more-->\n\n### Window\n从字面上看，一个Window就是一个窗口，对应的类型有多种，按照层级分为3种：Activity的Window、子Window和系统Window。\n\nWindow是一个抽象类，它有且仅有一个实现类，即常说的PhoneWindow，所以，所用到的Window实例，实际上类型都是PhoneWindow。\n\n\n### DecorView\nDecorView继承自FrameLayout，扩展了一些自己的功能方法。默认情况下，DecorView会向自己内部添加一个LinearLayout为根节点的layout文件，这个LinearLayout有两个子View，一个是ActionBar，一个是ID为`@android:id/content`的FrameLayout，我们在Activity里调用setContentView时，就是把我们写的布局文件，作为子View添加到这个FrameLayout下\n```sh\nDecorView\n|--LinearLayout\n   |--ActionBar\n   |--FrameLayout\n```\n\n\n### 三者关系\nActivity中持有一个Window的实例，在Activity.onAttach中被初始化；Window中持有一个DecorView实例，DecorView就是我们所看到的视图的根视图\n```sh\nActivity\n|--PhoneWindow\n   |--DecorView\n      |--LinearView\n         |--ActionBar\n         |--FrameLayout\n```\n\n在这个视图框架中，Activity处在最外层的位置，表面上，我们的很多交互都是在和Activity进行，但Activity内部会调用Window，Window内部会调用DecorView，最终完成我们的调用。\n\n\n### 一个页面的显示过程\n众所周知，要在Activity里显示一个页面，通常是在onCreate回调里调用setContentView方法，下面来看一看从设置，到最终显示出来，都经过了哪些流程\n\n1. 首先，在Activity.setContentView里没有做什么事情，而是直接将调用转给了PhoneWindow\n```java\n// Activity.java\npublic void setContentView(@LayoutRes int layoutResID) {\n    getWindow().setContentView(layoutResID);\n    initWindowDecorActionBar();\n}\n\npublic Window getWindow() {\n    return mWindow;\n}\n```\n\n2. mWindow即为PhoneWindow的实例，它是在Activity.attach方法里初始化的，attach方法的调用是在ActivityThread创建Activity时调用，要早于onCreate，所以在onCreate被调用时，mWindow已经初始化\n```java\n// ActivityThread.java\nprivate Activity performLaunchActivity(ActivityClientRecord r, Intent customIntent) {\n    // 1. 创建Activity\n    Activity activity = mInstrumentation.newActivity(cl, component.getClassName(), r.intent);\n    // 2. 调用Activity.attach\n    activity.attach(appContext, this, getInstrumentation(), r.token,\n                    r.ident, app, r.intent, r.activityInfo, title, r.parent,\n                    r.embeddedID, r.lastNonConfigurationInstances, config,\n                    r.referrer, r.voiceInteractor, window, r.configCallback,\n                    r.assistToken);\n    // 3. 调用Activity.onCreate\n    mInstrumentation.callActivityOnCreate(activity, r.state);\n}\n\n// Activity.java\nfinal void attach(Context context, ActivityThread aThread,\n        Instrumentation instr, IBinder token, int ident,\n        Application application, Intent intent, ActivityInfo info,\n        CharSequence title, Activity parent, String id,\n        NonConfigurationInstances lastNonConfigurationInstances,\n        Configuration config, String referrer, IVoiceInteractor voiceInteractor,\n        Window window, ActivityConfigCallback activityConfigCallback, IBinder assistToken) {\n    // 用PhoneWindow初始化mWindow变量\n    mWindow = new PhoneWindow(this, window, activityConfigCallback);\n    mWindow.setWindowControllerCallback(mWindowControllerCallback);\n    mWindow.setCallback(this);\n    mWindow.setOnWindowDismissedCallback(this);\n    mWindow.getLayoutInflater().setPrivateFactory(this);\n}\n```\n\n3. 回到PhoneWindow，在Activity里调用setContentView后，会调用PhoneWindow的setContentView方法，根据上面的介绍可以知道，PhoneWindow中有类型为DecorView的变量，名字为mDecor，我们自己写的页面最终会最为子View添加到DecorView下的LinearLayout下的ID为`@android:id/content`的FrameLayout里面。\n\n在PhoneWindow里，这个FrameLayout用变量mContentParent保存，所以在PhoneWindow的setContentView里，会先检查mContentParent是都已经初始化，如果没有初始化，则去检查mDecor是否初始化，因为mContentParent是mDecor中的元素，有了mDecor才能初始化mContentParent。\n\n如果mContentParent存在，则会将我们设置的view添加为它的子view。\n\n在官方的设计里，根视图DecorView是由两部分组成的，一个是上面的ActionBar，一个是中间的内容区Content，即mContentParent，所以，我们setContentView是在设置中间内容区的内容。但有时我们不需要ActionBar，会在主题Theme里使用NO_ACTION_BAR的，也可能会有其他的设定，比如需要ToolBar等。\n\n系统中有一些默认的layout文件，在初始化mContentParent时，会根据我们设定的不同的Theme，以及不同的FEATURE，来选对应的layout文件，加载到mDecor中，一般来说这些布局文件中会有一个ID为`@android:id/content`的FrameLayout，也就是mContentParent。\n\n但是，在实际情况中，还会有一些复杂的情况，比如设置了转场动画等等，以及现在的AppCompatActivity，为了兼容新版SDK的一些功能设计，在DecorView的基础上添加了同样设计的SubDecorView，用SubDecorView来填充DecorView的mContentParent，我们通过setContentView设置的View最终会填充到SubDecorView的mContentParent中，具体这里就不做展开说明了。\n\n下面看看这个过程中对应的一些源码\n```java\n// PhoneWindow.java\npublic void setContentView(int layoutResID) {\n    // Note: FEATURE_CONTENT_TRANSITIONS may be set in the process of installing the window\n    // decor, when theme attributes and the like are crystalized. Do not check the feature\n    // before this happens.\n    if (mContentParent == null) {\n        // 1. 如果为空，则去初始化DocerView，同时也会初始化mContentParent\n        installDecor();\n    } else if (!hasFeature(FEATURE_CONTENT_TRANSITIONS)) {\n        mContentParent.removeAllViews();\n    }\n    // 如果有转场动画，则通过Scene来辅助，没有则将view添加到mContentParent中\n    if (hasFeature(FEATURE_CONTENT_TRANSITIONS)) {\n        final Scene newScene = Scene.getSceneForLayout(mContentParent, layoutResID,\n                getContext());\n        transitionTo(newScene);\n    } else {\n        mLayoutInflater.inflate(layoutResID, mContentParent);\n    }\n    mContentParent.requestApplyInsets();\n    final Callback cb = getCallback();\n    if (cb != null && !isDestroyed()) {\n        cb.onContentChanged();\n    }\n    mContentParentExplicitlySet = true;\n}\n\nprivate void installDecor() {\n    mForceDecorInstall = false;\n    if (mDecor == null) {\n        // 先生成DecorView\n        mDecor = generateDecor(-1);\n        mDecor.setDescendantFocusability(ViewGroup.FOCUS_AFTER_DESCENDANTS);\n        mDecor.setIsRootNamespace(true);\n        if (!mInvalidatePanelMenuPosted && mInvalidatePanelMenuFeatures != 0) {\n            mDecor.postOnAnimation(mInvalidatePanelMenuRunnable);\n        }\n    } else {\n        mDecor.setWindow(this);\n    }\n    if (mContentParent == null) {\n        // 再从mDecor中找到mContentParent，这个方法下面单独说\n        mContentParent = generateLayout(mDecor);\n    }\n}\n\n// 创建DocorView\nprotected DecorView generateDecor(int featureId) {\n    ...\n    return new DecorView(context, featureId, this, getAttributes());\n}\n\n```\n\nmContentParent是在generateLayout方法中创建的，这个方法很长，足足写了三百多行。其中大致做了这几件事：\n\n第一步，获取WindowStyle，类型是TypedArray，这个和我们给Activity设置的Theme中的属性是相对应的，在这里通过R.styleable.Window_来读取，如果写过自定义控件的话，对这种读取属性的方式一定不陌生\n\n第二步，将其中设定的值取出，一部分直接设置给mDecor，如状态栏、导航栏；一部分赋值给PhoneWindow内的成员变量，如mFixedWidthMinor、mFixedWidthMajor；一部分通过setFlags设置给Window中类型为WindowManager.LayoutParams的变量mWindowAttributes，并刷新Window显示，如FLAG_FULLSCREEN，还有一部分直接赋值；一部分通过requestFeature设置给Window的变量mFeatures，如FEATURE_NO_TITLE，这个requestFeature就是我们为修改Activity一些特性，而在setContentView前调用的那个方法，可见系统也是通过这个方法，将我们在主题中设置的参数取出并应用\n\n第三步，根据设定的features，从系统中已经写好的layout布局文件中，找到一个合适的，这些文件可以这个目录下看到，`sdk/platforms/android-version/data/res/layout`\n\n第四步，加载布局文件，将其添加到mDecor中\n\n第五步，通过`@android:id/content`这个ID，找到ViewGroup，这便是mContentParent\n\n```java\nprotected ViewGroup generateLayout(DecorView decor) {\n    // Apply data from current theme.\n    // 第一步，获取包含主题属性的TypedArray\n    TypedArray a = getWindowStyle();\n\n    // 第二步，取值，并应用\n    if (a.getBoolean(R.styleable.Window_windowNoTitle, false)) {\n        requestFeature(FEATURE_NO_TITLE);\n    } else if (a.getBoolean(R.styleable.Window_windowActionBar, false)) {\n        // Don't allow an action bar if there is no title.\n        requestFeature(FEATURE_ACTION_BAR);\n    }\n    if (a.getBoolean(R.styleable.Window_windowTranslucentStatus,\n            false)) {\n        setFlags(FLAG_TRANSLUCENT_STATUS, FLAG_TRANSLUCENT_STATUS\n                & (~getForcedWindowFlags()));\n    }\n    ...\n\n    // 第三步，根据features，找layout文件\n    int layoutResource;\n    int features = getLocalFeatures();\n    if ((features & ((1 << FEATURE_LEFT_ICON) | (1 << FEATURE_RIGHT_ICON))) != 0) {\n        if (mIsFloating) {\n            TypedValue res = new TypedValue();\n            getContext().getTheme().resolveAttribute(\n                    R.attr.dialogTitleIconsDecorLayout, res, true);\n            layoutResource = res.resourceId;\n        } else {\n            layoutResource = R.layout.screen_title_icons;\n        }\n        removeFeature(FEATURE_ACTION_BAR);\n    }\n    ...\n\n    // 第四步，加载layout文件到mDecor\n    mDecor.onResourcesLoaded(mLayoutInflater, layoutResource);\n\n    ...\n    // 第五步，初始化mContentParent\n    ViewGroup contentParent = (ViewGroup)findViewById(ID_ANDROID_CONTENT);\n    return contentParent;\n}\n\n```\n\n至此，PhoneWindow中的setContentView已经走完了，mDecor、mWindow也已经初始化，我们设置的View也添加到了mDecor的content中，但是还没有显示出来，具体让页面内容显示出来，是在resume阶段。\n\n4. setContentView说完，现在开始说resume。resume是在ActivityThread中的handleResumeActivity方法中回调的，handleResumeActivity里面大致做了这几件事：调用Activity的onResume回调方法、将Activity的Window中的DecorView添加到WindowManager，以及显示Activity的DecorView\n```java\n// ActivityThread.java\npublic void handleResumeActivity(IBinder token, boolean finalStateRequest, boolean isForward,\n        String reason) {\n    // 调用Activity.onResume方法\n    final ActivityClientRecord r = performResumeActivity(token, finalStateRequest, reason);\n\n    // 得到DecorView\n    View decor = r.window.getDecorView();\n    decor.setVisibility(View.INVISIBLE);\n    ViewManager wm = a.getWindowManager();\n    WindowManager.LayoutParams l = r.window.getAttributes();\n    if (a.mVisibleFromClient) {\n    if (!a.mWindowAdded) {\n        a.mWindowAdded = true;\n        // 将decorView加到WindowManager\n        wm.addView(decor, l);\n    } else {\n        a.onWindowAttributesChanged(l);\n    }\n\n    // 调用Activity.makeVisible方法，让其显示，此时便看到了页面\n    if (r.activity.mVisibleFromClient) {\n        r.activity.makeVisible();\n    }\n}\n\n// Activity.java\nvoid makeVisible() {\n    if (!mWindowAdded) {\n        ViewManager wm = getWindowManager();\n        wm.addView(mDecor, getWindow().getAttributes());\n        mWindowAdded = true;\n    }\n    // 让DecorView可见\n    mDecor.setVisibility(View.VISIBLE);\n}\n```\n至此，页面进入可见状态。\n\n### 总结\n布局文件在调用setContentView后，会在PhoneWindow中初始化DecorView，找到DecorView中ID为`@android:id/content`的ViewGroup，然后将我们设置的View添加到其中，最终在RESUME阶段，会将DecorView添加到WindowManager中，并设置其可见。","tags":["Android"],"categories":["Android"]},{"title":"Android Context","url":"/2021/09/d4ee8f599683/","content":"曾经被问过一个问题：Android系统中的Context有几种？当时没怎么说清楚，现在再来聊聊这个问题。\n\n<!--more-->\n\nContext是个抽象类，它有两个直接子类：ContextImpl和ContextWrapper。ContextImpl实现了Context中的所有抽象方法，ContextWrapper也实现了Context的抽象方法，但它的实现方式是通过调用其持有的ContextImpl实例mBase的对应的方法，所以它叫做Wrapper，可以理解成ContextImpl的包装类。\n```shell\nContext\n|--ContextImpl\n|--ContextWrapper\n```\n\n而Application、Service都是ContextWrapper的直接子类。此外，ContextWrapper还有其他直接子类，如ContextThemeWrapper、ReceiverRestrictedContext，而Activity则是ContextThemeWrapper的直接子类，因为它需要主题。ReceiverRestrictedContext则是给BroadcastReceiver使用的，后面说。\n```shell\nContext\n|--ContextImpl\n|--ContextWrapper\n   |--Appliction\n   |--Service\n   |--ReceiverRestrictedContext\n   |--ContextThemeWrapper\n      |--Activity\n```\n\n这几个类的实例都是在ActivityThread中创建，其中的Context也是在这里面赋值的，分别来看一看\n\n### Activity\n创建Activity时，最终会走到ActivityThread.performLauncherActivity方法里\n```java\n// ActivityThread.java 省略了部分代码\nprivate Activity performLaunchActivity(ActivityClientRecord r, Intent customIntent) {\n    // 创建ContextImpl\n    ContextImpl appContext = createBaseContextForActivity(r);\n    // 创建Activity\n    Activity activity = mInstrumentation.newActivity(cl, component.getClassName(), r.intent);\n    // 创建Application\n    Application app = r.packageInfo.makeApplication(false, mInstrumentation);\n    // 调用Activity.attach\n    activity.attach(appContext, this, getInstrumentation(), r.token,r.ident, app, r.intent, r.activityInfo, title, r.parent, r.embeddedID, r.lastNonConfigurationInstances, config, r.referrer, r.voiceInteractor, window, r.configCallback, r.assistToken);\n    // 调用Activity.onCreate\n    if (r.isPersistable()) {\n        mInstrumentation.callActivityOnCreate(activity, r.state, r.persistentState);\n    } else {\n        mInstrumentation.callActivityOnCreate(activity, r.state);\n    }\n}\n\nprivate ContextImpl createBaseContextForActivity(ActivityClientRecord r) {\n\tContextImpl appContext = ContextImpl.createActivityContext(this, r.packageInfo, r.activityInfo, r.token, displayId, r.overrideConfig);\n\treturn appContext;\n}\n```\n可以看到，创建一个Activity的过程主要有3步：一是通过反射创建Activity实例，二是准备相关的参数，其中包含ContextImpl实例和Application实例，接着是attach，在这个方法里初始化Activity的成员变量，其中有一个Application类型的变量mApplication，传入的Application是为了初始化这个变量。\n\n### Service\n创建Service最终会走到ActivityThread.handleCreateService方法里\n```java\n// ActivityThread.java 省略了部分代码\nprivate void handleCreateService(CreateServiceData data) {\n\t// 创建ContextImpl\n\tContextImpl context = ContextImpl.createAppContext(this, packageInfo);\n\t// 创建Application\n\tApplication app = packageInfo.makeApplication(false, mInstrumentation);\n\t// 创建Service\n\tService service = packageInfo.getAppFactory().instantiateService(cl, data.info.name, data.intent);\n\t// 调用Service.attach\n\tservice.attach(context, this, data.info.name, data.token, app, ActivityManager.getService());\n\t// 调用Service.onCreate\n\tservice.onCreate();\n}\n```\n和Activity类似，不再赘述。\n\n### BroadcastReceiver\n创建BroadcastReceiver最终会走到ActivityThread.handleReceiver方法里\n```java\n// ActivityThread.java 省略了部分代码\nprivate void handleReceiver(ReceiverData data) {\n\t// 创建Application\n\tApplication app = packageInfo.makeApplication(false, mInstrumentation);\n\t// 创建ContextImpl\n\tContextImpl context = (ContextImpl) app.getBaseContext();\n\t// 创建BroadcastReceiver\n\tBroadcastReceiver receiver = packageInfo.getAppFactory().instantiateReceiver(cl, data.info.name, data.intent);\n\t// 调用BroadcastReceiver.onReceive\n\treceiver.onReceive(context.getReceiverRestrictedContext(), data.intent);\n}\n```\n可以看到，BroadcastReceiver没有直接使用创建的ContextImpl，而是通过context.getReceiverRestrictedContext()获取了ReceiverRestrictedContext，上面提过，它是ContextWrapper的直接子类，重写了其中的registerReceiver和bindService方法，方法里直接抛出异常，所以用BroadcastReceiver中的Context无法创建广播和服务\n```java\n// ContextImpl.java 只展示关键代码\nclass ReceiverRestrictedContext extends ContextWrapper {\n\t@Override\n    public Intent registerReceiver(BroadcastReceiver receiver, IntentFilter filter, String broadcastPermission, Handler scheduler) {\n        if (receiver == null) {\n            // Allow retrieving current sticky broadcast; this is safe since we\n            // aren't actually registering a receiver.\n            return super.registerReceiver(null, filter, broadcastPermission, scheduler);\n        } else {\n            throw new ReceiverCallNotAllowedException(\"BroadcastReceiver components are not allowed to register to receive intents\");\n        }\n    }\n\n    @Override\n    public boolean bindService(Intent service, ServiceConnection conn, int flags) {\n        throw new ReceiverCallNotAllowedException(\"BroadcastReceiver components are not allowed to bind to services\");\n    }\n}\n```\n\n### Application\n在创建上面3个的时候可以看到，Application都是通过packageInfo.makeApplication来创建的，packageInfo是个类型为LoadedApk类型的实例，具体看一看\n```java\n// LoadedApk.java 只展示了关键代码\npublic Application makeApplication(boolean forceDefaultAppClass, Instrumentation instrumentation) {\n\tif (mApplication != null) {\n\t\treturn mApplication;\n     }\n     ContextImpl appContext = ContextImpl.createAppContext(mActivityThread, this);\n     app = mActivityThread.mInstrumentation.newApplication(cl, appClass, appContext);\n     mApplication = app;\n     // 调用Application的onCreate方法\n     instrumentation.callApplicationOnCreate(app);\n}\n\n// Instrumentation.java \npublic Application newApplication(ClassLoader cl, String className, Context context) throws InstantiationException, IllegalAccessException, ClassNotFoundException {\n    Application app = getFactory(context.getPackageName()).instantiateApplication(cl, className);\n    app.attach(context);\n    return app;\n}\n```\n先创建了ContextImpl的实例，然后在Instrumentation中通过反射创建了Application实例，接着将上一步创建的ContextImpl实例通过attach方法传入，最后调用Application.onCreate方法\n\n### ContentProvider\n四大组件说了三个，再说说最后一个ContentProvicer，虽然不是Context的子类，但也和Context相关。创建Provider在ActivityThread.installProvider方法中\n```java\n// ContextImpl.java 只展示关键代码\nprivate ContentProviderHolder installProvider(Context context, ContentProviderHolder holder, ProviderInfo info, boolean noisy, boolean noReleaseNeeded, boolean stable) {\n\tContext c = null;\n    ApplicationInfo ai = info.applicationInfo;\n    if (context.getPackageName().equals(ai.packageName)) {\n        c = context;\n    } else if (mInitialApplication != null && mInitialApplication.getPackageName().equals(ai.packageName)) {\n        c = mInitialApplication;\n    } else {\n        try {\n            c = context.createPackageContext(ai.packageName, Context.CONTEXT_INCLUDE_CODE);\n        } catch (PackageManager.NameNotFoundException e) { // Ignore }\n    }\n    // 创建ContentProvider\n\tContentProvider localProvider = packageInfo.getAppFactory().instantiateProvider(cl, info.name);\n\tlocalProvider.attachInfo(c, info);\n}\n```\n视情况而定，ContextImpl的来源有多种，但最后都是通过attachInfo方法传入ContentProvider。\n\n### 总结\n回到最初的问题，Context有几种呢，就普遍性而言有3种：Application、Activity和Service，如果严谨一点，算上ReceiverRestrictedContext的话，那么就是4种。","tags":["Android","Context"],"categories":["Android"]},{"title":"Android适配","url":"/2021/09/352f312b568b/","content":"\n为什么要适配呢？这篇文章来聊一聊。\n<!--more-->\n因为现在有着五花八门的Android手机厂商，生产出来的设备有着各种各样的分辨率。这一点不像Apple，设备类型就那么有限的几种。\n\n为了做到让一张设计稿，在不同的设备上看起来都差不多，或者说不会相差太多，这就是适配的目的。\n\n### 几个概念\n- 屏幕大小\n常见的有5.0英寸、6.1英寸等等，这个长度指的是屏幕对角线的长度，根据勾股定理便可以根据长和宽算出来。为什么要用对角线的长度来表示一个屏幕的大小呢，对角线相等的屏幕可以有多种长和宽。查了下，是历史遗留原因，因为最开始的时候都是用圆形显示管来显示的，所以用直径表示显示管的大小，也就是其内矩形的对角线。后来工艺发展，做成了矩形，但这种方式保留了下来\n\n- 屏幕分辨率\n常见的有720x1280、1080x1920、1440x2560，其中的数字指的是该方向的像素块的数量。比如720x1280的屏幕，在较短的方向有720个像素块，较长的方向有1280个像素块，不同的屏幕像素块的大小可能是不同的。比如两块屏幕都是1080x1920，但一块是5.0英寸另一块是5.9英寸，那5.0的像素块就要小一些。\n\n- px\npixel，像素\n\n- ppi\n全称pixel per inch，指每英寸上的像素数量，比如1080宽，物理长度为3.375英寸，那么每英寸上的像素数量就是1080/3.75=320个，一般针对的是描述屏幕\n\n- dpi\n和ppi类似，全称是dots per inch，指每英寸上墨点的数量，针对的是打印到纸上，比如160dpi，意思就是打印出一条1英寸长的线时，这条线上会有160个墨点。在 Android 里，这两个值是相等的，在屏幕上显示一张图片时，一个像素块便相当于一个墨点，但是在打印机上打印时这两个不一定相等。\n\n因为不同屏幕有着不同的分辨率，所以我们不能在代码中以像素为单位设置图片的大小，比如一个ImageView设置成540px宽，有的屏幕上是2英寸，有的屏幕上却是3英寸，这样的效果是不可行的，因此，这里引出了新概念：\n\n- dip\n全称是density independent pixel，密度独立像素，简称dp。这是一个基于像素、和屏幕密度相关的长度单位。规定：在密度是160的屏幕上，1dp=1px，所以密度是320的屏幕上，1dp=2px，总之，密度越高的屏幕上，1dp代表的像素越多。\n\n- density\n密度，等于dpi/160，意思就是在这块屏幕上，1dp等于多少px\n\n在Android中，用dp代替px的好处是什么呢？例如，设计稿是1080x1920，屏幕密度是320，所以density等于2。上面一张160px宽的图片，即160/2=80dp。\n在dpi为320的屏幕上，也就是density等于2，它等于160像素，即0.5英寸；\n在dpi为160的屏幕上，也就是density等于1，它等于80像素，即0.5英寸。\n虽然屏幕密度不同，但这张图占用的物理宽度都是0.5英寸，给人视觉上的感觉是一样的。\n\n### 适配是在适配什么\n首先明确一点是，不管用什么单位，Android在最终绘制到屏幕时，都会转化成像素。原本这样就可以了，不同的屏幕我可以显示出同样的物理宽度，但由于手机厂商之多、生产的屏幕之多，所以还有着特殊的情况。\n\n比如，同样是1080x1920的屏幕，一块的dpi是480，density为480/160=3，物理宽度为1080/480=2.25英寸；另一块的dpi是360，density为360/160=2.25，物理宽度为1080/360=3英寸\n\n1080x1920、dpi为480的设计稿上，有个产品列表，介绍图片宽度为360dp，在第一块屏幕上刚好占满屏幕宽度，但是在第二块屏幕上只占用了360x2.25=810px，宽度上剩下了一大块空白，1080-810=270px。\n\n本质上，dip就是为了在大屏幕上显示更多的内容。这里的「大」是什么意思呢？可以看上面的例子，同样的1080像素的宽度，前者的物理宽度是2.25英寸，而后者是3英寸，明显后者比前者更大，所以在显示同样dp的图片时，后者留了一大片空白，因为可以显示更多的内容。\n\n但是这种显示效果就不可接受的，而说了半天的适配，就是适配这样的情况，同样像素宽度的屏幕，物理尺寸却不同，让一站图片在不同的屏幕都显示相同的比例。什么意思呢，就是说，设计稿里这张图占据了全部的宽度，那么在所有的屏幕上都要占据全部的宽度，如果在设计稿中占据了一半的宽度，那么在所有的屏幕上也要占据一半的宽度。\n\n因此，适配就是为了让UI元素在不同设备屏幕上，所占比例是相同的。\n\n可以看出，这样的适配只能满足一个方向，宽或者高。按照宽的比例调整就无法估计高，反之同理。若设备的宽高比与设计稿的宽高比相同，此时可兼顾两者。\n\n现在主要下面这几种适配方案。\n\n### 方案：修改density\n这套方案，是基于dp。\n\n因在绘制时使用的都是px，系统在将dp转化成px时，用的是TypedValue中的方法，最后输出都是px。\n```java\npublic static float applyDimension(int unit, float value, DisplayMetrics metrics) {\n        switch (unit) {\n        case COMPLEX_UNIT_PX: // pixel，像素\n            return value;\n        case COMPLEX_UNIT_DIP: // dp转px\n            return value * metrics.density;\n        case COMPLEX_UNIT_SP: // scaled dp 可缩放dp\n            return value * metrics.scaledDensity;\n        case COMPLEX_UNIT_PT: // point，1point = 1/72英寸\n            return value * metrics.xdpi * (1.0f/72);\n        case COMPLEX_UNIT_IN: // inch 英寸\n            return value * metrics.xdpi;\n        case COMPLEX_UNIT_MM: // millimeter 毫米\n            return value * metrics.xdpi * (1.0f/25.4f);\n        }\n        return 0;\n   }\n```\n直观的来看，同样是360dp宽的图片，在两个屏幕上所占比例不同的原因是，两个屏幕的宽度不同，一个是1080px/density=360dp，另个是1080px/density=480dp。\n\n这种方案逻辑是，动态修改屏幕的dp宽度，让屏幕的宽度等于设计稿的宽度。同时，屏幕的dp宽度是基于像素宽度和density计算出来的，而屏幕的像素宽度无法修改，所以要修改的就是density，这个值就是存储在DisplayMetrics中的一个变量，从上面的代码中可以看到，系统在将dp转化成px时，使用的是这个变量，所以修改这个变量就可以修改系统最终计算出来的px值。公式为：`动态density = 屏幕像素宽度/设计稿的dp宽度`\n\n修改的时机是，在系统使用之前，也就是在`setContentView`之前。\n\n```kotlin\nfun setCustomDensity(activity: Activity, application: Application, designWidthDp: Int) {\n        val appDisplayMetrics = application.resources.displayMetrics\n        val targetDensity = 1.0f * appDisplayMetrics.widthPixels / designWidthDp\n        val targetDensityDpi = (targetDensity * 160).toInt()\n        appDisplayMetrics.density = targetDensity\n        appDisplayMetrics.densityDpi = targetDensityDpi\n        val activityDisplayMetrics = activity.resources.displayMetrics\n        activityDisplayMetrics.density = targetDensity\n        activityDisplayMetrics.densityDpi = targetDensityDpi\n    }\n\noverride fun onCreate(savedInstanceState: Bundle?) {\n        setCustomDensity(this, application, 420)\n        super.onCreate(savedInstanceState)\n    }\n```\n\n这是字节给出的方案，成本极低，但是没有代码，Github上有人实现了一套，可以参考，[点击跳转](https://github.com/JessYanCoding/AndroidAutoSize)。\n\n### 方案：smallest width\n这套方案的原理是，手动指定每个像素所代表的dp数量。\n\n举个例子，假设设计稿是1080x1920\n\n在宽度为360dp的屏幕上，将宽度分为1080份，每份代表360/1080=0.33dp，然后生成这样一份文件：\n```xml\n<resources>\n    <dimen name=\"DIMEN_1PX\">0.33dp</dimen>\n    <dimen name=\"DIMEN_2PX\">0.66dp</dimen>\n    ...\n    <dimen name=\"DIMEN_1079PX\">359.67dp</dimen>\n    <dimen name=\"DIMEN_1080PX\">360dp</dimen>\n</resources>\n```\n在宽度为380dp的屏幕上，将宽度分为1080份，每份代表380/1080=0.35dp；\n在宽度为400dp的屏幕上，将宽度分为1080份，每份代表400/1080=0.37dp；\n...\n要针对当前的主流宽度屏幕各生成一份这样的文件，放到对应的目录下\n```shell\nvalues\nvalues-sw360dp\nvalues-sw380dp\nvalues-sw400dp\nvalues-sw420dp\n```\n在写布局文件时，控件的尺寸就用设计稿上的px尺寸，比如，设计稿上宽度为100px，那么在布局文件里就写`@dimen/DIMEN_100PX`，\n\n在360dp的屏幕上，就会读取到33dp，占比33/360=0.09；\n在380dp的屏幕上，就会读取到35dp，占比35/380=0.09；\n在400dp的屏幕上，就会读取到37dp，占比37/400=0.09；\n\n虽然在精度上有一些损失，但可忽略，实现了适配的需求。这种方案需要精准命中目标设备的宽度，所以需要我们准备足够多的这样的文件。\n\n### 方案：指定宽高\n这套方案的原理是，手动指定每个像素所代表的像素。\n\n这句话看着是不是有些别扭？一个像素不就是一个像素么，怎么还能代表其他像素呢？接着往下看\n\n上面的方案是按照屏幕宽度命中设备，这个方案是按照屏幕的像素宽度命中设备。\n\n还是那个例子，假设设计稿是1080x1920\n\n在720x1280的屏幕上，把宽分成1080份，每份代表720/1080=0.67px；把高分成1920份，每份代表0.67px；\n```xml\n<resources>\n    <dimen name=\"X1\">0.67px</dimen>\n    <dimen name=\"X2\">1.33px</dimen>\n    ...\n    <dimen name=\"X1079\">719.26px</dimen>\n    <dimen name=\"X1080\">720px</dimen>\n\n    <dimen name=\"Y1\">0.67px</dimen>\n    <dimen name=\"Y2\">1.33px</dimen>\n    ...\n    <dimen name=\"Y1079\">1279.33px</dimen>\n    <dimen name=\"Y1080\">1280px</dimen>\n</resources>\n```\n其中的X代表横向，Y代表竖向。\n\n在1080x1920的屏幕上，把宽分成1080份，每份代表1080/1080=1px；把高分成1920份，每份代表1920/1920=1px；\n在1440x2560的屏幕上，把宽分成1080份，每份代表1440/1080=1.33px；把高分成1920份，每份代表2560/1920=1.33px；\n\n将这些文件分别放到对应的目录下\n```shell\nvalues\nvalues-1280x720\nvalues-1920x1080\nvalues-2560x1440\n```\n在写布局文件时，控件的尺寸就用设计稿上的px尺寸，比如，设计稿上宽度为100px，高度为200px，那么在布局文件里就写`@dimen/X100`、`@dimen/Y200`，\n\n在1280x720的屏幕上，就会读取到，宽度67px，占比67/720=0.09，高度133px，占比133/1280=0.1；\n在1920x1080的屏幕上，就会读取到，宽度100px，占比100/1080=0.09，高度200px，占比200/1920=0.1；\n在2560x1440的屏幕上，就会读取到，宽度133px，占比133/1440=0.09，高度266px，占比266/2560=0.1；\n\n同上面一样，会有一些些精度上的损失，但基本上还是满足了适配的需求。这套方案也需要精准命中目标设备屏幕的像素宽高，因为同时指定了宽和高，所以相比上面只指定宽度的方案，需要准备更多的dimen文件，而现在市场的屏幕五花八门，很难保证准备的文件可以囊括所有的情况。\n\n### 总结\n抛开需求谈适配就是在扯淡，所以如果说哪个方案最合适，还是要看具体的需求。相比之下，第一套方案操作简单，且成本低，不用额外添加适配文件，不会进一步增加包体大小。","tags":["Android","屏幕适配"],"categories":["Android"]},{"title":"Android Fragment","url":"/2021/09/5536a870cb20/","content":"\n[原文地址](https://juejin.cn/post/7006970844542926855)\n\n<!--more-->\n\n原作者的slogan是，喜欢写又臭又长的文章。这篇文章确实长的很，洋洋洒洒上万字，就这字数就过滤掉了很大一部分人，但是我喜欢。写的很好，里面内容有旧也有新，担心哪天点开这链接弹出来个404，所以摘抄点出来。\n\n### 生命周期\nFragment中有两个生命周期，一个自身的生命周期，另一个是其所包含的View的生命周期，其中的View是可以多次被创建和销毁的，所以在使用ViewModel时，要将数据与View的生命周期相关联。\n![](https://i.loli.net/2021/09/19/YHsuRZOc6TSxVJA.png)\n\n### 回退栈\n增加/移除/替换Fragment都是基于事务进行的，当提交事务时，将事务添加到了回退栈，那么在将事务从回退栈中弹出时，FragmentManager就会reverse its operation，反向执行事务的操作，也就是恢复成该事务执行之前的状态。按下返回键，如果回退栈不为空，则回退栈就会弹出事务来响应返回按钮事件。当然，也可以不将事务加到回退栈中。相关接口：\n```kotlin\nFragmentTransaction.addToBackStack\nFragmentTransaction.popBackStack\nFragmentTransaction.disallowAddToBackStack\n```\n\n### registerForActivityResult\n`startActivityForResult`和`onActivityResult`都已经废弃，`registerForActivityResult`是官方推荐的从Activity获取数据的方式，新方式变得灵活了不少，如下：\n- 创建`ActivityResultContract<I, O>`的实例，声明输入/输出数据，需要实现里面的抽象方法。`createIntent`方法用来获取跳转的Intent，`parseResult`用来处理返回的数据\n- 创建`ActivityResultCallback<O>`接口实例，用来处理返回的数据，里面只有一个方法`onActivityResult`\n- 最后调用ComponentActivity中方法`registerForActivityResult(contract, callback)`把前两步创建的参数传入即可\n\n### Fragment Result\n在FragmentManager有这样一组方法，可以进行数据通信：\n```java\npublic final void setFragmentResultListener(String requestKey, LifecycleOwner lifecycleOwner, FragmentResultListener listener)\n\npublic final void setFragmentResult(String requestKey, Bundle result)\n```\n简单说，就是在观察者模式的基础上，加上了生命周期的管理，不管是Activity还是Fragment，只要能获取到同一个FragmentManager就可以通信。需要注意的是，里面保存key和listener用的是`Map<String, FragmentResultListener>`，所以一个key只能有一个listener，后面的会把前面的覆盖。\n\n### Fragment中监听返回按键\n```kotlin\nclass PlaceholderFragment(private val sectionNumber: Int) :\n    Fragment(R.layout.fragment_placeholder) {\n\n    private val onBackPressedCallback = object : OnBackPressedCallback(true) {\n        override fun handleOnBackPressed() {\n            //TODO       \n        }\n    }\n\n    override fun onAttach(context: Context) {\n        super.onAttach(context)\n        requireActivity().onBackPressedDispatcher.addCallback(this, onBackPressedCallback)\n    }\n}\n```\n\n### 其他用途\n- Fragment可设置内部的UI View，也可以不设置。当不设置时，可用其来监听生命周期，其中LifeCycle、Glide用的便是这种方式。\n- 也可以用作方法代理，请求权限，可将请求与处理放到一起处理，而不是像`registerForActivityResult`分开处理。FragmentTransaction的`add`方法都有多个重载方法，支持只添加一个Fragment，若此Fragment无View，则对用户来说是无感的，但对于我们来讲可以在其中处理一些业务。","tags":["Android","Fragment"],"categories":["Android"]},{"title":"Android之检查知否开了代理","url":"/2021/09/044f31f510db/","content":"\n最近有个新需求，用户如果开启了代理，就不让进入，在此记录一下检查方式。\n\n<!--more-->\n简单说，就是通过`ConnectivityManager`获取到设备当前的所有网络连接，如果其中包含`TRANSPORT_VPN`类型的连接，则认为开启了代理。\n\n代码如下\n```kotlin\nfun checkProxyOpen(ctx: Context): Boolean {\n     val manager = ctx.getSystemService(Context.CONNECTIVITY_SERVICE) as ConnectivityManager\n     manager.allNetworks.toList().forEach { network ->\n         val cap = manager.getNetworkCapabilities(network)\n         val vpnTransport = cap?.hasTransport(NetworkCapabilities.TRANSPORT_VPN) ?: false\n         if (vpnTransport) {\n             return true\n         }\n     }\n     return false\n}\n```","tags":["Android","Proxy"],"categories":["Android"]},{"title":"多apk导出与安装","url":"/2021/09/b14c888939d1/","content":"\n在aab盛行的年代，一个应用已经不单单对应一个apk文件了，经常是两个，或是多个。\n\n<!--more-->\n在设备上安装一个应用后，安装时的apk文件都是会存储在手机里的。不知道做没做过这样的需求，就是反编译别人apk，看看里面都有些什么，图片资源也好，库文件也罢。\n\n### adb导出apk\n\n```shell\n# 如果不知道完整的包名，就先这样过滤出目标包名\n$ adb shell pm list package | grep key-word\n\n# 获取apk文件路径\n$ adb shell pm path target.pakcage.name\n\n# 经过上一步，会得到一个或多个apk文件的路径，导出到本地\n$ adb pull xxxx.apk ~/xxx.apk\n```\n拿到apk文件了，就可以做想做的事了，比如用jadx反编译。\n\n另外，这个文件的位置，通过package manager也可以得到，代码如下：\n```java\nPackageManager pm = getPackageManager();\nApplicationInfo info = pm.getApplicationInfo(\"package_name\", 0);\nString path = info.sourceDir; // 这个path就是上面pm path的结果\n```\n\n### adb安装多apk\n安装单个apk\n```shell\n$ adb install xxx.apk\n```\n安装多个apk\n```shell\n$ adb install-multiple 1.apk 2.apk 3.apk\n```\n\n### 题外话\n终端窗口直接执行adb命令，会显示出命令介绍，不难发现它有三个安装命令，\n```shell\n$ adb\napp installation (see also `adb shell cmd package help`):\n install [-lrtsdg] [--instant] PACKAGE\n     push a single package to the device and install it\n install-multiple [-lrtsdpg] [--instant] PACKAGE...\n     push multiple APKs to the device for a single package and install them\n install-multi-package [-lrtsdpg] [--instant] PACKAGE...\n```\n除了install和install-multiple，还有个install-multi-package命令。\n\ninstall和install-multiple都是安装单应用的，一个对应单apk，一个是多apk。而install-multi-package命令是安装多应用，意思就是一次同时安装多个应用。你可能会想，怎么会需要一次安装多个应用呢，平常不都是单个开发的吗？\n\n有些需求吧，直到你遇到前你都不会相信：原来还真的会有这样的需求啊～\n\n我是真的遇到了，所以顺便提一提。另外还有，不是所有版本的设备都支持这个命令，在不支持的设备上执行后就会报错，不用深究，换个测试机就可以。","tags":["Android"],"categories":["Android"]},{"title":"Android之drawable和mipmap的区别","url":"/2021/09/86f0cc8aed5a/","content":"\nAndroid项目里，res中有两种放资源图片的目录，一个是drawable，另一个是mipmap。\n\n<!--more-->\n\n使用Android Stuido创建新项目时，默认会把app icon放到mipmap里，每个分辨率里各放一份，从hdpi到xxxhdpi，1倍图到4倍图。\n\n但是开发过程中，资源图一般都是放到drawable中，我们常用的是3倍图目录，drawable-xxhdpi，习惯了这样做却没深究为什么这样做。\n\n既然已经创建了mipmap目录，为什么不直接使用，而非要用手动创建的drawable目录呢？\n\n突然想到这个问题，就查了一下，原来这两个目录除了名字，还是有其他区别的：\nmipmap目录在安装到设备后，各个分辨率的资源会全部保留，而drawable下的资源只会选择一份合适的，其他的不保留。\n\n特意验证了一下：\n- 创建一个新项目，把一张图在drawable-xxhdpi（3倍）和drawable-xhdpi（2倍）中各放一份\n- 安装到一个屏幕密度440，也就是2.75倍的设备上（160为1倍）\n- adb导出apk包，jadx反编译\n- 发现只有3倍目录下有这张图，2倍目录下没有\n- 验证正确","tags":["Android"],"categories":["Android"]},{"title":"AAB介绍以及bundletool的使用","url":"/2021/09/4d7cb573fdf1/","content":"\n自2021年8月开始，GooglePlay商店要求开发者使用AAB来发布新应用。自打2018年5月谷歌官方推出AAB，已经过去了3个年头。\n\n<!--more-->\n\n### 介绍\nAAB，即Android App Bundle，可以把它理解成是新一代的APK。相比于APK，它的优点是可以进一步减小安装包的大小。\n\n举个例子，如果项目了引用了native库，那么一般都会有多个so库文件，每个库文件对应一种abi架构。\n\n当使用apk安装时，需要把所有so文件打到apk文件里，移动端下载该apk文件来安装程序；\n\n当使用aab安装时，会根据移动端的架构选择出对应的库文件，以及其他资源和代码，打到apk文件里，移动端下载该apk文件来安装程序，这样就不需要下载其他用不上的库文件，下载的文件小，省时间又省流量，用户体验好，所有官方主推这种格式。\n\n可以看到，中间有个过程，根据请求安装的客户端来生成对应的apk安装包，这件事就是Goolge Play商店在做。目前，不是所有的应用商店都支持了这个操作，只能在支持的应用商店上使用aab分发应用，不支持的依然要用apk格式的文件。\n\n### 分割维度\n根据官方文档介绍，[点击查看](https://developer.android.com/guide/app-bundle/configure-base#disable_config_apks)，支持3个维度的分割：语言、分辨率和架构\n```groovy\nandroid {\n    // When building Android App Bundles, the splits block is ignored.\n    splits {...}\n\n    // Instead, use the bundle block to control which types of configuration APKs\n    // you want your app bundle to support.\n    bundle {\n        language {\n            // Specifies that the app bundle should not support\n            // configuration APKs for language resources. These\n            // resources are instead packaged with each base and\n            // feature APK.\n            enableSplit = false\n        }\n        density {\n            // This property is set to true by default.\n            enableSplit = true\n        }\n        abi {\n            // This property is set to true by default.\n            enableSplit = true\n        }\n    }\n}\n```\n\n### 生成aab文件\nGradle任务中，有配置好的task，bundleDebug、bundleRelease，执行对应的task就可以生成aab文件。\n\n严格来讲，aab文件并不是安装包，在生成的时候并不知道目标设备的信息，所以只能算是一堆零件，可以按需组装。\n\n### bundletool\n[谷歌官方介绍](https://developer.android.com/studio/command-line/bundletool) [官方项目地址](https://github.com/google/bundletool)\n这是个专门用来操作aab文件的工具，可在项目里直接下载jar包使用，也可以通过`brew install bundletool`安装。\n\n这个工具可以通过aab文件生成apks、将apks安装到手机，还有几个不常用的功能，可以看项目里的介绍。\n\n1. 生成设备规范的JSON文件\n```shell\n$ bundletool get-device-spec --output=/tmp/device-spec.json\n```\n这个命令可以生成当前连接设备的规范文件，也就是参数信息文件。也可以手动创建，格式如下：\n```json\n{\n  \"supportedAbis\": [\"arm64-v8a\", \"armeabi-v7a\"],\n  \"supportedLocales\": [\"en\", \"fr\"],\n  \"screenDensity\": 640,\n  \"sdkVersion\": 27\n}\n```\n\n2. 生成apks\n```shell\n$ bundletool build-apks --bundle=/MyApp/my_app.aab --output=/MyApp/my_app.apks\n```\n此外还可以通过`ks`,`ks-pass`,`ks-key-alias`,`key-pass`四个参数来指定签名，如果不指定则使用缺省的签名文件\n这个apks是针对所有设备，加上`--connected-device`数可生成只针对当前连接的设备，多个设备时使用`--device-id=serial-id`，也可以使用`--device-spec=xxx.json`通过JSON文件来限定。\n为什么是apks呢，因为这真的就是多个apk。把.apks改成.zip后解压缩，就会看到里面有很多apk文件，包括基本的apk，以及按维度分割的apk。\n\n3. 安装apks到设备\n```shell\n$ bundletool install-apks --apks=xxx.apks\n```\n可以再检查一下都安装了哪几个apk文件：\n```shell\n$ adb shell pm path your.app.package.name\npackage:/data/app/your.app.package.name-_cJc4OrWZxYQCwC4AaWAtw==/base.apk\npackage:/data/app/your.app.package.name-_cJc4OrWZxYQCwC4AaWAtw==/split_config.arm64_v8a.apk\n```\n可以看到，安装了一个基本的base.apk，以及一个对应abi的apk。想查询设备上其他app时，可以通过这个命令来查询包名：\n```shell\n$ adb shell pm list package | grep key-word\n```\n\n4. 其他命令\n- 抽取apks的子集\n```shell\nbundletool extract-apks\n--apks=/MyApp/my_existing_APK_set.apks\n--output-dir=/MyApp/my_pixel2_APK_set.apks\n--device-spec=/MyApp/bundletool/pixel2.json\n```\n- 获取下载的大小\n```shell\nbundletool get-size total --apks=/MyApp/my_app.apks\n```\n\n### 总结\n国内一般都是无线网来下载、安装，但老外们使用流量的却不在少数，所以如果能减少安装包的大小，对于提高CVR还是有一定帮助的。\n\n","tags":["Android","bundletool"],"categories":["Android"]},{"title":"Android混淆配置","url":"/2021/09/54483afe4c94/","content":"\n记录一下混淆配置。\n\n<!--more-->\n\n混淆，其实就是给项目里的类、变量、方法等，换个名字，以此来降低可读性，同时还可以使包体变小。\n\n### 单模块项目\n这个相对简单，只需要配置build.gradle文件\n```groovy\nandroid {\n    buildTypes {\n        release {\n            minifyEnabled true // 打开混淆开关，只有为true的时候才会混淆\n            proguardFiles getDefaultProguardFile('proguard-android-optimize.txt'), 'proguard-rules.pro'\n            // 还可以再加两个配置来进一步减小包体\n            zipAlignEnabled true // 对齐\n            shrinkResources true // 移除\n        }\n    }\n}\n```\n- 只有打开minifyEnabled开关才会混淆\n- proguardFiles用来指定混淆配置文件，参数里的文件都会生效\n- proguard-android-optimize.txt在: ～/Android/sdk/tools/proguard/目录下\n- 除了上面这个文件，还有其他几个官方写好的默认配置\n- proguard-rule.pro在build.gradle同目录下，自己额外的混淆配置写在这个文件里\n\n### 多模块项目\n所有混淆配置写在一起，便于修改和管理，但是当不再依赖其中某个模块而将其移除后，这时混淆文件中对应的配置就是冗余的。\n\n所以，一般都是各自模块的混淆配置写在所在的模块里。主模块开启混淆，就会给所有模块混淆。\n\n主模块的配置依然同上，子模块的配置如下：\n```groovy\nandroid {\n    buildTypes {\n        release {\n            consumerProguardFiles 'proguard-rules.pro'\n        }\n    }\n}\n```\n如果不关心编译类型的话，可以直接写在默认配置块，使用AndroidStudio创建项目时，它已经帮忙写上了，用consumer-rules.pro文件名来区分\n```groovy\nandroid {\n    defaultConfig {\n        consumerProguardFiles \"consumer-rules.pro\"\n    }\n}\n```\n- 注意这里使用的是consumerProguardFiles\n- proguardFiles配置在子模块里是不生效的\n- getDefaultProguardFile只能在proguardFiles里使用\n\n### 输出文件\n- dump.txt 说明apk中所有类文件的内部结构\n- mapping.txt 原始于混淆后的类、方法和字段名称的对应关系\n- seeds.txt 未进行的混淆的类和成员\n- usage.txt 从apk移除的代码\n\n### 总结\n打开官方写好的配置文件，可以看到里面已经包含了用到的基本配置。所以不管是主模块还是子模块的proguard-rule.pro里，只需要写上自己额外需要的配置，如gson数据类，以及引入的第三方依赖所要求的反混淆配置，即可。","tags":["Android"],"categories":["Android"]},{"title":"Android 9发送http请求","url":"/2021/09/3b8c4beeb864/","content":"\n目前的http请求有两种，一种是明文的http请求，一种是加了密的https请求。官方出于安全考虑，Android 9及以后的版本，系统默认禁掉了http请求。但有些需求，偏偏需要我们发送http请求，这个时候就需要额外加个配置。\n\n<!--more-->\n\n在res目录下，新建个名叫xml的目录，在里面新建个xml文件，名字随意合法即可，但一般都是叫`network_security_config.xml`，让人一看到名字就知道这文件的作用。文件内添加http访问请求的配置，如下：\n```xml\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<network-security-config>\n    <base-config cleartextTrafficPermitted=\"true\" />\n</network-security-config>\n```\n\n然后再把这个配置，应用到application，在AndroidManifest.xml中，修改application标签，添加一行，如下：\n```xml\n <!-- 其他内容省略 -->\n <application\n        android:networkSecurityConfig=\"@xml/network_security_config\"> \n</application>\n```\n\n创建个配置文件，然后应用到application，这样就可以发送http请求了。","tags":["Android","Http"],"categories":["Android"]},{"title":"Java之反射","url":"/2021/09/48858ef75b98/","content":"\n反射，是Java的一种高级特性。就我而言，实际开发中很少遇到用反射的需求，但这并不能否定反射的重要地位，这篇文章来简单说一说。\n\n<!--more-->\n\n\n### 前言\n在Java里，有一个类，名字叫`Class`，这个名字总是容易给人一种这是个特殊的类。其实，和其他类一样，这也是个普通的类，在`java.lang`包下，lang就是language的简写，里面都是和Java语言本身相关的东西。这个类里面包含了一个类的所有信息：\n```java\n// 省略了一些代码\npackage java.lang\n\npublic final class Class<T> {\n\n\t// 这里只列举了一部分\n\tString name; // 类名\n\tClassLoader classLoader; // 类加载器\n\tString packageName; // 包名\n\tClass<?>[] interfaces; // 所实现的接口\n\tConstructor<?>[] contructors; // 构造方法\n\tField[] fields; // 字段\n\tMethod[] methods; // 方法\n\tint modifiers; // 类修饰符\n\n    private Class(ClassLoader loader, Class<?> arrayComponentType) {\n        this.classLoader = loader;\n        this.componentType = arrayComponentType;\n    }\n}\n```\n\n在JVM首次调用到一个类的时候，会先将这个类加载到JVM里，这个过程就是在为这个类创建Class实例，且JVM只会为每个类创建一个Class实例，如果存在则在直接使用。可以看到，Class只有一个构造方法，而且是私有的，只有JVM可以调用。\n\n那么，怎么获取到JVM创建的Class实例呢？一共有3种方式：\n```java\n// 方式1：通过类的静态变量class\nClass clz = String.class;\n\n// 方式2：通过实例的方法\nString str = \"str\";\nClass clz = str.getClass();\n\n// 方式3：通过Class的静态方法Class.forName\n// Class.forName有3个重载方法，可以传入不同的限定名称\nClass clz = Class.forName(\"java.lang.String\");\n```\n\n通过类的Class实例，我们可以创建类的实例，调用类的所有成员变量、和成员方法，包括私有的。\n\n### 方法概览\n通过反射，一般有三个目的：获取构造方法Constructor来创建实例、获取方法Method来调用，以及获取字段Field来set/get值。除此之外，还可以获取其他信息，如注解，来完成额外的操作，这些在这先不讨论。\n\n||构造方法|字段|方法|\n|--|--|--|--|\n|单个public|getConstructor()|getField()|getMethod()|\n|所有public|getConstructors()|getFields()|getMethods()|\n|类里任一|getDeclaredConstructor()|getDeclaredField()|getDeclaredMethod()|\n|类里所有|getDeclaredConstructors()|getDeclaredFields()|getDeclaredMethods()|\n\n- 不加s是获取单个，加s是获取所有\n- 不加declared的，是获取public的，protected都不行，必须public，可以是自己的，也可以是继承的\n- 加declared的，是获取类里面自己声明的，只能是写在类里的成员，不能是继承的，公开的、私有的都可以获取\n\n### 示例类\n创建了一个示例接口和一个示例类，很简单，看一眼就可以跳过。\n```java\n// Person接口\npublic interface Person {\n    String getName();\n    void sayHi(String toWho);\n}\n\n// Student实现类\npublic class Student implements Person {\n\n    // 一个私有变量  一个公开变量\n    private int sex;\n    public int score;\n\n    // 一个无参数构造方法 一个有参数的构造方法\n    public Student() {\n        this.score = 0;\n        this.sex = 1;\n    }\n\n    public Student(int score, int sex) {\n        this.score = score;\n        this.sex = sex;\n    }\n\n    // 私有构造方法\n    private Student(int score) {\n        this.score = score;\n        this.sex = 2;\n    }\n\n    // 继承过来的方法\n    @Override\n    public String getName() { return \"student\"; }\n\n    @Override\n    public void sayHi(String toWho) {\n        System.out.println(\"student say hi to :\" + toWho);\n    }\n\n    // 一个私有方法\n    private void setSex(int sex) { this.sex = sex; }\n\n    public int getSex() { return sex; }\n}\n\n```\n\n### 通过反射获取构造方法\n- 获取无参构造方法\n```java\n// 获取Class实例\nClass<Student> clz = Student.class;\n\nConstructor<Student> cst = clz.getConstructor();\nSystem.out.println(cst.newInstance().score); // 缺省值 0\n```\n- 获取有参数的构造方法\n```java\nClass<Student> clz = Student.class;\n\nConstructor<Student> cst = clz.getConstructor(int.class, int.class);\nSystem.out.println(cst.newInstance(80, 1).score); // 传入值 80\n```\n- 获取私有的构造方法\n```java\nClass<Student> clz = Student.class;\n\n// 这里必须用加declared的，因为带一个参数的构造方法是私有的\nConstructor<Student> ctr3 = clz.getDeclaredConstructor(int.class);\nctr3.setAccessible(true); // 使用私有的成员前，需要先设置为可访问\nSystem.out.println(ctr3.newInstance(55).score);\n```\n\n### 通过反射获取字段\n字段，Field，即类里面声明的成员变量。像上面，通过Class实例获取到类的构造函数，可以用其创建类的实例，那获取到字段有什么用呢？用字段可以获取其对应的值，所以，就需要一个类的实例，有了实例，才能获取。\n- 获取公开字段\n```java\nClass<Student> clz = Student.class;\n\nField score = clz.getField(\"score\"); // 通过字段名字获取\n// 使用字段，需要一个Student实例\nStudent student = new Student(60, 1);\n//  这句话的意思就是，获取student实例中score字段的值\nSystem.out.println(score.get(student)); // 60\n```\n- 获取私有字段\n```java\nClass<Student> clz = Student.class;\nStudent student = new Student(60, 1);\n\nField sex = clz.getDeclaredField(\"sex\"); // 这里必须加declared 通过字段名字获取\nsex.setAccessible(true); // 设置可访问\nsex.set(student, 10); // 先设置为10\nSystem.out.println(sex.get(student)); // 10\n```\n\n### 通过反射获取方法\n字段可通过名字获取，但方法不可只通过名字，因为会存在方法重载，即几个方法名字一样，但参数类型或者数量不同，所以要获取方法，就需要指定方法名称，同时和方法的参数的类型列表。和字段相同的是，方法在调用的时候，也需要一个实例，有了实例，才能在这个实例上调用其方法。\n- 获取公开方法\n```java\nClass<Student> clz = Student.class;\nStudent student = new Student(60, 1);\n\nMethod sayHi = clz.getMethod(\"sayHi\", String.class); // 指明方法名，和参数类型\nsayHi.invoke(student, \"Teacher\"); // student say hi to :Teacher\n```\n- 获取私有方法\n```java\nClass<Student> clz = Student.class;\nStudent student = new Student(60, 1);\n\nMethod setSex = clz.getDeclaredMethod(\"setSex\", int.class); // 指明方法名，和参数类型\nsetSex.setAccessible(true); // setSex是私有的，先设置为可访问\nsetSex.invoke(student, 100); // 调用，设置sex的值\nSystem.out.println(student.getSex()); // 100\n```\n\n### 总结\n通过上面的例子，可以看出：反射都是基于类的Class实例，通过里面的成员，来进行一些操作的。先获取到Class实例，再获取对应的成员变量，比如字段、方法等，然后再利用这些成员，采取一些操作来达成目的。\n\n没有太多代码，就不创建项目了，附上所有代码：\n<script src=\"https://gist.github.com/oynix/414b7208de0e3d0b59b2aaa3879b82de.js\"></script>","tags":["Java","反射"],"categories":["Java"]},{"title":"使用HtmlCompat改变字体样式","url":"/2021/09/995b1034fc8d/","content":"\n这篇文章说一说Android中的`HtmlCompat`使用。\n\n众所周知的是，要想做出各种炫酷多变样式的字体，使用Html+CSS最方便。一来是标签语法简单，二来是它支持设定很多属性。`HtmlCompat`这个类，就是帮助我们在Android中使用Html+CSS语法的工具。\n\n<!--more-->\n\n### 介绍\n`HtmlCompat`是`Html`的包装类，其中只有两个方法：一个是`fromHtml`，另个是`toHtml`。\n\n其实，所有带有Compat的类基本都是包装类。在Android SDK升级的过程中，到了某个版本某些类可能有了大改动，比如多了重载方法，这个版本以前的SDK，调用老方法；这个版本之后的调用新方法。而包装类的出现是为了方便调用者，我们只管调用包装类中的方法，而包装类里面会根据版本做出判断，去调用对应的方法。\n\n- fromHtml\n故名思义，这个方法就是把Html语法转换成要最终的样式，这个常用，这次主要说一说它\n\n- toHtml\n与`fromHtml`相反，很少用，还没有遇到过这样的需求，就不说了\n\n### 使用\n```java\npublic static Spanned fromHtml(@NonNull String source, @FromHtmlFlags int flags) {\n    if (Build.VERSION.SDK_INT >= 24) {\n        return Html.fromHtml(source, flags);\n    }\n    return Html.fromHtml(source);\n}\n```\n- param: source\n即Html文本，如\"\\<b\\>Hello\\<\\/b\\> World!\"，标签b会将Hello加粗显示\n\n- param: flags\n一看便知，这个是SDK 24新加的参数，它的作用是添加一些额外的操作，它现在有9个可选的常量值，每个值都有介绍，比如：`<p>`标签会从新的一行开始、`<h>`标签会从新的一行开始，等等。一般不需要，传0即可\n\n### 支持的标签\n官方文档写的很简单，这是地址：[文档](https://developer.android.com/reference/kotlin/androidx/core/text/HtmlCompat?hl=en)。我是从源码中看的，`Html.java`文件中，有个`handleStartTag`方法，它支持以下的标签解析：\n> br, p, ul, li, div, span, strong, b, em, cite, dfn, i, big, small, font, blockquote, tt, a, u, del, s, strike, sup, sub, h, img\n\n\n### 常用效果\n- 加粗\nb和strong都是加粗，效果是一样的，在解析的时候同等方式处理\n```kotlin\nprivate fun genBold() = HtmlCompat.fromHtml(\n    \"加粗效果：<b>加粗</b> or <strong>加粗2</strong>\", 0\n)\n```\n- 倾斜\n有多个标签都是倾斜：em、cite、dfn、i，它们的效果是一样的\n```kotlin\nprivate fun genItalic() = HtmlCompat.fromHtml(\n    \"倾斜效果: <i>倾斜</i> <em>倾斜</em> <cite>倾斜</cite>\", 0\n)\n```\n- 下划线\n```kotlin\nprivate fun genUnderline() = HtmlCompat.fromHtml(\n    \"下划线：<u>下划线</u>\", 0\n)\n```\n- 删除线\n```kotlin\nprivate fun genDelLine() = HtmlCompat.fromHtml(\n    \"删除线：<del>删除线</del>\", 0\n)\n```\n- 上角标\n```kotlin\nprivate fun genSup() = HtmlCompat.fromHtml(\n    \"上角标：2<sup>3</sup>\", 0\n)\n```\n- 下角标\n```kotlin\nprivate fun genSub() = HtmlCompat.fromHtml(\n    \"下角标：a<sup>4</sup>\", 0\n)\n```\n- 字体样式 \n这里的font只支持两个属性，看过源码才知道，之前还一直研究为什么别的属性不生效。\n一个是color，一个是face。color用来改变字体颜色，face用来改变字体的样式，face用的少，color用的多。\nface有四个可选值：normal默认，sans无衬线字体，serif有衬线字体，monospace等宽字体。\n```kotlin\nprivate fun genFont() = HtmlCompat.fromHtml(\n    \"字体样式：<font color='#873748' face='monospace'>字体颜色</font>,\" +\n            \"<font face='sans'>字体Face sans</font>\", 0\n)\n```\n\n### 自定义标签\n系统提供的标签就是这么多，如果需要一些其他的效果，如改变字体大小，可以自定义标签。`HtmlCompat.fromHtml`有个重载方法，是用来支持自定义标签的：\n```java\npublic static Spanned fromHtml(@NonNull String source, @FromHtmlFlags int flags,\n            @Nullable ImageGetter imageGetter, @Nullable TagHandler tagHandler) {\n        if (Build.VERSION.SDK_INT >= 24) {\n            return Html.fromHtml(source, flags, imageGetter, tagHandler);\n        }\n        return Html.fromHtml(source, imageGetter, tagHandler);\n    }\n```\nsource和flags同上，如果使用了img标签，就要提供ImageGetter参数来获取图片，没用则传入null；如果使用了自定义标签，则需提供tagHandler来解析自定义的标签。\n\n说一说自定义字体。\n\n需要先创建一个类，实现TagHandler接口，接口里就一个方法，`handleTag`，是用来解析标签的，在这里添加逻辑\n```kotlin\n// size是字号\nclass SizeLabel(private val size: Int) : Html.TagHandler {\n\t// 记录开始的角标和结束的角标\n    private var startIndex = 0\n    private var stopIndex = 0\n\n    // 这个方法会被调用两次，开始标签调用一次，opening=true，结束标签调用一次，opening=false\n    // output就是实时解析出来的内容\n    override fun handleTag(opening: Boolean, tag: String, output: Editable, xmlReader: XMLReader?) {\n    \t// tag就是标签的名字，这个名字不可与系统支持的重复，因为自定义的标签是放在判断的最后一个else里处理的\n        if (tag.lowercase(Locale.getDefault()) == \"size\") {\n            if (opening) {\n                startIndex = output.length\n            } else {\n                stopIndex = output.length\n                output.setSpan(\n                    AbsoluteSizeSpan(size),\n                    startIndex,\n                    stopIndex,\n                    Spanned.SPAN_EXCLUSIVE_EXCLUSIVE\n                )\n            }\n        }\n    }\n\n}\n```\n使用的方式与上类似，如下：\n```kotlin\nprivate fun genSizeLabel() = HtmlCompat.fromHtml(\n    \"自定义标签size：<size>加大字号</size>\", 0, null, SizeLabel(50)\n)\n```\n\n\n### 总结\n总的来说，方式简单，用起来也很简单，可以满足一些基本的奇特UI需求。除了使用Html的方式，还有一些其他的方式，如在`strings.xml`文件中定义，也可以实现一些特殊的效果。\n\n还可以使用`Span`来实现，这个的功能相当的多，在`android.text.style`这个包下都是它的实现类，每个类都可以实现一种UI效果，下次用到的时候再来仔细说一说。\n\n附上示例的Github地址：[https://github.com/oynix/htmlcompat-sample](https://github.com/oynix/htmlcompat-sample)","tags":["Android"],"categories":["Android"]},{"title":"Hexo+Github快速搭建个人博客","url":"/2021/09/33313fbab399/","content":"现在搭建个人博客的方式越来越多，而且过程也越来越简单。大体的思路，都是先生成静态网页，然后部署到一个依托网站。\n\n这篇文介绍的是用Hexo生成静态网站，然后部署到Github。\n\n<!--more-->\n\n### 介绍Node和npm\nHexo是用Node写的，所以要安装它所依赖的环境后才能用，先贴一下廖雪峰关于Node和npm关系的介绍\n> npm是什么东东？npm其实是Node.js的包管理工具（package manager）。\n>\n>为啥我们需要一个包管理工具呢？因为我们在Node.js上开发时，会用到很多别人写的JavaScript代码。如果我们要使用别人写的某个包，每次都根据名称搜索一下官方网站，下载代码，解压，再使用，非常繁琐。于是一个集中管理的工具应运而生：大家都把自己开发的模块打包后放到npm官网上，如果要使用，直接通过npm安装就可以直接用，不用管代码存在哪，应该从哪下载。\n>\n>更重要的是，如果我们要使用模块A，而模块A又依赖于模块B，模块B又依赖于模块X和模块Y，npm可以根据依赖关系，把所有依赖的包都下载下来并管理起来。否则，靠我们自己手动管理，肯定既麻烦又容易出错。\n\n### 安装Node和npm\n开始我用`brew`装了半天，中间总有个包不成功。最后发现直接从Node官网下载安装包最省事，一步到位。[https://nodejs.org/en/](https://nodejs.org/en/)。\n\n安装完之后检查一下，如果能显示出版本号，就可以了：\n```sh\n$ node -v\nv14.17.6\n\n$ npm -v\n6.14.15\n```\n\n### 安装hexo-cli\n这个工具是帮助我们初始化个人站的，一行命令就可以生成一个空站点\n```sh\n# For Mac\n$ sudo npm install hexo-cli -g\n\n# For Windows\n$ npm install hexo-cli -g\n```\n\n装完之后，验证一下是否成功，显示如下内容则表示成功了\n```sh\n$ hexo\nUsage: hexo <command>\n\nCommands:\n  help     Get help on a command.\n  init     Create a new Hexo folder.\n  version  Display version information.\n```\n\n### 初始化个人站\n一行命令即可：\n```sh\n# blog就是网站目录的名字，可随意起，合法即可\n$ hexo init blog\nINFO  Cloning hexo-starter https://github.com/hexojs/hexo-starter.git\nINFO  Install dependencies\nadded 242 packages from 207 contributors and audited 243 packages in 13.774s\n\n15 packages are looking for funding\n  run `npm fund` for details\n\nfound 0 vulnerabilities\n\nINFO  Start blogging with Hexo!\n```\n\n然后，进到blog目录，可以看到，这就是个Node项目。`package.json`里面是项目所需要的依赖，接下来安装依赖\n```sh\n# 切换到项目根目录\n$ cd blog\n\n$ npm install\nadded 1 package from 5 contributors and audited 243 packages in 2.29s\n\n15 packages are looking for funding\n  run `npm fund` for details\n\nfound 0 vulnerabilities\n\n```\n执行一下hexo命令，如下显示则说明成功:\n```sh\n$ hexo\nINFO  Validating config\nUsage: hexo <command>\n\nCommands:\n  clean     Remove generated files and cache.\n  config    Get or set configurations.\n  deploy    Deploy your website.\n  generate  Generate static files.\n  help      Get help on a command.\n  init      Create a new Hexo folder.\n  list      List the information of the site\n  migrate   Migrate your site from other system to Hexo.\n  new       Create a new post.\n  publish   Moves a draft post from _drafts to _posts folder.\n  render    Render files with renderer plugins.\n  server    Start the server.\n  version   Display version information.\n```\n\n### 生成静态网站\n看上面的命令介绍，其中这几个最常用：\n- `generate`：就是用来生成静态网站的，一般简写成`g`\n- `server`：是在本地运行，也就是把静态网站依托在本机上，一般简写成`s`\n- `deploy`：是把静态站部署到远程，一般简写成`d`\n- `new`：用来生成一片空文章\n- `init`：用来生成一个空页面\n- `claan`：是删除生成的静态网站\n\n```sh\n# 生成\n$ hexo g\n\n# 运行\n$ hexo s\nINFO  Validating config\nINFO  Start processing\nINFO  Hexo is running at http://localhost:4000 . Press Ctrl+C to stop.\n```\n看提示可以知道，hexo正在运行，在浏览器中访问本地的4000端口，就可以看到了\n\n### 部署之Github Token\n所谓部署，就是把生成的静态网站的所有文件，推送到远程的Github仓库。所以，Hexo就需要推送的权限。我用的是https协议，还没试过git协议。https的方式就是把带有推送权限的token放到仓库链接里即可。\n\nGithub Token：Github首页 -> 右上角个人头像 -> Settings -> Developer settings -> Personal access token -> Generate new token -> 把repo的大权限勾上\n\n默认的过期时间Expiration是30天，可以选长一点，不然过期之后还要更新token。最后就得到了一个以`ghp_`开头、总长度为40的字符串的token。\n\n### 部署之远程仓库\n在Github上新建个仓库，用来放静态网站的文件。仓库的名字有要求，一般是这样的：`*.github.io`，\n星号可以替换成你自己想要的单词。然后，这整个就是仓库的名字，比如我的仓库地址就是：\n> `https://github.com/oynix/oynix.github.io.git`\n\n\n- 如果，这个星号使用的是Github账号的名字，那么最终的网站地址就是：\n> `https://oynix.github.io/`\n- 如果，这个星号使用的是其他的名字，比如blog，那么最终的网站地址就是：\n> `https://oynix.github.io/blog.github.io/`\n\n换句话说，如果想要用最短URL，那么就用Github账号的名字；如果要用到path了，可以给仓库起个短点名字，如就叫blog，那么最终的网站地址就是:\n> `https://oynix.github.io/blog/`\n\n当然，如果买了自己的域名，那么这些都不重要。\n\n我本也想买个域名的，一年几十块钱。但国内的环境吧，各种验证、实名、审核等等，将我冷冰冰的劝退了，以至于我觉得github这个就挺好的。\n\n\n### 部署之hexo-deployer-git插件\n因为要把代码部署到Github，所有需要先安装这个插件。hexo也支持部署到其他地方，各自都有对应的插件。\n```sh\n# 根目录下执行\n$ npm install hexo-deployer-git --save\n+ hexo-deployer-git@3.0.0\nadded 1 package from 1 contributor and audited 244 packages in 2.394s\n\n15 packages are looking for funding\n  run `npm fund` for details\n\nfound 0 vulnerabilities\n```\n\n### 部署之配置\n根目录下有个文件，`_config.yml`，这个是用来配置网站的一些属性的，使用的yml格式，里面的注释里写了很详细的介绍，大部分应该都可以看得懂。\n\n其中，`deploy`是用来配置选项的：\n```yml\n# Deployment\n## Docs: https://hexo.io/docs/one-command-deployment\ndeploy:\n  type: ''\n```\n把前两步生成的token和仓库地址，写进去就可以，github的规则是把token加在前面然后用@连接\n```yml\n# Deployment\n## Docs: https://hexo.io/docs/deployment.html\ndeploy:\n  type: git\n  repo: https://{your_github_person_access_token}@github.com/{yourname}/{repo_name}.git\n  branch: master\n\n```\n2022年4月16日更新\n最近更新的比较频繁，发现往仓库推代码很快，但是部署网站却很慢且常常失败，细想了一下意识到，二者使用的协议不一样，前者是git，后者是https，于是便把部署协议换成git了，速度有所一生，格式如下\n```yml\ndeploy:\n  type: git\n  repo: git@github.com:oynix/oynix.github.io.git\n  branch: master\n```\n前提是，需要把本级的ssh pub key添加到github账号里，如果不是第一次推代码，那定是早就添加了，github首页右上角的Settings，里面有个SSH and GPC keys，进到这个里面，key在~/.ssh/目录下，有个id_rsa.pub的文件，把里面的内容复制过去即可。\n\n\n### 部署\n`generate`之后，会在根目录生成一个名字是`.deploy_git`的目录，这个目录默认是隐藏的，里面就是生成的静态网站，将会被推送到远程。\n```sh\n# 根目录下执行\n$ hexo g\n$ hexo d\nINFO  Validating config\nINFO  Deploying: git\nINFO  Setting up Git deployment...\n.... 省略 ....\n```\n然后，就可以在远程仓库看到所有的网站文件了\n\n\n### 启用Github Pages\n打开Github，进入刚刚创建的仓库，进入Settings，点进Pages，Branch选master，save一下。\n\n然后，上面就会出现网站地址了：`Your site is published at https://oynix.github.io/`\n\n首次部署，需要等1分钟左右才能访问，不然看到的就是404。\n\n\n### 总结\n总的来说，分为3大步：搭建环境、生成静态网站以及推送到远程。按流程来，还是很顺利的。\n\n其中，有个主题还没说，hexo支持很多主题，每个主题都可以配置很多选项，如字体的颜色大小、字间距、行间距、多字体，等等。搭配上这些，就可以让页面在视觉上更加美观、舒服，等有时间再单独写一写这些。","tags":["Hexo","Github"],"categories":["自建博客"]},{"title":"数据结构之排序算法","url":"/2021/08/de342dd74fb7/","content":"[原文链接](https://www.cnblogs.com/onepixel/articles/7674659.html)\n\n在实际应用中常常用到排序算法，这篇文来总结一下常用的。上面是原文链接，文章里介绍很详细，还有动图示例，形象易懂。\n\n重复的内容不再赘述，看原文就好，这里写一写我常用到的。\n<!--more-->\n\n### 冒泡排序\n这个记的最深刻，也是最常用的，因为一遇到排序问题，首先想到的就是冒泡。原理很简单，一句话总结就是，每次将未排序部分的极值移动到尾端。如果是升序排列，那么每次寻找的就是最大值，反之则是最小值。这个过程，就像是在冒泡。\n```kotlin\nval arr = intArrayOf(3, 44, 38, 5, 47, 15, 36, 26, 27, 2, 46, 4, 19, 50, 48)\n\nfun bubble() {\n    for (i in arr.indices) {\n    \t// 每趟循环到倒数第二个即可，因为比较的时候是j和j+1\n        for (j in 0 until (arr.size - i - 1)) {\n            if (arr[j] > arr[j + 1]) {\n                val temp = arr[j]\n                arr[j] = arr[j + 1]\n                arr[j + 1] = temp\n            }\n        }\n    }\n    println(arr.localString())\n}\n\n// 输出\n[2,3,4,5,15,19,26,27,36,38,44,46,47,48,50]\n```\n\n### 选择排序\n这个和冒泡排序很像，第一次从所有元素中找到极值放到第一位，第二次从剩下的元素中找到极值放到第二位，以此类推。\n```kotlin\n// 选择排序\nfun select () {\n    var temp = 0 // 临时变量\n    var pointer = 0 // 用来标记当前在找的位置\n    while (pointer < arr.size - 1) {\n        temp = arr[pointer]\n        // 通过for循环，找到本趟的极值\n        for (i in pointer until arr.size) {\n            if (arr[i] < temp) {\n                temp = temp xor arr[i]\n                arr[i] = temp xor arr[i]\n                temp = temp xor arr[i]\n            }\n        }\n        // 本趟结束，把极值赋值给当前位置\n        arr[pointer++] = temp\n    }\n}\n```\n\n### 快速排序\n- 这是个有趣的排序算法，使用递归\n- 选择一个基准值，一般选左端，或者右端\n- 目标是把比基准值小的放到左边，大的放到右边\n- 如果选择左端则从右端指针开始判断，反之从左端指针开始\n- 这里假设选择左端为基准值，所以从右端指针开始扫描\n- 用临时变量存储基准值，此时可认为左指针指向的位置是空\n- 如果右指针比基准值小，则将右指针的值填充到左指针，此时认为右指针位置是空\n- 此时用左指针扫描\n- 遇到比基准值大的时候，将左指针的值填充到右指针，此时认为左指针位置为空\n- 此时用右指针扫描\n- 直到两个指针相遇，将临时变量的基准值填充到任一指针\n- 然后将基准值左右两部分，分别递归\n```kotlin\nfun quick(low: Int,high: Int, array: IntArray) {\n    if (low >= high) return\n    var left = low\n    var right = high\n    val temp = array[left]\n    var reverse = true\n    while (left < right) {\n        if (reverse) {\n            // 从右指针扫描\n            // 当值比基准值小时，右指针的值填充到左指针，此时认为右指针为空\n            if (array[right] < temp) {\n                array[left] = array[right]\n                reverse = !reverse // 掉头\n            } else {\n                right-- // 右指针左移动\n            }\n        } else {\n            // 从左指针扫描\n            // 当值比基准值大时，左指针填充到右指针，此时认为左指针为空\n            if (array[left] > temp) {\n                array[right] = array[left]\n                reverse = !reverse // 调用\n            } else {\n                left++ // 左指针右移动\n            }\n        }\n    }\n    // 一趟结束后，指针相遇，把基准值放到指针所在位置\n    // 此时左侧都比基准值小，右侧都比基准值大\n    array[left] = temp\n    // 分别递归左侧和右侧\n    quick(low, left - 1, array)\n    quick(left + 1, high, array)\n}\n```\n\n### 插入排序\n- 将序列分为两部分，左侧是已经排好顺序的，右侧是未排的\n- 每次从未排序列中取一个数字，将其插入到已排好部分\n- 循环至排序完成\n```kotlin\nfun insert(array: IntArray) {\n    var border = 0 // 左侧已排序部分的边界\n    while (border < array.size - 1) {\n        // 每次取右侧未排序部分的第一个数字，将其插入到左侧的目标位置\n        for (i in border downTo 0) {\n            if (array[i + 1] < array[i]) {\n                // 异或操作交换值，不用额外的临时变量\n                array[i] = array[i] xor array[i + 1]\n                array[i + 1] = array[i] xor array[i + 1]\n                array[i] = array[i] xor array[i + 1]\n            } else {\n                break\n            }\n        }\n        border++\n    }\n}\n```\n\n\n[https://github.com/oynix/SortAlgorithmSample](https://github.com/oynix/SortAlgorithmSample)","tags":["数据结构","排序算法"],"categories":["算法"]},{"title":"Android基础之Handler","url":"/2021/08/aeb0be134986/","content":"\n说到Android的基础，就一定绕不开Handler，以及相关的Looper、Message、MessageQueue等。这篇文就说说它们之间的联系，来加深印象。\n\n太基础的就不说了，那样要说的东西就太多太多了，多少会显得冗杂。\n\n<!--more-->\n\n### 前言\n众所周知，一个application启动后，会启动一个线程作为主线程，也就是ActivityThread，所有更新UI的操作都要放到这个线程里进行。除去这个主线程，其他线程均为子线程，在子线程里更新UI会报错：CalledFromWrongThreadException。这是因为在ViewRootImpl中做了检查，只要当前线程不是主线程，就会抛出异常。\n\n那么，Android为什么这么做呢？\n\n可以假想一下，如果不这么设计，允许所有线程更新UI，那么在并发量多的时候：一个TextView，同一时刻，有10个线程想要更新其显示的内容，这就会发生混乱。\n\n如果想要解决这个问题，首先想到的应该就是加个同步锁synchronized，你们都可以更新UI，但是要排队，一个一个来。混乱的问题解决，但是性能很差，同步锁这个东西，不到万不得已的时候我都不会用。\n\n最后，就有了现在的这种模式，单独出一个线程，也就是主线程，用于更新UI，其他线程若想更新UI，那么就向主线程发送一个消息，发送之后继续自己的任务，等到合适的时机，主线程就会根据发来的消息，做出相应的处理。\n\n这就是Android的消息驱动模型。\n\n### 团队组成\n以前我只是知道个大概，为了写清楚这篇文，就去看了对应的源文件。搭配着AndroidStudio，源文件的可读性还是很不错的，如果有时间都可以去看看。\n\n- Handler\n用来发消息，即Message；同时，Handler也要提供Message的处理方式，也就是需要做哪些操作。\n- Looper\n如同名字一样，是一个循环器。它负责循环读取消息队列，MessageQueue中的消息，如果其中有新的未处理的消息，则就将其取出，并处理。\n- Message\n消息中包含了一个操作需要的一些信息，后面细说。\n- MessageQueue\n消息队列，所有的消息都将会发送到这里\n\n这么说有些抽象，理解起来可能有些困难，打个比方：你去银行存款，到了银行需要先排号，然后等着喊号，排号期间，你可以做些别的事情，比如聊天、打游戏或者看视频，等到轮到你的时候，你就会去柜台，拿出自己装在兜里的钱，然后存到自己的账户上。\n\n这个过程中，你就是一个Handler，排号就相当于发送了一个Message，所有排队中的号就相当于一个MessageQueue，而银行的叫号系统就如同一个Looper。\n\n可以同时有多个Handler，一个Handler也可以发送多个Message。\n\n\n### Looper\n- 线程里本没有Looper，需要手动创建，调用静态方法Looper.prepare()。\n- 一个线程只允许创建一个Looper，Looper里面使用了一个类型为`ThreadLocal<Looper>`静态变量`sThreadLocal`，保存了所有线程的Looper\n- 一个线程创建多个Looper时会报错：RuntimeException(\"Only one Looper may be created per thread\")\n- 主线程的Looper不需要手动创建，因为ActivityThread在main方法，也就是程序的入口，自动创建\n- Looper里面持有了一个MessageQueue，在构造方法里面将其初始化\n- 调用Looper中的loop方法之后，Looper便会循环从MessageQueue中取消息，没有消息时便会等待\n```java\n// 只列出了源码中的部分重要代码\npublic class Looper {\n    static ThreadLocal<Looper> sThreadLocal = new ThreadLocal<Looper>()\n    static Looper sMainLooper;\n    final MessageQueue mQueue;\n\n    // 构造方法中出实例化MessageQueue\n    private Looper(boolean quitAllowed) {\n        mQueue = new MessageQueue(quitAllowed);\n        mThread = Thread.currentThread();\n    }\n\n    // 通过prepare创建Looper，并添加到sThreadLocal中\n    private static void prepare(boolean quitAllowed) {\n        if (sThreadLocal.get() != null) {\n            throw new RuntimeException(\"Only one Looper may be created per thread\");\n        }\n        sThreadLocal.set(new Looper(quitAllowed));\n    }\n\n    public static Looper myLooper() {\n        return sThreadLocal.get(); // 获取当前线程的Looper\n    }\n\n    public static void loop() {\n        final Looper me = myLooper();\n        final MessageQueue queue = me.mQueue;\n        for (;;) {\n            Message msg = queue.next(); // 取出消息\n            msg.target.dispatchMessage(msg); // 掉用Handler的方法来处理消息\n        }\n    }\n}\n\n```\n\n\n### Handler\n- 在创建Handler时，会从Looper的静态变量`sThreadLocal`中获取当前线程的Looper，获取不到则报错`RuntimeException(\"Can't create handler inside thread that has not called Looper.prepare()\");`\n- 除会自动创建Looper的主线程，其他线程需要手动调用Loopr.prepare()进行创建，调用Looper.loop()开始循环取消息\n- 现在推荐的创建Handler的方式，是通过Looper.mainLooper()获取主线程的Looper，然后将其作为构造参数传到Handler的构造方法里\n- 所以，可以同时存在多个Handler发消息更新UI，因为使用的都是同一个Looper，即mainLooper\n- 可以通过Handler发送Message，也可以发送Runnable，在加入到MessageQueue前，Runnable也会被封装成Message，最后Looper统一处理Message\n```java\n// 只列出了源码中的部分重要代码\npublic class Handler {\n    Looper mLooper;\n    MessageQueue mQueue;\n    Handler.Callback mCallback;\n\n    public Handler(Callback callback, boolean async) {\n        mLooper = Looper.myLooper() // 获取当前线程的Looper\n        if (mLooper == null) {\n            throw new RuntimeException(\"Can't create handler inside thread that has not called Looper.prepare()\");\n        }\n        mQueue = mLoopr.mQueue;\n        mCallback = callback;\n    }\n\n    public Handler(Looper looper, Callback callback, boolean async) {\n        mLooper = looper;\n        mQueue = looper.mQueue;\n        mCallback = callback;\n    }\n\n    // 在Looper中调用，用来分发消息\n    public void dispatchMessage(Message message) {\n        if (msg.callback != null) {\n            handleCallback(msg); // 是Runnable的时候走到这里\n        } else { // 是Message的时候走的这里\n            if (mCallback != null) { \n                // 这个mCallback就是构造方法里传入的，\n                // 如果不重写handleMessage方法，也可以传入一个Callback来处理Message\n                if (mCallback.handleMessage(msg)) {\n                    return;\n                }\n            }\n            handleMessage(msg); // 如果没传入Callback，则调用handleMessage\n        }\n    }\n\n    // 用来处理Runnable\n    private static void handleCallback(Message message) {\n        message.callback.run();\n    }\n\n    // 用来处理Message\n    public void handleMessage(@NonNull Message msg) {\n    }\n}\n```\n\n\n### Message\n- Message是个链表结构，其中有个Message类型的成员变量，叫`next`，靠这个变量来建立起链表结构\n- Message中持有Handler的引用，叫做`target`，在Handler发送消息时，会把Handler赋值给Message的`target`变量\n- 在Looper从MessageQueue中取出Message时，便会调用其`target`的dispatchMessage方法来让Handler处理Message\n- Message一般不手动创建，而是通过`Message.obtain()`方法，如果Message池子里有可用的实例则会重用，没有则会返回一个new Message\n- 当使用Handler.post Runnable时，会将Runnable封装成Message，将Runnable赋值给其中的callback变量\n```java\n// 只列出了源码中的部分重要代码\npublic class Message {\n    Message next; // 链表，指向下一个Message\n    Handler target; // 发送和处理Message的Handler\n    Runnable callback; // 发送的Runnable\n\n    // obtain有很多重载方法\n    public static Message obtain() { /*省略*/ }\n}\n```\n\n### MessageQueue\n- 这就是个消息队列，持有队列头消息的引用\n- 对队列的操作都封装在这个类中，比如增加消息到链表\n- 因为可通过Handler消息发送延迟消息，所以队列中的消息是根据执行时间排队的\n\n\n### ThreadLocal\n总觉得说一说这个ThreadLocal才算完整。ThreadLocal是用来存储数据的，带有一个范型的参数，也就是需要存储的数据类型，它能够将数据与线程相互关联，保证在同一个线程取到的数据是同一个。通过get方法获取值，通过set方法设置值。\n实现原理就是，每个线程里维护了一个名字为`threadLocals`，类型是`ThreadLocal.ThreadLocalMap`的变量，这种类型就是一个定制的Map\n```java\npublic class ThreadLocal<T> {\n\n    public void set(T value) {\n        Thread t = Thread.currentThread();\n        ThreadLocalMap map = getMap(t); // 先获取到Thread里的map\n        if (map != null) // 然后将值set进去\n            map.set(this, value);\n        else\n            createMap(t, value);\n    }\n\n    public T get() {\n        Thread t = Thread.currentThread();\n        ThreadLocalMap map = getMap(t); // 先获取到Thread里的map\n        if (map != null) { // 然后从里面get值\n            ThreadLocalMap.Entry e = map.getEntry(this);\n            if (e != null) {\n                @SuppressWarnings(\"unchecked\")\n                T result = (T)e.value;\n                return result;\n            }\n        }\n        return setInitialValue();\n    }\n}\n\n// 使用\nThreadLocal tl = new ThreadLocal<String>();\ntl.set(\"something\");\nString value = tl.get()\n\n```\n\n\n### Handler使用\n当使用Handler发送Runnable时，直接使用Handler.post()方法即可，这个方法有很多重载方法，例如：可发送延迟的消息，也可以发送在某个具体时间执行的消息，等等。\n当使用Handler发送Message时，一般通过sendMessage方法发消息，然后重写它的handleMessage方法，来处理对应的消息，同样这个发送方法也有几个重载方法，查看对应的API文档即可：\n```kotlin\nclass HandlerTest : AppCompatActivity() {\n\n    // 创建一个Handler\n    val handler = object : Handler(Looper.getMainLooper()) {\n        override fun handleMessage(msg: Message) {\n            when (msg.what) {\n            1 -> { textView.text = \"message 1\" }\n            2 -> { textView.text = \"message 2\" }\n            }\n        }\n    }\n    \n    override fun onCreate(savedInstanceState: Bundle?) {\n        super.onCreate(savedInstanceState)\n\n        object : Thread() {\n            override fun run() {\n                // 在子线程调用，如从网络获取到数据后\n                val message = Message.obtain()\n                message.what = 1\n                handler.sendMessage(message)\n            }\n        }.start()\n    }\n}\n```\n一般用法就是这样，但是这样编译器会提示一个可能会导致内存溢出的警告，因为在Handler的构造方法里做了检查：\n```java\npublic Handler(@Nullable Callback callback, boolean async) {\n    if (FIND_POTENTIAL_LEAKS) {\n        final Class<? extends Handler> klass = getClass();\n        // 在这里，如果当前类是匿名类，或者是成员类，或者是局部类，并且不是静态类，那么就会发出警告\n        if ((klass.isAnonymousClass() || klass.isMemberClass() || klass.isLocalClass()) &&\n                (klass.getModifiers() & Modifier.STATIC) == 0) {\n            Log.w(TAG, \"The following Handler class should be static or leaks might occur: \" +\n                klass.getCanonicalName());\n        }\n    }\n    // 省略了一些代码\n}\n```\n\n### 什么是内存泄漏\n简单说，就是当一个实例该被GC回收的时候，却无法被回收，这块无法被回收的内存，就是泄漏的内存。什么意思呢，举个例子，当从一个Activity返回的时候，Activity的实例从任务栈弹出，这个时候这个实例就该被GC回收掉，但是，如果这时还被其他实例引用的话，GC是不会对它回收的。\n\n\n### 为何造成内存泄漏\n我们来捋一捋，作为Activity的匿名内部类，Handler会持有外部类的引用，这是Java的机制；而Handler会被Message中的target变量引用，Message会被MessageQueue引用，MessageQueue会被Looper引用，而Looper的生命周期是和当前Thread的生命一样长，如果是主线程的话，那么这个Looper就会贯穿应用全程，因为Activity的实例间接被主线程引用，对于有引用的内存，虚拟机宁愿报错OOM，也不会让GC回收。\n\n\n### 如何解决泄漏\n原因既然清楚了，那么就好解决了，只要避免Handler引用外部类，这里就是Activity，那么就不会泄漏了。一般的方案，就是使用静态内部类，静态内部类对外部类是没有引用的，这也是Java的机制；或者将Handler独立出去，单独放到一个类文件中，使其不再是内部类，这样便不会在引用外部类。\n\n\n### 总结\nAndroid通过主线程的消息队列来更新UI，而Handler是这个消息驱动模型中的一员，负责发消息和处理消息，同时这个模型中还有其他几个成员：Message，消息；MessageQueue，消息队列；Looper，从队列去消息的循环器。\n","tags":["Android"],"categories":["Android"]},{"title":"Android基础之singleTask","url":"/2021/08/83315178a002/","content":"\n时间做的久了，基础的知识忘的越来越多，正所谓：基础不牢，地动山摇。最近有需要，所以在慢慢重来，今天说一说Activity的几种启动模式。\n\n<!--more-->\n\n### 前言\n\n启动模式有4种：`standard`、`singleTop`、`singleTask`和`singleInstance`，这次主要说一说`singleTask`，相比于其他，这个算是比较复杂一些的。\n\n利用`adb`提供的命令`adb shell dumpsys activity activities`可以查看设备当前的activity栈信息。此外，`adb shell dumpsys`可以查看各种信息，直接输入就会列出它所支持的所有服务。\n\n下面贴了一段我用的测试设备的activity信息，乍一看上去内容有些冗杂，其实是因为里面包含了很详细的信息和关系，从头按行读，读懂的话不是问题。从这些数据中，可以对`Process`、`Task`之间的关系有个大致了解。\n\n为了不影响阅读体验，我把它折叠起来了。\n\n<details style='background-color:#f9f2f4'>\n<summary><font color='#c7254e' size='3px'> view detail</font></summary>\n```shell\n$ adb shell dumpsys activity activities\nACTIVITY MANAGER ACTIVITIES (dumpsys activity activities)\nDisplay #0 (activities from top to bottom):\n\n  Stack #7: type=standard mode=fullscreen\n  isSleeping=false\n  mBounds=Rect(0, 0 - 0, 0)\n    Task id #25\n    mBounds=Rect(0, 0 - 0, 0)\n    mMinWidth=-1\n    mMinHeight=-1\n    mLastNonFullscreenBounds=null\n    * TaskRecord{3e1780c #25 A=com.oynix.launch.mode.sample U=0 StackId=7 sz=2}\n      userId=0 effectiveUid=u0a208 mCallingUid=2000 mUserSetupComplete=true mCallingPackage=null\n      affinity=com.oynix.launch.mode.sample\n      intent={act=android.intent.action.MAIN cat=[android.intent.category.LAUNCHER] flg=0x10000000 cmp=com.oynix.launch.mode.sample/.MainActivity}\n      realActivity=com.oynix.launch.mode.sample/.MainActivity\n      autoRemoveRecents=false isPersistable=true numFullscreen=2 activityType=1\n      rootWasReset=false mNeverRelinquishIdentity=true mReuseTask=false mLockTaskAuth=LOCK_TASK_AUTH_PINNABLE\n      Activities=[ActivityRecord{a1dcebd u0 com.oynix.launch.mode.sample/.MainActivity t25}, ActivityRecord{907f0e u0 com.oynix.launch.mode.sample/.AActivity t25}]\n      askedCompatMode=false inRecents=true isAvailable=true\n      mRootProcess=ProcessRecord{26080b8d0 21734:com.oynix.launch.mode.sample/u0a208}\n      stackId=7\n      hasBeenVisible=true mResizeMode=RESIZE_MODE_RESIZEABLE_VIA_SDK_VERSION mSupportsPictureInPicture=false isResizeable=true lastActiveTime=6697777 (inactive for 3s)\n      isLaunchedPairApp=false\n      mOverrideConfig={0.0 ?mcc?mnc ?localeList ?layoutDir ?swdp ?wdp ?hdp ?density ?lsize ?long ?ldr ?wideColorGamut ?orien ?uimode ?night ?touch ?keyb/?/? ?nav/? winConfig={ mBounds=Rect(0, 0 - 0, 0) mAppBounds=null mWindowingMode=undefined mActivityType=undefined} mkbd/? desktop/?showBtnShape = -1  themeSeq=0 0 0  ?dc}\n      dexBoundsPolicy:\n       mLastNonFullBoundsDisplayId=-1\n      * Hist #1: ActivityRecord{907f0e u0 com.oynix.launch.mode.sample/.AActivity t25}\n          packageName=com.oynix.launch.mode.sample processName=com.oynix.launch.mode.sample\n          launchedFromUid=10208 launchedFromPackage=com.oynix.launch.mode.sample userId=0\n          app=ProcessRecord{26080b8d0 21734:com.oynix.launch.mode.sample/u0a208}\n          Intent { cmp=com.oynix.launch.mode.sample/.AActivity }\n          frontOfTask=false task=TaskRecord{3e1780c #25 A=com.oynix.launch.mode.sample U=0 StackId=7 sz=2}\n          taskAffinity=com.oynix.launch.mode.sample\n          realActivity=com.oynix.launch.mode.sample/.AActivity\n          baseDir=/data/app/com.oynix.launch.mode.sample-3DMFUnGXrp7XpBKiFV3-Tg==/base.apk\n          dataDir=/data/user/0/com.oynix.launch.mode.sample\n          stateNotNeeded=false componentSpecified=true mActivityType=standard\n          compat={480dpi} labelRes=0x7f0e001b icon=0x7f0c0000 theme=0x7f0f01a1\n          mLastReportedConfigurations:\n           mGlobalConfig={0.9 ?mcc?mnc [zh_CN_#Hans] ldltr sw360dp w360dp h668dp 480dpi nrml long port finger -keyb/v/h -nav/h winConfig={ mBounds=Rect(0, 0 - 0, 0) mAppBounds=Rect(0, 0 - 1080, 2076) mWindowingMode=fullscreen mActivityType=undefined} s.9 mkbd/h desktop/dshowBtnShape = 0  themeSeq=0 0 0  ?dc}\n           mOverrideConfig={0.9 ?mcc?mnc [zh_CN_#Hans] ldltr sw360dp w360dp h668dp 480dpi nrml long port finger -keyb/v/h -nav/h winConfig={ mBounds=Rect(0, 0 - 1080, 2076) mAppBounds=Rect(0, 0 - 1080, 2076) mWindowingMode=fullscreen mActivityType=standard} s.9 mkbd/h desktop/dshowBtnShape = 0  themeSeq=0 0 0  ?dc}\n          CurrentConfiguration={0.9 ?mcc?mnc [zh_CN_#Hans] ldltr sw360dp w360dp h668dp 480dpi nrml long port finger -keyb/v/h -nav/h winConfig={ mBounds=Rect(0, 0 - 1080, 2076) mAppBounds=Rect(0, 0 - 1080, 2076) mWindowingMode=fullscreen mActivityType=standard} s.9 mkbd/h desktop/dshowBtnShape = 0  themeSeq=0 0 0  ?dc}\n          taskDescription: label=\"null\" icon=null iconResource=0 iconFilename=null primaryColor=ff6200ee\n           backgroundColor=ffffffff\n           statusBarColor=ff3700b3\n           navigationBarColor=fff2f2f2\n          launchFailed=false launchCount=1 lastLaunchTime=-5s311ms\n          haveState=false icicle=null\n          state=RESUMED stopped=false delayedResume=false finishing=false\n          keysPaused=false inHistory=true visible=true sleeping=false idle=true mStartingWindowState=STARTING_WINDOW_NOT_SHOWN\n          fullscreen=true noDisplay=false immersive=false launchMode=0\n          frozenBeforeDestroy=false forceNewConfig=false\n          mActivityType=standard\n          vrActivityType=0\n          waitingVisible=false nowVisible=true lastVisibleTime=-4s856ms\n          resizeMode=RESIZE_MODE_RESIZEABLE_VIA_SDK_VERSION\n          mLastReportedMultiWindowMode=false mLastReportedPictureInPictureMode=false\n          mUseDeviceDefaultTheme=false\n      * Hist #0: ActivityRecord{a1dcebd u0 com.oynix.launch.mode.sample/.MainActivity t25}\n          packageName=com.oynix.launch.mode.sample processName=com.oynix.launch.mode.sample\n          launchedFromUid=2000 launchedFromPackage=null userId=0\n          app=ProcessRecord{26080b8d0 21734:com.oynix.launch.mode.sample/u0a208}\n          Intent { act=android.intent.action.MAIN cat=[android.intent.category.LAUNCHER] flg=0x10000000 cmp=com.oynix.launch.mode.sample/.MainActivity }\n          frontOfTask=true task=TaskRecord{3e1780c #25 A=com.oynix.launch.mode.sample U=0 StackId=7 sz=2}\n          taskAffinity=com.oynix.launch.mode.sample\n          realActivity=com.oynix.launch.mode.sample/.MainActivity\n          baseDir=/data/app/com.oynix.launch.mode.sample-3DMFUnGXrp7XpBKiFV3-Tg==/base.apk\n          dataDir=/data/user/0/com.oynix.launch.mode.sample\n          stateNotNeeded=false componentSpecified=true mActivityType=standard\n          compat={480dpi} labelRes=0x7f0e001b icon=0x7f0c0000 theme=0x7f0f01a1\n          mLastReportedConfigurations:\n           mGlobalConfig={0.9 ?mcc?mnc [zh_CN_#Hans] ldltr sw360dp w360dp h668dp 480dpi nrml long port finger -keyb/v/h -nav/h winConfig={ mBounds=Rect(0, 0 - 0, 0) mAppBounds=Rect(0, 0 - 1080, 2076) mWindowingMode=fullscreen mActivityType=undefined} s.9 mkbd/h desktop/dshowBtnShape = 0  themeSeq=0 0 0  ?dc}\n           mOverrideConfig={0.9 ?mcc?mnc [zh_CN_#Hans] ldltr sw360dp w360dp h668dp 480dpi nrml long port finger -keyb/v/h -nav/h winConfig={ mBounds=Rect(0, 0 - 1080, 2076) mAppBounds=Rect(0, 0 - 1080, 2076) mWindowingMode=fullscreen mActivityType=standard} s.9 mkbd/h desktop/dshowBtnShape = 0  themeSeq=0 0 0  ?dc}\n          CurrentConfiguration={0.9 ?mcc?mnc [zh_CN_#Hans] ldltr sw360dp w360dp h668dp 480dpi nrml long port finger -keyb/v/h -nav/h winConfig={ mBounds=Rect(0, 0 - 1080, 2076) mAppBounds=Rect(0, 0 - 1080, 2076) mWindowingMode=fullscreen mActivityType=standard} s.9 mkbd/h desktop/dshowBtnShape = 0  themeSeq=0 0 0  ?dc}\n          taskDescription: label=\"null\" icon=null iconResource=0 iconFilename=null primaryColor=ff6200ee\n           backgroundColor=ffffffff\n           statusBarColor=ff3700b3\n           navigationBarColor=fff2f2f2\n          launchFailed=false launchCount=0 lastLaunchTime=-24s316ms\n          haveState=true icicle=Bundle[mParcelledData.dataSize=2448]\n          state=STOPPED stopped=true delayedResume=false finishing=false\n          keysPaused=false inHistory=true visible=false sleeping=false idle=true mStartingWindowState=STARTING_WINDOW_REMOVED\n          fullscreen=true noDisplay=false immersive=false launchMode=0\n          frozenBeforeDestroy=false forceNewConfig=false\n          mActivityType=standard\n          vrActivityType=0\n          waitingVisible=false nowVisible=false lastVisibleTime=-6s410ms\n          resizeMode=RESIZE_MODE_RESIZEABLE_VIA_SDK_VERSION\n          mLastReportedMultiWindowMode=false mLastReportedPictureInPictureMode=false\n          mUseDeviceDefaultTheme=false\n\n    Running activities (most recent first):\n      TaskRecord{3e1780c #25 A=com.oynix.launch.mode.sample U=0 StackId=7 sz=2}\n        Run #1: ActivityRecord{907f0e u0 com.oynix.launch.mode.sample/.AActivity t25}\n        Run #0: ActivityRecord{a1dcebd u0 com.oynix.launch.mode.sample/.MainActivity t25}\n\n    mResumedActivity: ActivityRecord{907f0e u0 com.oynix.launch.mode.sample/.AActivity t25}\n    mLastPausedActivity: ActivityRecord{a1dcebd u0 com.oynix.launch.mode.sample/.MainActivity t25}\n\n  Stack #0: type=home mode=fullscreen\n  isSleeping=false\n  mBounds=Rect(0, 0 - 0, 0)\n\n    Task id #18\n    mBounds=Rect(0, 0 - 0, 0)\n    mMinWidth=-1\n    mMinHeight=-1\n    mLastNonFullscreenBounds=null\n    * TaskRecord{13181bb #18 I=com.sec.android.app.launcher/com.android.launcher3.infra.activity.Launcher U=0 StackId=0 sz=1}\n      userId=0 effectiveUid=u0a96 mCallingUid=1000 mUserSetupComplete=true mCallingPackage=android\n      intent={act=android.intent.action.MAIN cat=[android.intent.category.HOME] flg=0x10800100 cmp=com.sec.android.app.launcher/com.android.launcher3.infra.activity.Launcher}\n      origActivity=com.sec.android.app.launcher/.activities.LauncherActivity\n      realActivity=com.sec.android.app.launcher/com.android.launcher3.infra.activity.Launcher\n      autoRemoveRecents=false isPersistable=false numFullscreen=1 activityType=2\n      rootWasReset=false mNeverRelinquishIdentity=true mReuseTask=false mLockTaskAuth=LOCK_TASK_AUTH_PINNABLE\n      Activities=[ActivityRecord{ad01979 u0 com.sec.android.app.launcher/.activities.LauncherActivity t18}]\n      askedCompatMode=false inRecents=true isAvailable=true\n      stackId=0\n      hasBeenVisible=true mResizeMode=RESIZE_MODE_RESIZEABLE mSupportsPictureInPicture=false isResizeable=true lastActiveTime=6676345 (inactive for 24s)\n      isLaunchedPairApp=false\n      mOverrideConfig={0.0 ?mcc?mnc ?localeList ?layoutDir ?swdp ?wdp ?hdp ?density ?lsize ?long ?ldr ?wideColorGamut ?orien ?uimode ?night ?touch ?keyb/?/? ?nav/? winConfig={ mBounds=Rect(0, 0 - 0, 0) mAppBounds=null mWindowingMode=undefined mActivityType=undefined} mkbd/? desktop/?showBtnShape = -1  themeSeq=0 0 0  ?dc}\n      dexBoundsPolicy:\n       mLastNonFullBoundsDisplayId=-1\n      * Hist #0: ActivityRecord{ad01979 u0 com.sec.android.app.launcher/.activities.LauncherActivity t18}\n          packageName=com.sec.android.app.launcher processName=com.sec.android.app.launcher\n          launchedFromUid=0 launchedFromPackage=null userId=0\n          app=ProcessRecord{95a823d0 5418:com.sec.android.app.launcher/u0a96}\n          Intent { act=android.intent.action.MAIN cat=[android.intent.category.HOME] flg=0x10800100 cmp=com.sec.android.app.launcher/.activities.LauncherActivity }\n          frontOfTask=true task=TaskRecord{13181bb #18 I=com.sec.android.app.launcher/com.android.launcher3.infra.activity.Launcher U=0 StackId=0 sz=1}\n          taskAffinity=null\n          realActivity=com.sec.android.app.launcher/com.android.launcher3.infra.activity.Launcher\n          baseDir=/system/priv-app/TouchWizHome_2017/TouchWizHome_2017.apk\n          dataDir=/data/user/0/com.sec.android.app.launcher\n          stateNotNeeded=true componentSpecified=false mActivityType=home\n          compat={480dpi} labelRes=0x7f090042 icon=0x7f020127 theme=0x7f0e019c\n          mLastReportedConfigurations:\n           mGlobalConfig={0.9 ?mcc?mnc [zh_CN_#Hans] ldltr sw360dp w360dp h668dp 480dpi nrml long port finger -keyb/v/h -nav/h winConfig={ mBounds=Rect(0, 0 - 0, 0) mAppBounds=Rect(0, 0 - 1080, 2076) mWindowingMode=fullscreen mActivityType=undefined} s.9 mkbd/h desktop/dshowBtnShape = 0  themeSeq=0 0 0  ?dc}\n           mOverrideConfig={0.9 ?mcc?mnc [zh_CN_#Hans] ldltr sw360dp w360dp h668dp 480dpi nrml long port finger -keyb/v/h -nav/h winConfig={ mBounds=Rect(0, 0 - 1080, 2076) mAppBounds=Rect(0, 0 - 1080, 2076) mWindowingMode=fullscreen mActivityType=home} s.9 mkbd/h desktop/dshowBtnShape = 0  themeSeq=0 0 0  ?dc}\n          CurrentConfiguration={0.9 ?mcc?mnc [zh_CN_#Hans] ldltr sw360dp w360dp h668dp 480dpi nrml long port finger -keyb/v/h -nav/h winConfig={ mBounds=Rect(0, 0 - 1080, 2076) mAppBounds=Rect(0, 0 - 1080, 2076) mWindowingMode=fullscreen mActivityType=home} s.9 mkbd/h desktop/dshowBtnShape = 0  themeSeq=0 0 0  ?dc}\n          OverrideConfiguration={0.0 ?mcc?mnc ?localeList ?layoutDir ?swdp ?wdp ?hdp ?density ?lsize ?long ?ldr ?wideColorGamut ?orien ?uimode ?night ?touch ?keyb/?/? ?nav/? winConfig={ mBounds=Rect(0, 0 - 0, 0) mAppBounds=null mWindowingMode=undefined mActivityType=home} mkbd/? desktop/?showBtnShape = -1  themeSeq=0 0 0  ?dc}\n          taskDescription: label=\"null\" icon=null iconResource=0 iconFilename=null primaryColor=ff0074d4\n           backgroundColor=fffafafa\n           statusBarColor=0\n           navigationBarColor=0\n          launchFailed=false launchCount=0 lastLaunchTime=-1h51m21s986ms\n          haveState=true icicle=Bundle[mParcelledData.dataSize=14056]\n          state=STOPPED stopped=true delayedResume=false finishing=false\n          keysPaused=false inHistory=true visible=false sleeping=false idle=true mStartingWindowState=STARTING_WINDOW_NOT_SHOWN\n          fullscreen=true noDisplay=false immersive=false launchMode=2\n          frozenBeforeDestroy=false forceNewConfig=false\n          mActivityType=home\n          vrActivityType=0\n          waitingVisible=false nowVisible=false lastVisibleTime=-1m33s752ms\n          connections=[ConnectionRecord{108b50e u0 CR com.samsung.android.app.spage/.service.overlay.PageOverlayService:@e38ef09}]\n          resizeMode=RESIZE_MODE_RESIZEABLE\n          mLastReportedMultiWindowMode=false mLastReportedPictureInPictureMode=false\n          mUseDeviceDefaultTheme=true\n\n    Running activities (most recent first):\n      TaskRecord{13181bb #18 I=com.sec.android.app.launcher/com.android.launcher3.infra.activity.Launcher U=0 StackId=0 sz=1}\n        Run #0: ActivityRecord{ad01979 u0 com.sec.android.app.launcher/.activities.LauncherActivity t18}\n\n    mLastPausedActivity: ActivityRecord{ad01979 u0 com.sec.android.app.launcher/.activities.LauncherActivity t18}\n\n  ResumedActivity: ActivityRecord{907f0e u0 com.oynix.launch.mode.sample/.AActivity t25}\n  mFocusedStack=ActivityStack{9f0e91 stackId=7 type=standard mode=fullscreen visible=true translucent=false, 1 tasks} mLastFocusedStack=ActivityStack{9f0e91 stackId=7 type=standard mode=fullscreen visible=true translucent=false, 1 tasks}\n  mCurTaskIdForUser={0=25}\n  mUserStackInFront={}\n  displayId=0 stacks=2\n   mHomeStack=ActivityStack{364f85f stackId=0 type=home mode=fullscreen visible=false translucent=true, 1 tasks}\n   mDefaultMinSizeOfResizeableTask=660\n  isHomeRecentsComponent=true  mDefaultMinSizeOfResizeableTask=660  KeyguardController:\n    mKeyguardShowing=false\n    mAodShowing=false\n    mKeyguardGoingAway=true\n    mOccluded=false\n    mDismissingKeyguardActivity=null\n    mDismissalRequested=false\n    mVisibilityTransactionDepth=0\n    mDexOccluded=false\n    mDexDisplaySleepToken=null\n  LockTaskController\n    mLockTaskModeState=NONE\n    mLockTaskModeTasks=\n    mLockTaskPackages (userId:packages)=\n      u0:[]\n```\n</details>\n\n### 几个概念\n在此之前，做一些准备工作，有几个名词需要先解释。\n- Process 进程\n如果没有特殊的配置，启动一个`application`就会启动一个进程，进程名称默认为包名。进程之间相互独立，内存互不共享。一个进程内可以有多个线程，这些线程的内存是共享的，所以一个变量可以同时被多个线程访问，从而导致的线程不安全问题。\n在`AndroidManifest.xml`文件中声明四大组件时，如果设置了`android:process`属性，这个就不会运行在`applicaton`的所在的进程，而是另起一个新的进程。进程的名字就是`android:process`属性的值。\n\n- Task 任务\n可以简单的把Task理解成一个存放Activity的栈，一个Activity必须依附于一个Task，启动Activity就是将Activity实例压入栈顶，销毁Activity就是将Activity实例出栈的过程。Activity虽然依附于Task，但并不是随便一个Task就可以，每个Task都有一个`name`，Activity就是根据这个名字找到自己的归宿。意思就是说，会同时存在多个Task，从上面`dumpsys`的结果也可以看出这一点，其中的`TaskRecord`便是一个Task实例。Task的名字是可以重复的，这与其中包含的Activity的模式有关，下面再说。\n\n- android:taskAffinity\n这是`AndroidManifest.xml`文件中，`activity`标签的一个属性，字符串类型。`affinity`，直译过来就是密切关系、类同的意思，在这里就是指定Task的名字。`application`也有这个属性，当`activity`不设置这个属性时，默认会使用`application`这个属性的值；如果`application`也没有设置这个属性的值，那就默认使用包名。所以，不设置这个属性时，activity启动后都会依附在一个名字为包名的Task中，从`dumpsys`结果也可以看出来。\n\n\n### 模式：standard\n这个是默认的模式，不主动设置的Activity，都是这个模式。这个模式很好理解，只要设置成这个模式，它从生到死都会存在包名为名称的Task中，即便是设置了`taskAffinify`也不会生效。每次启动，都会创建新的实例压入Task的栈顶。\n\n### 模式：singleTop\n从名字来看，就是单独的顶部。意思就是，在Task栈顶只会有一个实例。启动时，如果发现栈顶就是这个activity的实例，那么就会通过重用这个实例，这个时候会掉用Activity中的`onNewIntent`方法。这个模式也对`taskAffinify`属性无效，只会存在于包名的Task中。常用于内容详情，如新闻详情，单独占一个页面，浏览完详情，底部会显示几个其他新闻的链接，点击之后，会再次启动新闻详情，自己跳自己，这样不管跳转了多少次，按一次返回，就可以回到新闻列表页面。\n\n### 模式：singleTask\n如果上面解释的几个概念都能明白，那这个属性就很好说了。顾名思义，在Task中只会存在一个实例。这个模式下，`taskAnffinity`属性会生效，如果不设置，那就是包名。启动Activity时，首先会按照`taskAnffinity`查找对应的Task，如果没找到，那么就新建一个，然后将Activity实例压入栈；如果找到了该名字的Task，那么会在该Task中查找Activity的实例，若找到，如果不在Task栈顶，那么就将上面的Activity实例全部出栈，使其位于栈顶；如果栈中无此Activity的实例，则新建实例并压入栈。\n\n### 模式：singleInstance\n这个也很好理解，凡是以这个模式启动的Activity，都会自己独占一个Task。如果不存在则创建新Task然后实例压入栈，如果存在则`onNewIntent`复用其中的Activity实例。如果不设置`taskAffinity`，那么Task的名字就是包名，这时，就会有两个名字都是包名的Task，所以Task的名字是可能会相同的。这里强调一下独占这个词，如果一个以`singleTask`启动的Activity，找到了它目标名字的Task，但是这个Task里包含`singleInstance`启动的Activity实例，那么它会将实例压入该栈吗？不会的，因为是独占，所以不允许其他实例。\n\n### 总结\n其中3个都很好理解，`standard`是默认模式，只要启动就会创建新实例并压入默认Task；`singleTop`是栈顶存在就复用，不存在就创建；`singleInstance`是独占一个Task；`singleTask`是先找到目标名字、且没有被独占的Task，找不到则新建，Task中若存在实例则通过弹出上面的实例使其处于栈顶并`onNewIntent`复用，已在栈顶则直接复用，若Task栈中不存在实例，则创建并压入栈。\n\n如果能自己把每个模式验证，那么理解的就会深刻些。我便是跑了一个Application，写了几个简单的Activity，通过不断调整`AndroidManifest.xml`中Activity的`launchMode`和`taskAnffinity`，然后配合`adb shell dumpsys activity activities`命令，从头到尾走了一遍。\n\n附上Git地址：[https://github.com/oynix/launch-mode-sample](https://github.com/oynix/launch-mode-sample)\n","tags":["Android"],"categories":["Android"]},{"title":"Kotlin之let、apply、also、with","url":"/2021/08/517bb194f5b9/","content":"\n自从前两年的I/O大会上，Google官方宣布Kotlin-first后，越来越多的Android由Java转向了Kotlin。而使用Kotlin常常要碰上标题中的这几个函数，它们之间有着相似的地方，但也有各自的不同。放在一起，横向对比，便于记忆，在此做个记录。\n\n<!--more-->\n\n### 分类\n这几个函数均来自kotlin-stdlib库中的Standard.kt文件，同样在这个文件中还有另外几个函数，一块说一说。\n\n按照类型可以分为两类，一类是顶层函数，一类是扩展函数。\n\n这几个函数的参数中，基本都有一个代码块参数block，`T.() -> R`表示block的参数是T.this，`(T) -> R`表示block的参数是T，也就是it。\n\n### 顶层函数有：\n```kotlin\npublic inline fun TODO(): Nothing \n\npublic inline fun TODO(reason: String): Nothing \n\npublic inline fun repeat(times: Int, action: (Int) -> Unit) \n\npublic inline fun <R> run(block: () -> R): R \n\npublic inline fun <T, R> with(receiver: T, block: T.() -> R): R \n```\n其中，`TODO`是用来标记尚未实现的空方法，`repeat`用来重复执行传入的action，这两个就不多说了，我们来对比一下`with`和`run`\n\n|名称|block参数|返回值|\n|-|-|-|\n|run|无|block()|\n|with|T.this|block()|\n\n### 扩展函数有：\n```kotlin\npublic inline fun <T, R> T.run(block: T.() -> R): R \n\npublic inline fun <T> T.apply(block: T.() -> Unit): T \n\npublic inline fun <T, R> T.let(block: (T) -> R): R\n\npublic inline fun <T> T.also(block: (T) -> Unit): T\n\npublic inline fun <T> T.takeIf(predicate: (T) -> Boolean): T?\n\npublic inline fun <T> T.takeUnless(predicate: (T) -> Boolean): T?\n```\n其中，`takeIf`表示传入的predicate为true时，返回T，false返回null，而`takeUnless`恰恰相反，false时返回T，true时返回null。\n\n然后，我们来一块看一下剩下的4个函数。其实根据block的传入参数，和返回值的对比，区别就很清晰了。\n传入参数有两种：T.this 和 T\n返回值有两种：T 和 block()\n两种传入参数和两种返回值，两两组合，就有了这4个函数\n\n|名称|block参数|返回值|\n|-|-|-|\n|run|T.this|block()|\n|apply|T.this|T|\n|let|T|block()|\n|also|T|T|\n\n通过表格对比，就更加清晰了\n\n### 应用\n从传入参数来看，传T.this和T是类似的，传入T.this时，调用T的方法通过this.调用；传入T时，调用T的方法通过it.调用。\n如果你不关心扩展函数的返回值，那么随便你用哪个，本质上的区别并不大。\n如果关心扩展函数的返回值，当需要修改T中的一些成员的时候，考虑使用`apply`和`also`；当需要通过T来得到一个结果的时候，考虑使用`run`和`let`。\n\n### 总结\n这些个函数，都是Kotlin为了方便开发者写代码而设计的，如果你一个都不用，这完全没有问题。如果要用的话，就要清楚它们之间的区别和联系。\n\n","tags":["Kotlin"],"categories":["Kotlin"]},{"title":"Room的使用","url":"/2021/08/6960a7d25570/","content":"Room是一个数据库，基于SQLite的抽象层，也可以直接使用SQLite，但强烈建议使用Room。\n\n官方文档：[Android Room](https://developer.android.com/training/data-storage/room)\n\n<!--more-->\n\n### 导入依赖\n```groovy\ndependencies {\n    // ..... 其他依赖 .....\n\n    // Room\n    def room_version = \"2.3.0\"\n\n    implementation \"androidx.room:room-runtime:$room_version\"\n    annotationProcessor \"androidx.room:room-compiler:$room_version\"\n\n    // To use Kotlin annotation processing tool (kapt)\n    kapt \"androidx.room:room-compiler:$room_version\"\n}\n```\n\n### 创建表。\nRoom里的表，需要用@Entry注解标注，这里用个简单的学生表\n```kotlin\n// table_name就是表的名字，indecies是可选项，用来生成表的索引\n@Entity(tableName = \"student\", indices = [Index(value = [\"num\"], unique = true)])\ndata class Student(\n    @PrimaryKey val id: Int,\n    val num: Int,\n    val name: String,\n    val age: Int\n)\n```\n\n### 创建数据表访问类。\n这里我们只需要声明接口，并加以@Dao注解标注，具体实现交给Room来做，\n```kotlin\n// 这里只定义CRUD，增删改查，也可根据需要定义其他接口，如查询分数大于某个数值的所有学生\n@Dao\ninterface StudentDao {\n    @Insert\n    fun insert(student: Student): Long\n\n    @Delete\n    fun delete(student: Student): Int\n\n    @Update\n    fun update(student: Student): Int\n\n    @Query(\"SELECT * FROM student WHERE num = :num\")\n    fun query(num: Int): Student?\n}\n```\n\n### 表有了，访问方式也有了，下面创建数据库。\n```kotlin\n// 继承自RoomDatabase，其中已经实现了绝大数功能，我们只需要额外声明几个接口，用来提供Dao数据类\n// 方法的具体实现交给Room来做\n@Database(entities = [Student::class], version = 1)\nabstract class AppDatabase : RoomDatabase() {\n    abstract fun studentDao(): StudentDao\n}\n```\n\n### 万事俱备，现在可以用了。在Activity里调用下试试看\n```kotlin\noverride fun onCreate(savedInstanceState: Bundle?) {\n        super.onCreate(savedInstanceState)\n        setContentView(R.layout.activity_main)\n\n        // 通过Room提供的Builder创建数据库的实例\n        // 第一个参数是个context，第二个参数是数据库的Class，第三个参数是数据库文件的名字\n        val db = Room.databaseBuilder(this, AppDatabase::class.java, \"app.db\").build()\n\n        // 获得一个Dao\n        val dao = db.studentDao()\n\n        // 添加一条记录\n        dao.insert(Student(1, 1, \"john\", 98))\n    }\n```\n\n### 添加完成，运行一下。\n然后你会发现，崩溃了。。。日志如下：\n```shell\njava.lang.RuntimeException: Unable to start activity ComponentInfo{com.oynix.room.sample/com.oynix.room.sample.MainActivity}: java.lang.IllegalStateException: Cannot access database on the main thread since it may potentially lock the UI for a long period of time.\n```\n这句话的意思是说，不能在main thread，也就是主线程访问数据库，因为这样有可能会把页面卡住一段很长的时间。这样的检测机制算是合理的，毕竟这属于IO操作，而IO操作都应该放到单独的线程去跑。\n但是也可以去掉这种检测，在创建数据库的时候额外传入个配置：\n```kotlin\noverride fun onCreate(savedInstanceState: Bundle?) {\n        super.onCreate(savedInstanceState)\n        setContentView(R.layout.activity_main)\n\n        val db = Room.databaseBuilder(this, AppDatabase::class.java, \"app.db\")\n            .allowMainThreadQueries() // 允许在主线程操作\n            .build()\n        val dao = db.studentDao()\n        dao.insert(Student(1, 1, \"john\", 98))\n    }\n```\n这个时候再运行一下，就会发现顺利执行\n\n### 数据库文件\n这个时候，在Android Studio的Device File Explorer中，可以在data/data/{包名}/database目录下发现3个文件，app.db、app.db-shm和app.db-wal，其中.db是数据库文件，另外两个是临时文件。\n把这三个文件导出到电脑桌面，然后用能打开db文件的软件将app.db打开，如SQLite Professional、SQLite Studio等，会看到我们创建的student表，以及表中刚刚插入的那条数据。\n\n### 增加一张表\n这个时候，业务发生调整，我们需要增加一张教师表，如下\n```kotlin\n@Entity(tableName = \"teacher\", indices = [Index(value = [\"num\"], unique = true)])\ndata class Teacher(\n    @PrimaryKey val id: Int,\n    val num: Int, // 教师编号\n    val name: String,\n    val course: String\n)\n\n@Dao\ninterface TeacherDao {\n    @Insert\n    fun insert(teacher: Teacher): Long\n\n    @Delete\n    fun delete(teacher: Teacher): Int\n\n    @Update\n    fun update(teacher: Teacher): Int\n\n    @Query(\"SELECT * FROM teacher WHERE num = :num\")\n    fun query(num: Int): Teacher?\n}\n```\n同时，也要修改数据库类，增加新的教师表实体\n```kotlin\n\n@Database(entities = [Student::class, Teacher::class], version = 1)\nabstract class AppDatabase : RoomDatabase() {\n    abstract fun studentDao(): StudentDao\n    abstract fun teacherDao(): TeacherDao\n}\n```\n增加一条教师的记录。张老师，他很厉害，会教数学\n```kotlin\noverride fun onCreate(savedInstanceState: Bundle?) {\n        super.onCreate(savedInstanceState)\n        setContentView(R.layout.activity_main)\n\n        val db = Room.databaseBuilder(this, AppDatabase::class.java, \"app.db\")\n            .allowMainThreadQueries()\n            .build()\n        // John，学号：1\n        val dao = db.studentDao()\n        dao.insert(Student(1, 1, \"John\", 14))\n        \n        // 张老师，教数学\n        val teacherDao = db.teacherDao()\n        teacherDao.insert(Teacher(1, 1001, \"Miss Zhang\", \"Math\"))\n    }\n```\n再一运行，发现又报错了。。。\n```shell\njava.lang.RuntimeException: Unable to start activity ComponentInfo{com.oynix.room.sample/com.oynix.room.sample.MainActivity}: java.lang.IllegalStateException: Room cannot verify the data integrity. Looks like you've changed schema but forgot to update the version number. You can simply fix this by increasing the version number.\n```\n这句话的意思是说，数据库的schema，也就是结构发生了改变，但是版本号没有更新，Room不知道怎么处理这些schema的修改，然后就报了个错。\n\n### 数据库升级\n就像刚刚那样，在版本的迭代更新中，常常会有修改数据库结构的情况。在Room中，数据库是通过version号，来管理数据库版本的，每做一次修改，version都要增加，一般增加1，你每次加2也没人能拿你怎么样。我们在创建数据库的同时，还要告诉Room版本更新做了哪些操作，这些需要通过addMigrations来添加。\n只修改schema，而不增加version，程序会崩溃。\n只增加version，而不提供Migration，程序会删除并重建数据库\n```kotlin\noverride fun onCreate(savedInstanceState: Bundle?) {\n        super.onCreate(savedInstanceState)\n        setContentView(R.layout.activity_main)\n\n        val db = Room.databaseBuilder(this, AppDatabase::class.java, \"app.db\")\n            .allowMainThreadQueries()\n            .addMigrations(object : Migration(1, 2){\n                override fun migrate(database: SupportSQLiteDatabase) {\n                    database.execSQL(\"CREATE TABLE IF NOT EXISTS `teacher` (`id` INTEGER NOT NULL, `num` INTEGER NOT NULL, `name` TEXT NOT NULL, `course` TEXT NOT NULL, PRIMARY KEY(`id`))\")\n                    database.execSQL(\"CREATE UNIQUE INDEX IF NOT EXISTS `index_teacher_num` ON `teacher` (`num`)\")\n                }\n            })\n            .build()\n        // 这里要注掉，因为表里已经有了一个id为1的记录了\n        // val dao = db.studentDao()\n        // dao.insert(Student(1, 1, \"John\", 14))\n\n        val teacherDao = db.teacherDao()\n        teacherDao.insert(Teacher(1, 1001, \"Miss Zhang\", \"Math\"))\n    }\n```\n如上，从1到2后，我们新加了一个teacher表，并在表上加了一个索引，那么这么写就可以了。\n如果说，不想写这么长的SQL语句怎么办？也好办，全局搜AppDatabase_Impl.java文件，这里面就是Room已经写好的。\n再次运行，发现没有再崩溃，打开app.db，里面多了一张表，表里有一条刚加的张老师的记录。\n\n### addMigrations\n这里要单独说一说这个方法，程序运行后，如果本地数据库版本和代码里的版本不一致，这个时候这个方法才会派上用场，如果一致则无用。\n先帖下文档里的说明：\n```kotlin\n/**\nAdds a migration to the builder.\nEach Migration has a start and end versions and Room runs these migrations to bring the database to the latest version.\nIf a migration item is missing between current version and the latest version, Room will clear the database and recreate so even if you have no changes between 2 versions, you should still provide a Migration object to the builder.\nA migration can handle more than 1 version (e.g. if you have a faster path to choose when going version 3 to 5 without going to version 4). If Room opens a database at version 3 and latest version is >= 5, Room will use the migration object that can migrate from 3 to 5 instead of 3 to 4 and 4 to 5.\nParams:\nmigrations – The migration object that can modify the database and to the necessary changes.\nReturns:\nThis RoomDatabase.Builder instance.\n*/\n@NonNull\npublic Builder<T> addMigrations(@NonNull Migration... migrations)\n```\n它接收可变参数，即可同时接收多个Migration。每个Migration都有个startVersion，以及一个endVersion，Room将会运行这些Migration，将本地数据库的版本一步步升级到代码里的最新版本。如果缺失当前版本到最新版本的Migration，Room将会清空数据库并重建。所以，即便在两个版本之间没有变化，仍然需要提供一个Migration给builder。\n一个Migration可以处理多个版本，例如，当前是版本3，最新是版本5，你提供了3到4的Migration、4到5的Migration以及3到5的Migration，那么Room就会选择更快的Migration，即3到5，而不是由3到4再到5。\n\n### 数据加密\n虽然Android高版本在数据安全这一块已经提升了很多，未root的手机基本看不到其他应用独立存储空间里的内容，但为了以防万一，可以进一步将数据库文件，也就是app.db，进行加密。\n当前有很多种实现思路，如每次写之前，将数据加密，读之后，将数据解密，等。\n这里介绍个第三方加密库，使用很方便，当然也有缺点，就是包体会变大，因为用到了native库，增大6M左右\n- 引入依赖\n```groovy\n // room cypher maven\nmaven { url \"https://s3.amazonaws.com/repo.commonsware.com\" }\n\n// room cypher\nimplementation \"com.commonsware.cwac:saferoom.x:1.2.1\"\n```\n- 增加Factory，openHeloperFactory，\n```kotlin\n override fun onCreate(savedInstanceState: Bundle?) {\n        super.onCreate(savedInstanceState)\n        setContentView(R.layout.activity_main)\n\n        val db = Room.databaseBuilder(this, AppDatabase::class.java, \"app.db\")\n            .allowMainThreadQueries()\n            .openHelperFactory(SafeHelperFactory(\"your_database_password\".toCharArray()))\n            .addMigrations(object : Migration(1, 2){\n                override fun migrate(database: SupportSQLiteDatabase) {\n                    database.execSQL(\"CREATE TABLE IF NOT EXISTS `teacher` (`id` INTEGER NOT NULL, `num` INTEGER NOT NULL, `name` TEXT NOT NULL, `course` TEXT NOT NULL, PRIMARY KEY(`id`))\")\n                    database.execSQL(\"CREATE UNIQUE INDEX IF NOT EXISTS `index_teacher_num` ON `teacher` (`num`)\")\n                }\n            })\n            .build()\n//        val dao = db.studentDao()\n//        dao.insert(Student(1, 1, \"John\", 14))\n\n//        val teacherDao = db.teacherDao()\n//        teacherDao.insert(Teacher(1, 1001, \"Miss Zhang\", \"Math\"))\n    }\n```\n- 加密之后，再导出来的app.db就无法打开了\n\n### 总结\n以上，Room的简单使用就这些了，相比于SQLite，简单、方便了不少，本地化数据可以多考虑使用。\n另外还有些更高级的用法，比如和ViewModel的结合、和Hilt的结合、异步操作数据流，等等，这里就就不做说明了。\n\n附上Github地址：[https://github.com/oynix/RoomSample](https://github.com/oynix/RoomSample)","tags":["Android","Kotlin","Room"],"categories":["Android"]},{"title":"管理 MacOS 上的 Python 环境版本","url":"/2021/06/d54bb8006555/","content":"\n### 00.前言\nMacOS 上的 Python不同版本的环境一直是个让人头大的问题，原因在于，系统预先安装了2.7版本，但这是个老版本了，老版本是不能卸载的，一些系统程序都在依赖它。\n\n现在市面上开发的新程序多数在用3.x版本，部分老代码还在用2.x版本，两个大版本还是有些区别的，无法完全兼容，这就让管理多版本共存成了个问题。\n\n当然，也有一些管理工具，如pyenv，但其实python的venv模块已经足够了，下面会简单说一说使用。\n<!--more--> \n### 01.卸载干净\n据不完全统计，目前发现了以下这些还算固定的安装目录：\n\n- 自己安装的Python在这个目录，即通过官网下载的安装程序安装\n/Library/Frameworks/Python.framework\n\n- Python应用目录\n/Applications/Python3.x\n\n- 通过brew命令安装在这个目录，brew是个包管理工具，使用它安装的都在Cellar目录\n/usr/local/Cellar\n\n- 通过CommandLineTools安装在这个目录，这是个Xcode带的工具包\n/Libaray/Developer/CommandLineTools/Library/Frameworks\n\n- 系统预安装的在这个目录，这个看看就行了，不能删\n/System/Library/Frameworks/Python.framework\n\n```sh\n$ which python\n$ which python3\n```\n\n通过这两个命令，找到python可执行程序\n- /usr/local/bin，这个目录下的，可以删除\n- /usr/bin，这个目录下的，想删也删不了，没权限。Catalina以下的通过关闭SIP可以操作/usr/bin目录下的文件，但以上的版本关掉SIP也不行了。我在早年间通过这种方式在/usr/bin目录下放了一个python3的可执行程序，现在升级到了Big Sur版本，导致这个可执行文件删不掉了，除了重装系统，我也没想到什么好办法，暂时就先这么放着。\n\n终端窗口执行python会进入2.7的交互解释环境，执行python3会报错command not found\n```sh\n$ python3\n-bash: python3: command not found\n\n$ which python\n/usr/bin/python\n\n$ python\nWARNING: Python 2.7 is not recommended. \nThis version is included in macOS for compatibility with legacy software. \n```\n\n至此，现在系统里应该只剩下系统预安装的python2.7了，可执行文件在/usr/bin目录，同时/usr/local/bin目录不再有python可执行文件。\n\n### 02.安装最新\n直接用brew安装就好，别再用其他的各路神仙工具了，听我一句劝，不要在意别人怎么怂恿，就用brew就可以了，这个是macOS上最普遍、最通用的包管理工具，用最简单的方式做最大的事，多了不起。\n\n如果不是新买的机器，应该都装了brew工具了，要是没装，那就先装一下，一行代码，等着就好了\n```sh\n$ ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\"\n```\n\n如果发现访问困难，卡住、网速慢，可以使用国内镜像网站，下面这个是中科大的，速度还可以\n```sh\n$ ruby -e \"$(curl -fsSL https://cdn.jsdelivr.net/gh/ineo6/homebrew-install/install)\"\n```\n\n然后，安装python3，一行代码，还是等着就好了，python3有多个版本，3.6、3.7、3.8以及最新的3.9，不指定版本会默认安装最新，如果有需要，可以指定版本：python@3.x，如果同时存在多个3.x，要注意名字的区分\n```sh\n$ brew install python3\n```\n\n这里唠叨几句pip，pip是python的包管理工具，前身是easy_install，这两者的关系是，python是可执行文件，pip是python的一个模块，可有也可无，非必需，建议还是用pip，毕竟其他方式管理包很麻烦。如果意外把pip删除了也可以单独安装\n\n```sh\n# 安装\n$ python3 -m ensurepip\n$ python3 -m pip install pip --upgrade\n# 目标位置\n$ which pip\n/usr/local/bin/pip\n# 卸载\n$ python3 -m pip uninstall pip\n\n# 默认会安装这个三个，再安装用pip install {package}即可\n$ pip list -v\npip          21.1.2    /usr/local/lib/python3.9/site-packages     pip\nsetuptools   57.0.0    /usr/local/lib/python3.9/site-packages     pip\nwheel        0.36.2    /usr/local/lib/python3.9/site-packages     pip\n```\n\n一个pip关联一个python可执行文件，像上面这样，就是将pip关联到了python3，通过这个pip安装的包只有python3可调用到，系统自带的python调用不到，如果有需要，也可以为系统python可执行文件也装个pip工具，但要注意名字的区分\n\n```sh\n# 安装\n$ python -m ensurepip\n# python是系统自带的，但没有操作系统目录的权限，所以需要加上--user\n$ python -m pip install pip --upgrade --user\n# --user后会安装到当前用户目录库下，我的在这\n$ cd /Users/{username}/Library/Python/2.7/bin\n# 然后在pip同样的位置创建一个软连接就可以了\n$ ln -s /Users/{username}/Library/Python/2.7/bin/pip /usr/local/bin/pip2\n# 目标位置\n$ which pip2\n/usr/local/bin\n\n# 卸载\npython -m pip uninstall\n\n# 这个就比较多了，而且都在系统目录里，咱也操作不了\n# 再安装要加--user，这样会安装到当前用户目录库文件下: pip2 install {package} --user\n# /Users/{username}/Library/Python/2.7/lib/python/site-packages\n$ pip2 list -v\naltgraph   0.10.2  /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python\nasn1crypto 0.24.0  /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python\nbdist-mpkg 0.5.0   /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python\nbonjour-py 0.3     /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python\n```\n\n### 03.日常使用\n日常使用是通过venv模块，一般一个项目使用一个venv环境，互相独立、互不干扰。\n\n这种模式，就像是在一座大房子（机器）里可以建造很多不同类型（版本）的小房间（虚拟环境），每个小房间（虚拟环境）里的操作的影响范围只限于在这个房间（虚拟环境）内，各个房间（虚拟环境）互相独立互不影响，房间（虚拟环境）可以随时创建（新建）和拆除（删除）。\n\n```sh\n# 切换到项目的根目录下\n$ cd PyProj\n\n# 创建一个venv环境，第二个参数venvDir是环境目录的名称，一般使用venv，可随意，合法即可\n$ python3 -m venv venvDir\n\n# 查看虚拟环境，可看到如下内容\n$ ls -l venvDir\ndrwxr-xr-x  12 username  staff  384 Jun  8 23:44 bin\ndrwxr-xr-x   2 username  staff   64 Jun  8 23:44 include\ndrwxr-xr-x   3 username  staff   96 Jun  8 23:44 lib\n-rw-r--r--   1 username  staff   90 Jun  8 23:44 pyvenv.cfg\n\n# 激活当前venv环境，之后每行前面会多个(venvDir)，表示在该环境中\n$ source venvDir/bin/activate\n\n# 查看python可执行文件位置，此时在虚拟环境中，只有一个python，所以不要再输入python3\n(venvDir)$ which python\nPyPorj/venvDir/bin/python\n\n# 查看pip\n(venvDir)$ which pip\nPyPorj/venvDir/bin/pip\n\n# 此时的python可执行程序和pip可执行程序只在当前环境内有效，若要退出当前环境则执行\n(venvDir)$ deactivate\n```\n\n注意，如果在IDE（如PyCharm）的Terminal里执行创建venv的命令，可能会报权限的错，使用系统的终端便可正常使用。\n\n### 04.附录\n- 查看pip版本\n```sh\n$ pip -V\n```\n\n- 用pip安装package时，加上--user参数，会安装到当前用户的库目录中，只对当前用户有效，不加--user会安装到全局目录，对所有用户有效。如果你的电脑只有一个用户，那么二者没有区别\n```sh\n$ pip install --user\n～/Library/Python/3.9/lib/python/site-packages/\n\n$ pip install\n/usr/local/lib/python3.9/site-packages/\n```\n\n- brew安装目录\n/usr/local/Cellar\nHomebrew配置目录\n/usr/lcoal/etc\nHomebrew命令目录\n/usr/local/bin\n\n- brew常用命令\nbrew install FORMULA\nbrew cleanup\nbew searh FORMULA\nbrew info FORMULA\nbrew upgrade FORMULA\nbrew update","tags":["Python","MacOS"],"categories":["Python"]},{"title":"CircleImageView","url":"/2020/02/c0c9e38ff81e/","content":"\nAndroid 系统默认的 ImageView 是矩形，但有时页面上需要展示圆形的图片，如头像。这里提供一种最简单的实现思路。\n\n<!--more-->\n将圆形遮罩当作目标（DST），图片当作源（SRC）\n先画的是destination，后画的是source\n\n```java\npublic class CircleImageView extends AppCompatImageView {\n\n    private Paint mPaint;\n    private Xfermode mXfermodeDstOut;\n    private Path mPath;\n\n    public CircleImageView(Context context, @Nullable AttributeSet attrs) {\n        super(context, attrs);\n        init();\n    }\n\n    private void init() {\n        mPaint = new Paint(Paint.ANTI_ALIAS_FLAG | Paint.FILTER_BITMAP_FLAG);\n        mPaint.setStyle(Paint.Style.FILL);\n        mXfermodeDstOut = new PorterDuffXfermode(PorterDuff.Mode.DST_OUT);\n    }\n\n    @Override\n    protected void onDraw(Canvas canvas) {\n        if (mPath == null) {\n            int w = getWidth();\n            int h = getHeight();\n            int cx = w / 2;\n            int cy = h / 2;\n            mPath = new Path();\n            mPath.moveTo(0, 0);\n            mPath.lineTo(w, 0);\n            mPath.lineTo(w, h);\n            mPath.lineTo(0, h);\n            mPath.addCircle(cx, cy, Math.min(cx, cy), Path.Direction.CCW);\n        }\n        canvas.saveLayer(0, 0, getWidth(), getHeight(), mPaint, Canvas.ALL_SAVE_FLAG);\n        super.onDraw(canvas);\n        mPaint.setXfermode(mXfermodeDstOut);\n        canvas.drawPath(mPath, mPaint);\n        mPaint.setXfermode(null);\n        canvas.restore();\n    }\n}\n```\n[源文件](https://github.com/oynix/widgetlib/blob/master/widget/src/main/java/com/oynix/widget/CircleImageView.java)","tags":["Android","Widget","CircleImageView"],"categories":["Android"]},{"title":"Paint常用方法说明","url":"/2020/02/bcaaeeb315b6/","content":"\n# Paint常用方法说明\n\n[原文地址](https://blog.csdn.net/aigestudio/article/details/41316141)，写的很详细并且有趣。这里只挑出一些常用的，难于理解的，单独拿出来做个笔记。\n\n<!--more-->\n\n## setAntiAlias(boolean aa)\n\n设置抗锯齿。也可以在 new 的时候传入 Paint.ANTI_ALIAS_FLAG。\n\n## setColorFilter(ColorFilter filter)\n\n类 ColorFilter 没有具体实现，它有三个子类：\n\n### ColorMatricColorFilter\n\n矩阵颜色过滤器，在 Android 中图片是以 RGBA 像素点的形式加载到内存中的，修改这些橡塑信息需要一个 ColorMatrix 类的支持，其定义了一个 4x5 的 float[] 类型的矩阵：\n\n```java\nColorMatrix colorMatric = new ColorMatrix(new float[]{\n  1, 0, 0, 0, 0,// R\n  0, 1, 0, 0, 0,// G\n  0, 0, 1, 0, 0,// B\n  0, 0, 0, 1, 0,// A\n});\n```\n\n其中，第一行表示 R(红色) 的向量，第二行表示 G(红色) 的向量，第三行表示 B(蓝色) 的向量，最后一行表示 A(透明度) 的向量，这一顺序是固定的，不可改变。每一行的前 4 个值表示的是 RGBA 的值，其范围在 0.0F 至 2.0F 之间，1 为保持原图的 RGB 的值。每一行的第 5 个表示偏移值，想让颜色更倾向于某个颜色时，就增加该颜色的偏移值。\n\n> 何为偏移值？顾名思义当我们想让颜色更倾向于红色的时候就增大R向量中的偏移值，想让颜色更倾向于蓝色的时候就增大B向量中的偏移值，这是最最朴素的理解，但是事实上色彩偏移的概念是基于白平衡来理解的，什么是白平衡呢？说得简单点就是白色是什么颜色！如果大家是个单反爱好者或者会些PS就会很容易理解这个概念，在单反的设置参数中有个色彩偏移，其定义的就是白平衡的色彩偏移值，就是当你去拍一张照片的时候白色是什么颜色的，在正常情况下白色是（255, 255, 255, 255）但是现实世界中我们是无法找到这样的纯白物体的，所以在我们用单反拍照之前就会拿一个我们认为是白色的物体让相机记录这个物体的颜色作为白色，然后拍摄时整张照片的颜色都会依据这个定义的白色来偏移！而这个我们定义的“白色”（比如：255, 253, 251, 247）和纯白（255, 255, 255, 255）之间的偏移值（0, 2, 4, 8）我们称之为白平衡的色彩偏移。\n\nColorMetrix 类里面提供一些实在的方法，如 setSaturation(float sat) 设置饱和度。\n\n### LighingColorFilter\n\n光照颜色过滤，该类只有一个构造方法：\n\n```java\nLightingColorFilter(int mul, int add)\n```\n\n其中 mul 的全称是 colorMultiply 意为色彩倍增，add 全称是 colorAdd 意为色彩增加，这两个值都是 16 进制的色彩值 0xAARRGGBB。\n\n### PorterDuffColorFilter\n\n同 LightingColorFilter 一样，只有一个构造方法：\n\n```java\nPorterDuffColorFilter(int color, PorterDuff.Mode mode)\n```\n\n接受两个值，一个是 16 进制的颜色值，另一个是 PorterDuff 内部类 Mode 中的常量值，表示混合模式。Mode 不仅仅应用于色彩混合，还应用于图形混合，如果在 PorterDuffColorFilter 中强行设置图形混合的模式，将不会看到任何对应的效果。\n\n## setXfermode(Xfermode xfermode)\n\nXfermode，可以直接理解为图像混合模式，它没有具体实现，但有 3 个子类，这 3 个子类实现的功能比 setColorFilter 的 3 个子类复杂\n\n### AvoidXfermode\n\n这个 API 因为不支持硬件加速所以在 API 16 已经过时了，如果想在高于 16 的机器上使用，必须关闭硬件加速，可以在 [HardwareAccelerate](https://developer.android.com/guide/topics/graphics/hardware-accel.html) 文档中查看如何关闭硬件加速，以及查看更多不支持硬件加速的 API。\n\nAvoidXfermode 只有一个含参的构造方法：\n\n```java\nAvoidXfermode(int opColor, int tolerance, AvoidXfermode.Mode mode)\n```\n\n具体实现和 ColorFilter 一样都被封装在 C/C++ 内，我们只管调用就好。第一个参数 opColor 表示一个 16 进制的可以带透明通道的颜色值，第二个参数 tolerance 表示容差值，可以理解为一个标识「精确」或「模糊」的东西，最后一个参数 AvoidXfermode 表示具体模式，可选值只有两个：AvoidXfermode.Mode.AVOID 或 AvoidXfermode.Mode.TARGET\n\n#### AvoidXfermode.Mode.TARGET\n\n在该模式下 Android 会判断画布上的颜色是否有跟 opColor 一样的颜色，比如 opColor 是红色，TARGET 模式下就会判断画布上是否有存在红色的地方，如果有则把该区域「染」上一层画笔定义的颜色，否则不「染」色，而 tolerance 容差值则表示画布上的像素和 opColor 之间的差别是多少的时候才去「染」，比如当前画布有一个像素的色值是(200, 20, 13)，而 opColore 是 (255, 0, 0)，当 tolerance 容差值为 255 时，即便(200, 20, 13)并不等于 opColor 也会被染色，容差值越大「染」色范围越广。\n\n#### AvoidXfermode.Mode.AVOID\n\n与 TARGET 恰恰相反，TARGET 是与 opColor 与画布颜色一样，而 AVOID 是 opColor 与 画布颜色不一样，其他的都类似。\n\n### PixelXorXfermode\n\n与 AvoidXfermode 一样也在 API 16 过时了，该类也提供了一个含参的构造方法\n\n```java\nPixelXorXfermode(int opColor)\n```\n\n该类的计算实现很简单，从官方给出的计算公式来看就是：op^src^dst，像素色值按位异或运算\n\n### PorterDuffXfermode\n\nXfermode的最后一个子类也是唯一一个没有过时切沿用至今的子类。该类同样只有一个构造方法：\n\n```\nPorterDuffXfermode(PorterDuff.Mode mode)\n```\n\n其中的 PorterDuff.Mode 和上面讲的 ColorFilter 用到的 PorterDuff.Mode 是一样的。PorterDuffXfermode 就是图形混合模式的意思，其概念最早来自 SIGGRAPH 的 Tomas Porter 和 Tom Duff，名字就是这两个人的名字的组合\n\n![](https://i.loli.net/2021/07/19/ALKqGnE3UshgClQ.jpg)\n\n这张图片从一定程度上形象地说明了图形混合的作用，两个图形一圆一方通过一定的计算产生不同的组合效果，在 API 中 Android 提供了 18 种（比上图多了两种 ADD 和 OVERPLAY）模式：\n\n![](https://i.loli.net/2021/07/19/3kGpPcMVwu7XaxL.jpg)\n\nSa 全称 Source Alpha，Sc 全称 Source Color，Da 全称 Destination Alpha，Dc 全称 Destination Color。每个中括号由两个值组成：[Alpha, Color]。\n\nSource 为源图像，意为将要绘制的图像；Destination 为目标图像，意为将源图像绘制到的图像。简单理解，先绘制的是 dst，后绘制的是 src。\n\n#### 总结\n\nOVER：谁在上谁在下的问题\n\nIN：绘制相交部分，SRC_IN绘制SRC，DST_IN绘制DST\n\nOUT：绘制不相交部分，SRC_OUT绘制SRC，DST_OUT绘制DST\n\nATOP：SRC_ATOP只绘制SRC中相交部分，DST_ATOP只绘制DST中相交部分\n\n## setDither(boolean dither)\n\n设置绘制图像时的抗抖动，也称为递色\n\n放大来看，其在很多相邻像素之间插入了一个中间值，使颜色过渡变得些许柔和\n\n## setMaskFilter(MaskFilter maskFilter)\n\nMaskFilter 类中没有任何实现方法，它有两个子类 BlurMaskFilter 和 EmbossMaskFilter，前者为模糊遮罩滤镜，而后者为浮雕遮罩滤镜，不支持硬件加速\n\n### BlurMaskFilter\n\n只有一个含参的都早方法\n\n```java\nBlurMaskFilter(float radisu, BlurMaskFilter.Blur style)\n```\n\n其中 radius 表示阴影半径，值越大越扩散。第二个参数 style 表示模糊类型，有四种选择：SOLD 效果是在图像的 Alpha 边界产生一层与 Paint 颜色一致的阴影效果而不影响图像本身；NORMAL 会将整个图像模糊掉；OUTER 会在 Alpha 边界外产生一层阴影且会将原本的图像变得透明；INNER 则会在图像内部产生模糊，很少用\n\n如上所说 BlurMaskFilter 是根据 Alpha 通道的边界来计算模糊的，如果是一张图片（注：Android 会把复制到资源目录的图片转为 RGB565）你会发现没有任何效果，那么如何给图片加一个类似阴影的效果呢？其实很简单，可以尝试从 Bitmap 中获取其 Alpha 通道，并在绘制 Bitmap 前先以该 Alpha 通道绘制一个模糊就可以了\n\n```java\npublic class BlurMaskFilterView extends View {\n\tprivate Paint shadowPaint;// 画笔\n\tprivate Context mContext;// 上下文环境引用\n\tprivate Bitmap srcBitmap, shadowBitmap;// 位图和阴影位图\n \n\tprivate int x, y;// 位图绘制时左上角的起点坐标\n \n\tpublic BlurMaskFilterView(Context context) {\n\t\tthis(context, null);\n\t}\n \n\tpublic BlurMaskFilterView(Context context, AttributeSet attrs) {\n\t\tsuper(context, attrs);\n\t\tmContext = context;\n\t\t// 记得设置模式为SOFTWARE\n\t\tsetLayerType(LAYER_TYPE_SOFTWARE, null);\n \n\t\t// 初始化画笔\n\t\tinitPaint();\n \n\t\t// 初始化资源\n\t\tinitRes(context);\n\t}\n \n\t/**\n\t * 初始化画笔\n\t */\n\tprivate void initPaint() {\n\t\t// 实例化画笔\n\t\tshadowPaint = new Paint(Paint.ANTI_ALIAS_FLAG | Paint.DITHER_FLAG);\n\t\tshadowPaint.setColor(Color.DKGRAY);\n\t\tshadowPaint.setMaskFilter(new BlurMaskFilter(10, BlurMaskFilter.Blur.NORMAL));\n\t}\n \n\t/**\n\t * 初始化资源\n\t */\n\tprivate void initRes(Context context) {\n\t\t// 获取位图\n\t\tsrcBitmap = BitmapFactory.decodeResource(context.getResources(), R.drawable.a);\n \n\t\t// 获取位图的Alpha通道图\n\t\tshadowBitmap = srcBitmap.extractAlpha();\n \n\t\t/*\n\t\t * 计算位图绘制时左上角的坐标使其位于屏幕中心\n\t\t */\n\t\tx = MeasureUtil.getScreenSize((Activity) mContext)[0] / 2 - srcBitmap.getWidth() / 2;\n\t\ty = MeasureUtil.getScreenSize((Activity) mContext)[1] / 2 - srcBitmap.getHeight() / 2;\n\t}\n \n\t@Override\n\tprotected void onDraw(Canvas canvas) {\n\t\tsuper.onDraw(canvas);\n\t\t// 先绘制阴影\n\t\tcanvas.drawBitmap(shadowBitmap, x, y, shadowPaint);\n \n\t\t// 再绘制位图\n\t\tcanvas.drawBitmap(srcBitmap, x, y, null);\n\t}\n}\n```\n\n## setPathEffect(PathEffect effect)\n\nPathEffect 很明显就是路径效果的意思，其一共有六个子类，效果如下\n\n![](https://i.loli.net/2021/07/19/MUrCkB97ZFY8Hya.jpg)\n\n从上到下：未设置PathEffect，CornerPathEffect，DiscretePathEffect，DashPathEffect，PathDashPathEffect，ComposePathEffect，SumPathEffect\n\n## setStrokeCap(Paint.Cap cap)\n\n设置画笔笔触风格，ROUND，SQUARE 和 BUTT\n\n##setStrokeJoin(Paint.Join join)\n\n设置结合处的形态\n\n## setShadowLayer(float radius, float dx, float dy, int shadowColor)\n\n为绘制的图形添加一个阴影层效果，不支持硬件加速\n\n## setShader(Shader shader)\n\n着色器，有五个子类\n\n### BitmapShader\n\n只有一个含参的构造方法，其他 4 个子类都有两个\n\n```java\nBitmapShader(Bitmap bitmap, Shader.TileMode tileX, Shader.TileMode tileY)\n```\n\nShader.TileMode 有三种：CLAMP 拉伸，MIRROR 镜像和 REPEAT 重复\n\n### LinearGradient\n\n线性渐变\n\n```java\nLinearGradient(float x0, float y0, float x1, float y1, int color0, int color1, Shader.TileMode tile)\n```\n\n(x0, y0) 渐变的起点，(x1, y1) 渐变的终点，color0 起点颜色，color1 终点颜色\n\n```java\nLinearGradient(float x0, float y0, float x1, float y1, int[] colors, float[] positions, Shader.TileMode tile)\n```\n\ncolors 表示支持多个颜色，positons 表示各个颜色的分界位置，如 {Color.RED, Color.GREEN, Color.BLUE}，{0, 0.3F, 0.8F}，positions 为null 时均分渐变区域\n\n### SweepGradient\n\n梯度渐变，也称扫描式渐变，累死雷达扫描效果\n\n```java\nSweepGradient(float cx, float cy, int color0, int color1)\n\nSweepGradient(float cx, float cy, int[] colors, float[] positons)\n```\n\n同 LinearGradient\n\n### RadialGradient\n\n径向渐变，从圆心中心向四周渐变的效果，构造方法就先写一个，同上\n\n```java\nRadialGradient(float cx, float cy, float radius, int centerColor, int edgeColor, Shader.TileMode tile);\n```\n\n### ComposeShader\n\n组合 Shader\n\n```java\nComposeShasdr(Shader s0, Shader s1, Xfermode mode);\nComposeShader(Shader s0, Shader s1, PorterDuff.Mode mode)\n```\n\n## Metrix\n\n3 x 3 坐标矩阵，初始值:\n\n```java\nnew float[]{\n  1, 0, 0, // x\n  0, 1, 0, // y\n  0, 0, 1, // 1\n}\n```\n\n第一列表示 x 轴方向缩放，第二列表示 y 轴方向缩放，第三列表示偏移\n\n### setTranslate scale\n### preTranslate scale\n### postTranslate scale\n常应用于中心缩放\n```java\nmatrix.setScale(interpolatedTime, interpolatedTime);\nmatrix.preTranslate(-centerX, -centerY);\nmatrix.postTranslate(centerX, centerY);\n```\n","tags":["Android","Paint"],"categories":["Android"]},{"title":"Flask API 单元测试 unittest，mock && patch","url":"/2019/12/97c306187ae6/","content":"\n单元测试，主要是为了测试某个方法，或是某个代码快，对于各种输入的处理，输出是否符合预期。但由于其他库、或模块的依赖，以至于很难独立测试我们自己实现的逻辑代码。\n\n对此，引出 mock。\n<!--more--> \n## 一、Flask\n**Flask**是个轻量 API 框架，使用起来非常容易上手\n```python\n# 安装：pip install flask\nfrom flask import Flask\n\napp = Flask(__name__)\n\n@app.route('/')\ndef index():\n    return 'Hello Flask'\n\napp.run(port=5000)\n```\n这样，一个简单的 server 就跑起来了，访问 **http:localhost:5000** 便可以看到返回的数据：**Hello Flask**\n\n下面举例说明，如果对单一的接口写测试用例\n\n## 二、举例：用户登录\n1. 用户登录是个常见的功能接口，接口逻辑之外的部分基本同上，这里省略不写。用户使用 **name** 和 **password** 进行登陆操作，服务器收到请求后，根据 **name** 从数据库查询 **password** ，一致则返回 **200 OK**，不一致返回 **400 Bad Request**，很简单的实现，如下：\n\t```python\n\tfrom flask import request\n\tfrom app.model import UserDB\n\t\n\t@app.route('/login')\n\tdef login():\n\t    name = request.args.get('name')\n\t    if not name:\n\t        return 'name is required', 400\n\t   \n\t    password = request.args.get('password')\n\t    if not password:\n\t        return 'password is required', 400\n\t  \n\t    # 从数据库获取用户数据\n\t    user = UserDB.get_user(name)\n\t    if user.get('password') == password:\n\t        return 'OK', 200\n\t    else:\n\t        return 'password is wrong', 400\n\t```\n    其中 **UserDB** 为数据模块中，从数据库查询用户数据的类。这里对于**登录逻辑**的单元测试，只指测试该部分最小的代码块，对于代码块中引入的依赖，在测试时都认为是正常的。例如，在测试 **login()** 的时候，我们认为 **UserDB** 是正常的、可用的，至于 **UserDB** 的可靠性，需要 **UserDB** 模块的单元测试来保障。\n    对于待测试模块内引入的依赖，采用 **mock** 的方式模拟。\n2. **Flask** 的单元测试，先看代码\n\t```python\n\timport unittest\n\tfrom unittest.mock import Mock\n\tfrom unittest.mock import patch\n\t# 该app为创建的Flask实例\n\tfrom application import app\n\t\n\tfrom app.model import UserDB\n\t\n\tclass LoginTestCase(unittest.TestCase):\n\t  \n\t    def setUp(self):\n\t        # push一个上下文，便可以使用flask中的全局变量，如g\n\t        app.app_context().push()\n\t        app.testing = True\n\t        # 测试用的http client\n\t        self.client = app.test_client()\n\t    \n\t    def test_login_success(self):\n\t        # 真实请求中的url，host和port可省略\n\t        url = '/login?name=flask&password=flaskpassword'\n\t        # 模拟的方法名称，也可直接写字符串： get_user\n\t        func_name = UserDB.get_user.__name__\n\t        # 模拟的方法，不管请求参数是什么，都会返回return_value的值（Mock还有其他用法）\n\t        mock_func = Mock(return_value={'name': 'flask', 'password': 'flaskpassword'})\n\t        # patch意为，当UserDB的get_user方法被调用时，用mock出来的func来处理\n\t        # 而mock的func，不管请求参数，都会返回return_value\n\t        # 故而，只要UserDB的get_user被调用，都会返回{'name': 'flask', 'password': 'flaskpassword'}\n\t        # with，表示这种处理方式的作用范围\n\t        # 当在with的范围之外时，调用UserDB的get_user不受mock影响，会正常调用\n\t        with patch.object(UserDB, func_name, func):\n\t            # response为返回的响应\n\t            response = self.client.get(url)\n\t            # 因为传入的name和password，和UserDB的mock func返回的name和password相同\n\t            # 所以，该请求会返回200\n\t            # assertEqual意为，认定返回码与200相等，若不等则该用例不通过\n\t            self.assertEqual(response.status_code, 200)\n\t       \n\t    def test_login_failed(self):\n\t        # 测试传入错误密码的情况\n\t        url = '/login?name=flask&password=wrongpassword'\n\t        func_name = UserDB.get_user.__name__\n\t        mock_func = Mock(return_value={'name': 'flask', 'password': 'flaskpassword'})\n\t        with patch.object(UserDB, func_name, func):\n\t            response = self.client.get(url)\n\t            # 因为传入密码错误，所以在此我们认定返回码是400\n\t            self.assertEqual(response.status_code, 400)\n\t```\n\n此外，还可以对测试缺少参数，这里不再赘述。这样，便可对接口的各种情况进行测试了。\n","tags":["Flask","Python"],"categories":["Flask"]},{"title":"React - Webpack 项目脚手架搭建","url":"/2019/11/05d3ed0e9549/","content":"\n> 把手还是伸向了前端，抽空折腾了几天，算是理清了起步门槛。\n<!--more--> \n##### 一、首先确保安装了 npm，如果没装....那就想办法装上\n```sh\n$ npm\nUsage: npm <command>\n\nwhere <command> is one of:\n    access, adduser, bin, bugs, c, cache, completion, config,\n    ddp, dedupe, deprecate, dist-tag, docs, doctor, edit,\n    explore, get, help, help-search, i, init, install,\n    install-test, it, link, list, ln, login, logout, ls,\n    outdated, owner, pack, ping, prefix, profile, prune,\n    publish, rb, rebuild, repo, restart, root, run, run-script,\n    s, se, search, set, shrinkwrap, star, stars, start, stop, t,\n    team, test, token, tst, un, uninstall, unpublish, unstar,\n    up, update, v, version, view, whoami\n\nnpm <command> -h     quick help on <command>\nnpm -l           display full usage info\nnpm help <term>  search for help on <term>\nnpm help npm     involved overview\n\nSpecify configs in the ini-formatted file:\n    /Users/xiaoyu/.npmrc\nor on the command line via: npm <command> --key value\nConfig info can be viewed via: npm help config\n\nnpm@5.6.0 /usr/local/lib/node_modules/npm\n```\n##### 二、安装 create-react-app。如果用 WebStorm，可以跳过这一步。\n> IDE 可以选择创建 React App，省去了手动执行，所以创建后的目录内容是一样的。\n```sh\n// -g : global\n$ npm install create-react-app -g\n/usr/local/bin/create-react-app -> /usr/local/lib/node_modules/create-react-app/index.js\n+ create-react-app@3.2.0\nadded 91 packages in 24.685s\n\n$ create-react-app\nPlease specify the project directory:\n  create-react-app <project-directory>\n\nFor example:\n  create-react-app my-react-app\n\nRun create-react-app --help to see all options.\n```\n如介绍所言，创建一个app，名字任意，合法即可\n```sh\n$ create-react-app my-react-app\n```\n项目结构如下：\n```sh\n$ ls my-react-app\nREADME.md\t\t    package-lock.json\tpublic\nnode_modules\t\tpackage.json\t\tsrc\n```\n- README.md : 你懂的\n- node_moudles : 依赖都在找个目录下\n- package.json : npm的配置文件，或者说是项目的配置文件\n- package-lock.json : 锁定版本号\n- public : 存放静态资源\n- src :  代码／资源\n\n#### 三、安装 webpack 全家桶\n> npm install 参数说明：package.json 有几个依赖节点，`dependencies` 、 `devDependencies` 和 `optionalDependencies`，前者会随着项目发布出去；后者顾名思义，只在开发时使用；后后者为可选阶段\n>  - - - - - - - \n> -S， --save ：依赖添加到 `dependencies` 节点，\n> -D，--save-dev ：依赖添加到 `devDependencies` 节点\n> -O，--save-optional ：依赖添加到  `optionalDependencies` 节点\n\n以下命令，在项目根目录下执行\n```sh\n// 也可以放在一行执行\n$ npm install webpack -D\n$ npm install webpack-cli -D\n$ npm install webpack-dev-server -D\n```\n**注意，这里有个坑：这三个依赖的版本号一定要相互匹配，如果你要指定版本，一定要确认指定的版本号是行不通的，不然就会报错。都用最新版，目前一切正常。**\n\n#### 四、配置 webpack server\n鉴于 webpack 可用于本地 server，也可用于打包，各自使用不同的配置文件。在项目根目录创建个文件夹 `wepack`，用于存放 webpack 配置文件。\n1. webpack/webpack.config.js，用于开发 server\n```js\nconst path = require('path');\nconst webpack = require('webpack');\nconst __repo = path.dirname(__dirname);\nconst HtmlWebpackPlugin = require('html-webpack-plugin');\n\nmodule.exports = {\n    entry: { // 程序唯一入口\n        'index': path.resolve(__repo, 'src/index.jsx'),\n    },\n    mode: 'development',\n    output: { // 打包文件输出位置\n        path: path.resolve(__repo, \"build\"),\n        filename: \"bundle.js\",\n        publicPath: \"/\"\n    },\n    devServer: {\n        contentBase: [path.join(__repo, 'public'),], // 本地服务器索价在的页面所在目录\n        compress: false,\n        port: 7788, // server 使用端口\n        disableHostCheck: true,\n        inline: true, // 实时刷新\n        historyApiFallback: true, // 不跳转\n        hot: true\n    },\n    module: {\n        rules: [\n            {\n                test: /(\\.jsx|\\.js)$/, // 匹配所护理文件的扩展名正则表达式\n                exclude: /(node_modules|bower_components)/, // 手动添加／屏蔽的文件\n                use: {\n                    loader: 'babel-loader', // loader名称\n                }\n            },\n            {\n                test: /\\.(css|styl)$/,\n                use: [\n                    {\n                        loader: 'style-loader'\n                    },\n                    {\n                        loader: 'css-loader'\n                    }\n                 ]\n            },\n            {\n                test: /\\.html$/,\n                use: [\n                    {loader: 'html-loader'}\n                ]\n            },\n            {\n                test: /\\.(gif|jpg|png|svg|ttf|eot|woff|woff2)$/,\n                use : {\n                    loader: 'file-loader?name=fonts/[name].[ext]'\n                }\n            },\n        ]\n    },\n    plugins: [\n        new HtmlWebpackPlugin({\n            filename: 'index.html',\n            template: 'public/index.html'\n        })\n    ]\n};\n```\n其中的 `module`，就是 webpack 的 loader，都是用来打包用的：\n- **babel-loader**：打包jsx、js文件，转化成浏览器认识的格式，因该loader配置选项较多，一般单抽取出独立的文件`.bebelrc`，放在项目根目录，webpack可以自动识别到\n- **css-loader**，**style-loader**：打包css、style文件\n- **html-loader**：打包html文件\n- **file-loader**：打包其他格式文件，如配置中所写\n\n**.babelrc 内容如下：**\n```json\n{\n  \"presets\": [\"@babel/preset-react\", \"@babel/preset-env\"], // 支持的编码\n  \"plugins\": [\n    \"@babel/plugin-transform-runtime\"\n  ]\n}\n```\n其中，所有的loader、plugin，都需要手动安装\n```shell\n$ npm install -D babel-core babel-loader css-loader style-loader html-loader file-loader\n\n$ npm install -D @babel/preset-env @babel/preset-react @babel/plugin-transform-runtime html-webpack-plugin\n```\n2. 配置 package.json，使用webpack/webpack.config.js。修改 package.json 中的`scripts` 节点，如下：\n```json\n\"dev\": \"webpack-dev-server --config webpack/webpack.config.js\"\n```\n此时，在项目根目录下执行该命令，即可。\n\n```sh\n$ npm run dev\n```\n\n#### 五、配置 webpack 打包配置\n和 server 类似，这里直接贴上配置文件\n1. **webpack/webpack.config.build.js**\n\n```js\nconst path = require('path');\nconst webpack = require('webpack');\nconst __repo = path.dirname(__dirname);\nconst HtmlWebpackPlugin = require('html-webpack-plugin')\n\nmodule.exports = {\n    mode: \"production\",\n    entry: path.resolve(__repo, 'src/index.jsx'),\n    devtool: \"#source-map\",\n    output: {\n        path: path.resolve(__repo, \"dist\"),\n        filename: \"app/[name].bundle.js\",\n        publicPath: \"/\"\n    },\n    module: {\n        rules: [\n            {\n                test: /(\\.jsx|\\.js)$/, // 匹配所护理文件的扩展名正则表达式\n                exclude: /(node_modules|bower_components)/, // 手动添加／屏蔽的文件\n                use: {\n                    loader: 'babel-loader', // loader名称\n                }\n            },\n            {\n                test: /\\.(css|styl)$/,\n                use: [\n                    {\n                        loader: 'style-loader'\n                    },\n                    {\n                        loader: 'css-loader'\n                    }\n                ]\n            },\n            {\n                test: /\\.html$/,\n                use: [\n                    {loader: 'html-loader'}\n                ]\n            },\n            {\n                test: /\\.(gif|jpg|png|svg|ttf|eot|woff|woff2)$/,\n                use : {\n                    loader: 'file-loader?name=fonts/[name].[ext]'\n                }\n            },\n        ]\n    },\n\n    plugins: [\n        new HtmlWebpackPlugin({\n            filename: 'index.html',\n            template: 'public/index.html'\n        })\n    ]\n};\n```\n2. 修改`package.json`中的scripts节点，如下\n\n```json\n\"build\": \"webpack --config webpack/webpack.config.build.js\"\n```\n执行打包命令后，所有文件会输出到项目根目录下的`dist`中。\n```sh\n$ npm run build\n```\n打包后的文件，配合`nginx`就可以访问请求了。\n","tags":["React","Webpack"],"categories":["React"]},{"title":"RHEL(Red Hat Enterprise Linux) 安装 zip、unzip","url":"/2019/11/4ae565dbddd3/","content":"\n> 多数的系统镜像文件中都是包含这两个命令，但总有意外。\n<!--more--> \n- 一般方法\n```sh\n$ sudo yum install zip unzip\n```\n- 如果一般方法报错，这个是安装unzip\n```sh\n$ sudo rpm -ivh https://rpmfind.net/linux/mageia/distrib/cauldron/x86_64/media/core/release/unzip-6.1c-6.mga8.x86_64.rpm\n```\n\n##### 其他版本的系统，链接从这里找 -> [点一下呗](https://rpmfind.net/linux/rpm2html/search.php?query=unzip)\n","tags":["Linux"],"categories":["Linux"]},{"title":"yum 安装最新版本 mysql","url":"/2019/11/fda8ed989b0e/","content":"---\n\n#### 一. 先到官网查询最新的版本，[官网地址](https://dev.mysql.com/downloads/repo/yum/)\n注意选择自己Linux对应的版本，查询方式：\n<!--more--> \n```shell\n$ cat /etc/*-release\nNAME=\"Red Hat Enterprise Linux Server\"\nVERSION=\"7.7 (Maipo)\"\n......\n\n$ uname -m\nx86_64\n```\n根据以上信息，选择所需版本的 rpm 名称，如图\n![](https://i.loli.net/2021/07/07/JsqNMBWZcmKpEXu.png)\n#### 二. 安装、启动\n1. 下载 rpm 文件。可以在网页上点 Download，然后在传送到服务器，也可以直接在服务器上下载，如下，替换链接后面部分即可：\n\t```sh\n\t$ wget http://repo.mysql.com/mysql80-community-release-el7-3.noarch.rpm\n\t```\n2. 导入 yum repo。\n\t```sh\n\t$ sudo rpm -ivh mysql80-community-release-el7-3.noarch.rpm\n\t```\n3. 安装\n\t```sh\n\t$ sudo yum install mysql-server\n\t```\n4. 启动\n\t```sh\n\t$ sudo systemctl start mysqld.service\n\t```\n\n#### 三. 连接、密码\n1. 连接\n\t```sh\n\t$ mysql -u root -p\n\t```\n2. 如果需要密码，去 `/var/log/mysqld.log`里面找，格式类似如下，`5Vgr6>Go.Azi`即是\n\t```sh\n\t2019-11-25T08:46:57.138469Z 5 [Note] [MY-010454] [Server] A temporary password is generated for root@localhost: 5Vgr6>Go.Azi\n\t```\n3. 登陆成功之后，如果提示用`ALTER USER`修改密码，如下\n\t```sh\n\tmysql> alter user 'root'@'localhost' identified by 'new_password';\n\t```\n4. 如果提示密码不合格，查看一下当前密码要求，如下，length表示密码最小长度，mixed_case_count表示大小写字母混合数量，number_count表示数字数量，special_char_count表示特殊字符数量\n\t```sh\n\tmysql> show variables like 'validate_password%';\n\t+--------------------------------------+--------+\n\t| Variable_name                        | Value  |\n\t+--------------------------------------+--------+\n\t| validate_password.check_user_name    | ON     |\n\t| validate_password.dictionary_file    |        |\n\t| validate_password.length             | 6      |\n\t| validate_password.mixed_case_count   | 1      |\n\t| validate_password.number_count       | 1      |\n\t| validate_password.policy             | MEDIUM |\n\t| validate_password.special_char_count | 0      |\n\t+--------------------------------------+--------+\n\t7 rows in set (0.00 sec)\n\t```\n5. 如果想设置个简单好记的密码，修改一下密码检查，exit退出mysql，再连接登陆后生效\n\t```sh\n\tmysql> set global validate_password.mixed_case_count=0;\n\tmysql> set global validate_password.special_char_count=0;\n\t```","tags":["Linux","mysql","yum"],"categories":["Linux"]},{"title":"nginx路由匹配","url":"/2019/11/6e1530768100/","content":"\n几种匹配模式，今天涉及到了，在此记录。\n<!--more--> \n1. =\n精确匹配\n2. ^~\n精确前缀匹配\n3. ~\n正则匹配（大小写敏感）\n4. ~*\n正则匹配（大小写不敏感）\n5. /uri\n普通前缀匹配\n6. /\n通用匹配\n","tags":["nginx"],"categories":["nginx"]},{"title":"nginx 转发错误 13 permission denied","url":"/2019/11/5e5a9e36111c/","content":"---\n\n今天在做 nginx 转发的时候，总是权限的错误：\n<!--more-->\n```shell\n2019/11/23 14:22:28 [crit] 19986#19986: *1 connect() to 127.0.0.1:5050 failed (13: Permission denied) while connecting\n```\n\n从网上翻了翻，大多数文章都在说修改 nginx 用户，而且这些文章的内容还都是一样的，这让着急解决问题的我很恼火....不知道是一个人写完在各个地方发了一遍，还是别的什么，我没无聊到查这些... -_-#\n\n修改 nginx 配置文件，`/etc/nginx/nginx.conf`，改成 root\n```shell\nuser root\n```\n\n然后用 root 权限 restart nginx 服务\n```shell\n$ sudo systemctl restart nginx\n```\n\n一般到这就结束了，但是却还没解决我的问题，权限问题依然在。又在网上一番找，原来是 linux 给拦截了，暂时关掉就可以了 [链接](https://www.cnblogs.com/songxingzhu/p/10063043.html)\n```sh\n$ setenforce 0                  ##设置SELinux 成为permissive模式\n```\n","tags":["nginx"],"categories":["nginx"]},{"title":"ELK 单机部署，多 beat 节点","url":"/2019/11/c712d783ad18/","content":"\n[参考文章](https://www.cnblogs.com/sparkdev/p/10554076.html)\n\n适用场景：多个项目或服务，独立部署，各个服务有自己的 log 文件。为便于查看、过滤等，可单机部署 ELK 服务后，各个服务通过 filebeat 服务将 log 发送至 ELK 机器。\n<!--more--> \n![](https://i.loli.net/2021/07/07/rNvnGcQ4SyhpZlf.png)\n\n#### 一、安装 java\n```sh\n$ sudo yum install java\n\n$ java -version\nopenjdk version \"11.0.5\" 2019-10-15 LTS\nOpenJDK Runtime Environment Corretto-11.0.5.10.1 (build 11.0.5+10-LTS)\nOpenJDK 64-Bit Server VM Corretto-11.0.5.10.1 (build 11.0.5+10-LTS, mixed mode)\n```\n\n> 对于 elasticsearch、logstash 和 kibana，**Elastic.co** 都提供了多种环境的安装方式，这里只介绍通过 RPM 的方式，其他环境可参考[官网文档](https://www.elastic.co/guide/index.html)。\n#### 二、安装 elasticsearch \n1. 下载安装公钥。\n\t```sh\n$ rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch\n\t```\n2. 增加 yum 源。在 `/etc/yum.repos.d/` 创建文件 `elasticsearch.repo` 并写入以下内容:\n\t```sh\n[elasticsearch-7.x]\nname=Elasticsearch repository for 7.x packages\nbaseurl=https://artifacts.elastic.co/packages/7.x/yum\ngpgcheck=1\ngpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch\nenabled=1\nautorefresh=1\ntype=rpm-md\n\t```\n3. 安装、启动\n    ```sh\n$ sudo yum install elasticsearch\n\n$ sudo systemctl daemon-reload\n\n$ sudo systemctl enable elasticsearch.service\n Created symlink from /etc/systemd/system/multi-user.target.wants/elasticsearch.service to /usr/lib/systemd/system/elasticsearch.service.\n\n$ sudo systemctl start elasticsearch.service\n\n$ sudo systemctl | grep elasticsearch\n elasticsearch.service   loaded active running   Elasticsearch\n    ```\n    **注意**：elasticsearch 基于 java，默认占用的最小内存是 1G，如果机器内存不够启动时会报错 `Not enough space`，将 `/etc/elasticsearch/jvm.options` 中的 `-Xms` 和 `-Xmx` 改小后重试即可。\n\n\n#### 三、安装 logstash\n1. 下载安装公钥。如果上面执行过，可跳过。\n\t```sh\n$ rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch\n\t```\n2. 增加 yum 源。在 `/etc/yum.repos.d/` 创建文件 `logstash.repo` 并写入以下内容:\n\t```sh\n[logstash-7.x]\nname=Elastic repository for 7.x packages\nbaseurl=https://artifacts.elastic.co/packages/7.x/yum\ngpgcheck=1\ngpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch\nenabled=1\nautorefresh=1\ntype=rpm-md\n\t```\n3. 安装\n\t```sh\n$ sudo yum install logstash\n\t\n$ sudo systemctl daemon-reload\n\t\n$ sudo systemctl enable logstash.service\n Created symlink from /etc/systemd/system/multi-user.target.wants/logstash.service to /etc/systemd/system/logstash.service.\n\t```\n4. 配置。在 `/etc/logstash/conf.d/` 创建文件 `beat2es.conf`，并写入以下内容：\n\t```js\ninput {\n    beats{\n        port => 5044\n        ssl => false\n    }\n}\nfilter {\n    grok {\n        match => { \"message\" => \"%{TIMESTAMP_ISO8601:[@metadata][timestamp]} %{DATA:message\" }\n        overwrite => [ \"message\" ]\n    }\n    date {\n        match => [ \"[@metadata][timestamp]\" , \"yyyy-MM-dd HH:mm:ss,SSS\" ]\n    }\n}\noutput {\n    elasticsearch {\n        hosts => [\"localhost:9200\"]\n        index => \"%{[fields][appname]}-%{+YYYY.MM.dd}\"\n        sniffing => true\n    }\n}\n\t```\n5. 启动\n\t```sh\n$ sudo systemctl start logstash\n\t```\n\n#### 四、安装 kibana\n1. 下载安装公钥。如果上面执行过，可跳过。\n\t```sh\n$ rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch\n\t```\n2. 增加 yum 源。在 `/etc/yum.repos.d/` 创建文件 `kibana.repo` 并写入以下内容:\n\t```sh\n[kibana-7.x]\nname=Kibana repository for 7.x packages\nbaseurl=https://artifacts.elastic.co/packages/7.x/yum\ngpgcheck=1\ngpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch\nenabled=1\nautorefresh=1\ntype=rpm-md\n\t```\n3. 安装、启动\n\t```sh\n$ sudo yum install kibana\n\n$ sudo systemctl daemon-reload\n\n$ sudo systemctl enable kibana.service\nCreated symlink from /etc/systemd/system/multi-user.target.wants/kibana.service to /etc/systemd/system/kibana.service.\n\t\n$ sudo systemctl start kibana.service\n\t```\n\n###### 至此，ELK 服务已经部署完成。logstash 监听 5044 端口，所有发送到 5044 端口的内容都会传送至 elasticsearch，可通过 kibana 可视化搜索页面进行查询。\n###### kibana 默认部署在 locaohost:5601，为了增加安全性，需通过 nginx 为 kibana 设置用户登陆访问。\n###### 如果不需要安全性，可修改 `/etc/kibana/kibana.yml` 文件，将其中的 `server.host` 的值改为 `0.0.0.0` 后重启 kibana 服务，这样外网可直接通过该机器的 5601 端口访问 kibana 服务。\n\n#### 五、设置 kibana 登陆访问\n1. 添加 nginx 源\n\t```sh\n$ sudo rpm -ivh http://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpm\n\t```\n2. 安装 nginx\n\t```sh\n$ sudo yum install nginx\n\t```\n3. 配置 nginx。修改 `/etc/nginx/conf.d/default.conf` 中 `/` 路由的配置，如下：\n\t```sh\nlocation / {\n     auth_basic \"secret\";\n     auth_basic_user_file /etc/nginx/db/passwd.db;\n     proxy_pass http://localhost:5601;\n     proxy_set_header Host $host:5601;\n     proxy_set_header X-Real-IP $remote_addr;\n     proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n     proxy_set_header Via \"nginx\";\n  }\n\t```\n4. 安装 httpd\n\t```sh\n$ sudo yum install httpd\n\t```\n5. 设置用户。用户名：jack，密码：123456\n\t```sh\n$ sudo htpasswd -bc /etc/nginx/pwd.db jack 123456\n\t```\n6. 启动 nginx\n\t```sh\n$ sudo systemctl nginx.service\n\t```\n\n###### 至此，访问该机器的 80 端口，通过用户密码验证，即可访问到 kibana 服务。\n\n#### 六、安装 filebeat\n> filebeat 服务可安装在任何有 log 文件的机器上，其实时监听 log 文件，并将内容发送至 logstash 服务。\n1. 下载 rpm 文件，并安装\n\t```sh\n$ curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.4.2-x86_64.rpm\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 22.7M  100 22.7M    0     0  24.8M      0 --:--:-- --:--:-- --:--:-- 24.8M\n\n$ sudo rpm -vi filebeat-7.4.2-x86_64.rpm\nPreparing packages...\nfilebeat-7.4.2-1.x86_64\n\n$ filebeat version\nfilebeat version 7.4.2 (amd64), libbeat 7.4.2 [15075156388b44390301f070960fd8aeac1c9712built 2019-10-28 19:46:13 +0000 UTC]\n\t```\n2. 配置。配置文件按模块分为了几部分，如 Filebeat inputs、Filebeat modules、Outputs等，在这里只需关心两个模块，一是 Filebeat inputs，另个为 Outputs。\nFilebeat inputs 用来配置 Filebeat 服务所监听、读取的文件，以及读取时的一些选项，这里的文件，即为 log 文件。\n\n\t```\n\t   enabled: true 表示开启\n\t\n\t   paths: 指定 log 文件的路径\n\t\n\t   fields: 配置元数据，appname 为必填项，用来区分不同项目\n\t\n\t   multiline.pattern: 正则表达式\n\t\n\t   multiline.negate: 是否反向。true 表示匹配 multiline.pattern 时开始新的一行；false 表示不匹配时开始新的一行\n\t\n\t   multiline.match: 连接的位置。after 表示不匹配 multiline.pattern 时连在上一句后面；before 表示连在下一句前面\n\t\n\t   这 3 项用来设置多行识别，'^[0-9]{4}-[0-9]{2}-[0-9]{2}' 是识别，行首格式为 YYYY-MM-DD 的日期，即每当行首为该格式的日期时，如 2019-11-15，都会重新开始一行。\n\t```\n   \n   Outputs 用来配置读取到的内容，如何输出。配置里缺省的输出方向是 Elasticsearch，这里需要切换为 Logstash。Logstash 的 SSL 目前尚未开启，因此只需配置 hosts 即可。\n\n\t```\nhosts: [\"{host}:5044\"]，logstash 服务所在的主机地址\n\t```\n\n   如无特殊需求，修改下面内容中的 `paths` 和 `appname` 以及 `hosts`，替换原 filebeat.yml 文件内容，即可。\n\n\t```sh\n\t   #=========================== Filebeat inputs =============================\n\t \n\tfilebeat.inputs:\n\t \n\t- type: log\n\t  enabled: true\n\t  paths:\n\t    - /var/log/app.log\n\t  fields:\n\t    appname: {your-app-name}\n\t  multiline.pattern: '^[0-9]{4}-[0-9]{2}-[0-9]{2}'\n\t  multiline.negate: true\n\t  multiline.match: after\n\t \n\t#============================= Filebeat modules ===============================\n\t \n\tfilebeat.config.modules:\n\t  # Glob pattern for configuration loading\n\t  path: ${path.config}/modules.d/*.yml\n\t \n\t  # Set to true to enable config reloading\n\t  reload.enabled: false\n\t \n\t#==================== Elasticsearch template setting ==========================\n\t \n\tsetup.template.settings:\n\t  index.number_of_shards: 1\n\t  #index.codec: best_compression\n\t  #_source.enabled: false\n\t \n\t#================================ Outputs =====================================\n\t \n\t#----------------------------- Logstash output --------------------------------\n\toutput.logstash:\n\t  # The Logstash hosts\n\t  hosts: [\"{host}:5044\"]\n\t \n\t  # Optional SSL. By default is off.\n\t  # List of root certificates for HTTPS server verifications\n\t  #ssl.certificate_authorities: [\"/etc/pki/root/ca.pem\"]\n\t \n\t  # Certificate for SSL client authentication\n\t  #ssl.certificate: \"/etc/pki/client/cert.pem\"\n\t \n\t  # Client Certificate Key\n\t  #ssl.key: \"/etc/pki/client/cert.key\"\n\t \n\t#================================ Processors =====================================\n\t \n\tprocessors:\n\t  - add_host_metadata: ~\n\t  - add_cloud_metadata: ~\n\t ```\n3. 启动\n\t```sh\n\t$ sudo systemctl enable filebeat.service\n\t\n\t$ sudo systemctl start filebeat.service\n\t```","tags":["ELK","Linux"],"categories":["ELK"]},{"title":"Elastic Beanstalk (EB) 引入 CloudWatch Log 服务","url":"/2019/11/95ca4e5703e9/","content":"\n- 原因\n 现所有 EB 环境服务的 log，均以文件的形式，存储在 EB 机器本地。当机器因各种问题（包含但不限于 bug ），造成无法远程访问时，无法读取其上的 log 来定位问题。故引入 AWS 的 CloudWatch Log 服务。\n\n<!--more-->\n\n- 原理\n CloudWatch Log 是一项服务。功能是，以接近实时的速度以流的方式读取、并存储文件。\n\n- 配置\n 1. 在项目根目录下创建名为`.ebextentions`的目录；\n 2. 在`.ebextentions`中新建文件`default.config`，扩展名必须为`.config`，文件名任意，合法即可；\n 3. 写入如下内容，部署时自动执行，具体见[AWS文档](https://docs.aws.amazon.com/zh_cn/elasticbeanstalk/latest/dg/ebextensions.html)\n```yaml\npackages:\n  yum:\n    awslogs: []\n\nfiles:\n  \"/etc/awslogs/awscli.conf\" :\n    mode: \"000600\"\n    owner: root\n    group: root\n    content: |\n      [plugins]\n      cwlogs = cwlogs\n      [default]\n      region = `{\"Ref\":\"AWS::Region\"}`\n\n  \"/etc/awslogs/awslogs.conf\" :\n    mode: \"000600\"\n    owner: root\n    group: root\n    content: |\n      [general]\n      state_file = /var/lib/awslogs/agent-state\n\n  \"/etc/awslogs/config/logs.conf\" :\n    mode: \"000600\"\n    owner: root\n    group: root\n    content: |\n      [/var/log/automation/app.log]\n      log_group_name = `{\"Fn::Join\":[\"/\", [\"/aws/elasticbeanstalk\", { \"Ref\":\"AWSEBEnvironmentName\" }, \"var/log/automation/app.log\"]]}`\n      log_stream_name = {instance_id}\n      file = /var/log/automation/app.log\n\ncommands:\n  \"1_init_log_dir\":\n      cwd: /var/log/\n      command: |\n        mkdir automation\n        chmod 775 automation\n        chgrp wsgi automation\n        chown wsgi automation\n      ignoreErrors: true\n  \"2_check_awslogs\":\n    command: chkconfig awslogs on\n  \"3_reload_awslogs\":\n    command: service awslogs restart\n```\n\n- 说明\n配置文件中使用了 3 个键，**packages**、**files** 和 **commands**。具体说明可见AWS文档。\n 1. **packages**\n - 使用 yum 安装 CloudWatch Log 服务，**awslogs**。\n \n 2. **files**：写入 awslogs 的配置文件，其中前两个 **awscli.conf** 和 **awslogs.conf** 在此不需要关心，只需关注第 3 个 **logs.conf**。\n - **log_group_name:** 在 CloudWatch Log 中显示的 **group** 的名称，对应下图中红色框；\n - **log_stream_name:** 在 CloudWatch Log 中显示的 **stream** 的名称，对应下图中蓝色框；\n - **file:** 该数据流所关联的文件的绝对路径\n ![](https://i.loli.net/2021/08/02/F7rtfBhgzmG6iLW.png)\n \n 3. **commands**\n 为便于查看和管理，统一将log放到了路径 `/var/log/` 下，并每个独立程序使用一个目录，这里使用automation说明。在 2 中，参数 **file** 使用的值是 `/var/log/automation/app.log`，所以在启动前需先创建 **automation** 目录。\n  - **1_init_log_dir：** 创建目录并修改权限，EB环境中，程序的默认执行用户是 wsgi；\n  - **2_check_awslogs：** 更新 awslogs 服务；\n  - **3_reload_awslogs：** 重启 awslogs 服务。\n\n- 使用\n将配置文件 **default.config** 中 **logs.conf** 的 **log_group_name**、**log_stream_name**和**file**以及 **1_init_log_dir** 替换为对应项目信息即可，在 **CloudWatch Log** 中可根据 **group_name** 和 **stream_name** 查找 **log**。\n\n- 扩展\n如有需要，可同时创建多个流，修改 **logs.conf** 即可，格式参考如下\n```yaml\n\"/etc/awslogs/config/logs.conf\" :\n    mode: \"000600\"\n    owner: root\n    group: root\n    content: |\n      [/var/log/messages]\n      log_group_name = `{\"Fn::Join\":[\"/\", [\"/aws/elasticbeanstalk\", { \"Ref\":\"AWSEBEnvironmentName\" }, \"var/log/messages\"]]}`\n      log_stream_name = {instance_id}\n      file = /var/log/messages\n\n      [/var/log/dmesg]\n      log_group_name = `{\"Fn::Join\":[\"/\", [\"/aws/elasticbeanstalk\", { \"Ref\":\"AWSEBEnvironmentName\" }, \"var/log/dmesg\"]]}`\n      log_stream_name = {instance_id}\n      file = /var/log/dmesg\n\n      [/var/log/automation/app.log]\n      log_group_name = `{\"Fn::Join\":[\"/\", [\"/aws/elasticbeanstalk\", { \"Ref\":\"AWSEBEnvironmentName\" }, \"var/log/automation/app.log\"]]}`\n      log_stream_name = {instance_id}\n      file = /var/log/automation/app.log\n```\n","tags":["AWS","CloudWatch Log"],"categories":["AWS"]},{"title":"保持ssh远程连接不断开","url":"/2019/09/ced3db1f808e/","content":"\n通过`ssh user@server`登陆到远程服务器时，经常会遇到一个问题，\n\n```sh\nConnection closed by remote host\n```\n意思就是服务器断开了这个连接。\n<!--more--> \n##### 解决方法\n\n```sh\n// 先登录到远程服务器\n$ ssh -i ./ssh/authorization.pem {root}@{server}\n\n// 切换到root\n$ sudo su -\n\n// 修改配置文件\n# vi /etc/ssh/sshd_config\n\n// 将其中的两行\n#ClientAliveInterval 0\n#ClientAliveCountMax 3\n// 修改为\nClientAliveInterval 2\nClientAliveCountMax 3\n// :wq 保存，并退出\n\n// 重启ssh服务\n# /etc/init.d/sshd restart\nStopping sshd:                                             [  OK  ]\nStarting sshd:                                             [  OK  ]\n```\n\n断开当前ssh连接，重新登录，问题解决。","tags":["Linux","ssh"],"categories":["Linux"]},{"title":"在AWS Lambda中使用psycopg2连接Redshift","url":"/2019/09/6df5f8cca1a9/","content":"\n- 环境：MacOS 10.12.6\n\n开始说正题。\n\nRedshift是基于PostgreSQL的二次开发应用，所以，能连接PostgreSQL的工具都可以用来连接Redshift。我选择的是使用最广泛的`psycopg2`。\n<!--more--> \n如果上来就执行:\n```sh\n$ pip install psycopg2\n```\n你会看到下面的提示错误：\n\n```sh\nError: pg_config executable not found.\n    \n    pg_config is required to build psycopg2 from source.  Please add the directory\n    containing pg_config to the $PATH or specify the full executable path with the\n    option:\n    \n        python setup.py build_ext --pg-config /path/to/pg_config build ...\n    \n    or with the pg_config option in 'setup.cfg'.\n    \n    If you prefer to avoid building psycopg2 from source, please install the PyPI\n    'psycopg2-binary' package instead.\n    \n    For further information please check the 'doc/src/install.rst' file (also at\n    <http://initd.org/psycopg/docs/install.html>).\n    \n    ----------------------------------------\nERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\n```\n提示需要一个叫做`pg_config`的东西。`pg_config`是个编译PostgreSQL源码后得到的一个文件。所以想要通过这种方式安装`psycopg2`就需要手动去编译源码。\n\n如果懒得编译，人家已经替你想好了办法，正如提示里所言，\n\n```sh\n If you prefer to avoid building psycopg2 from source, please install the PyPI\n    'psycopg2-binary' package instead.\n```\n因此，通过下面命令安装删减版的`psycopg2`，\n\n```sh\n$ pip install psycopg2-binary\n```\n然后，在本机上就可以正常使用了。\n\n---\n\n**但是，Lambda不可以。不同于独立的机器，Lambda需要完整的依赖包才能执行。**\n\n在Github上搜到了[awslambda-psycopg2](https://github.com/jkehler/awslambda-psycopg2)，作者介绍说是专门解决在Lambda上使用`psycopg2`的。\n\n按照`README.md`的步骤，先编译PostgreSQL，再用生成的`pg_config`去编译`psycopg2`。但执行后总会报一个错误，\n\n```python\nNo module named 'psycopg2._psycopg'\n```\n看着[issue](https://github.com/jkehler/awslambda-psycopg2/issues/47)里面几个老外说来说去，也没说出个可行的解决方案。\n\n几番尝试下来，终究是填了坑。\n\n**其实是编译环境的问题，在什么环境下编译生成的依赖包，只能在该环境下使用。Lambda是在Linux机器上执行的，所以必须在Linux上进行编译，生成的依赖包才可以使用。**\n\n就是这么简单。\n\n![](https://i.loli.net/2021/07/07/IX1DjFi72OblPoG.png)\n","tags":["AWS Lambda","python"],"categories":["Python"]},{"title":"在Spark中加载Redshift数据问题汇总","url":"/2019/09/e4951d749391/","content":"\n#### 1. java.sql.SQLException: No suitable driver\n这个错误是因为，连接Redshift时需要一个driver，而程序执行时找不到能用的driver，所以报错。AWS提供了多个版本连接Redshift的driver，[**点击查看**](https://docs.aws.amazon.com/zh_cn/redshift/latest/mgmt/configure-jdbc-connection.html#download-jdbc-driver)。\n<!--more--> \n#### 2. java.lang.NoClassDefFoundError: com/amazonaws/services/kinesis/model/Record\n经过几次尝试发现，直接使用AWS提供的驱动可以连上Redshift，打印出表结构，但是不能加载数据，一加载数据会报这个奇怪的错误，表结构都可以打印出来，为什么不能加载数据呢？我想不通。几番查询，找到了一个包装库，[**github地址**](https://github.com/databricks/spark-redshift#python)。\n\n#### 3. java.lang.IllegalArgumentException: AWS Access Key ID and Secret Access Key must be specified as the username or password (respectively) of a s3n URL, or by setting the fs.s3n.awsAccessKeyId or fs.s3n.awsSecretAccessKey properties (respectively).\n按照2里面的github库里的文档说明配置好后，可能会报这个错。因为spark-redshift用到了S3，所以要配置key和secret才可以。文档里也提供了[**几种方式**](https://github.com/databricks/spark-redshift#configuration)，i、ii和iii，开始我选择的是第三种方式，直接写在了URI里面。\n\n#### 4. java.lang.NoClassDefFoundError: com/eclipsesource/json/Json\n紧接着，配置好aws的key和secret，可能会遇到这个错误。这个错误一眼看上去感觉奇怪，为什么会报json的错误呢？在[**spark-redshift的issue**](https://github.com/databricks/spark-redshift/issues/279)里面找到了遇到同样问题的人，最下面**arvindkanda**提供了解决方案，启动时提供一个额外的jar包就可以了。\n\n\n#### 5. java.sql.SQLException: [Amazon](500310) Invalid operation: S3ServiceException:The S3 bucket addressed by the query is in a different region from this cluster.\n这个问题是说，S3和EMR必须在同一个region，不然Spark是读不到Redshift的数据的。我这里用的都是us-west-2，Oregon，俄勒冈。\n\n\n#### 6. com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.model.AmazonS3Exception: Bad Request (Service: Amazon S3; Status Code: 400; Error Code: 400 Bad Request; \n这个问题，就比较厉害了，卡了我好几个小时。网上各种方案都在说，因为签名版本的问题，所以访问S3时，必须指定S3的endpoint，查来的都是`s3a`的，[**比如这个**](https://stackoverflow.com/questions/34209196/amazon-s3a-returns-400-bad-request-with-spark)。但是因为spark-redshift里用的是`s3n`，我就将a替换成了n，但是这个问题还是在。各种方案不断尝试，可能是运气好，莫名的就试对了一种方式：将3里面的方式替换成ii，然后再配置`sc.hadoopConfiguration.set(\"fs.s3a.endpoint\", \"s3.us-west-2.amazonaws.com\")`，就可以了。\n\n#### 最终代码如下，\n\n```java\nspark = SparkSession.builder.getOrCreate()\nspark._jsc.hadoopConfiguration().set('fs.s3n.awsAccessKeyId', aws_access_key_id)\nspark._jsc.hadoopConfiguration().set('fs.s3n.awsSecretAccessKey', aws_secret_access_key)\nspark._jsc.hadoopConfiguration().set(\"fs.s3n.endpoint\", \"s3.us-west-2.amazonaws.com\")\n\nrsdf = spark.read\\\n        .format('com.databricks.spark.redshift')\\\n        .option('url', 'jdbc:redshift://host:port/schema')\\\n        .option('dbtable', 'table_name')\\\n        .option('user', 'username')\\\n        .option('password', 'password')\\\n        .option('tempdir', 's3n://bucket/dir')\\\n        .load()\n# 打印表结构\nrsdf.printSchema()\n# 打印表内容\nrsdf.show()\n```\n\n##### 关于spark启动命令参数，[**这篇文章**](https://blog.csdn.net/u012402124/article/details/99485901)已经说明过，这里就不再赘述。","tags":["AWS","Spark","Redshift"],"categories":["Spark"]},{"title":"「AWS」入门安装aws cli","url":"/2019/08/c35313b67e87/","content":"\n> cli，即Command Line Interface，是aws服务常用的命令工具\n<!--more--> \n[AWS官网地址](https://amazonaws-china.com/cn/cli/)\n\n- 环境：Python\n\n1. 安装\n\n安装起来只需要一条命令：\n```shell\n$ pip install awscli --user\n```\n \n执行完成之后，输入`aws`，输出如下，则说明安装成功了：\n```shell\n$ aws\nusage: aws [options] <command> <subcommand> [<subcommand> ...] [parameters]\nTo see help text, you can run:\n\n  aws help\n  aws <command> help\n  aws <command> <subcommand> help\naws: error: the following arguments are required: command\n```\n\n查看支持的命令，其中的`AVAILABLE SERVICES`便是支持的命令，内容过多，只罗列了部分\n```shell\n$ aws help\nNAME\n       aws -\n\nDESCRIPTION\n       The  AWS  Command  Line  Interface is a unified tool to manage your AWS\n       services.\n\nSYNOPSIS\n          aws [options] <command> <subcommand> [parameters]\n\n       Use aws command help for information on a  specific  command.  Use  aws\n       help  topics  to view a list of available help topics. The synopsis for\n       each command shows its parameters and their usage. Optional  parameters\n       are shown in square brackets.\nAVAILABLE SERVICES\n       o acm\n\n       o acm-pca\n\n       o alexaforbusiness\n\n       o amplify\n\n       o apigateway\n\n       o apigatewaymanagementapi\n\n       o apigatewayv2\n\n       o application-autoscaling\n\n       o appmesh\n\n       o appstream\n\n       o appsync\n\n       o athena\n\n       o autoscaling\n\n       o autoscaling-plans\n\n       o backup\n\n       o batch\n\n       o budgets\n\n       o ce\n\n       o chime\n\n       o cloud9\n\n       o clouddirectory\n\n       o cloudformation\n\n       o cloudfront\n\n       o cloudhsm\n\n       o cloudhsmv2\n\n       o cloudsearch\n\n```\n\n2. 配置\n\n其中有一个子命令`configure`，是用来配置aws cli的。aws cli访问的都是 aws 服务，而每个服务都是需要身份验证的，所以在使用之前，需要先配置身份信息。\n\n同样，先查看`configure`的说明：\n```shell\n$ aws configure help\nNAME\n       configure -\n\nDESCRIPTION\n       Configure  AWS  CLI  options. If this command is run with no arguments,\n       you will be prompted for configuration values such as your  AWS  Access\n       Key  Id  and you AWS Secret Access Key.  You can configure a named pro-\n       file using the --profile argument.  If your config file does not  exist\n       (the default location is ~/.aws/config), the AWS CLI will create it for\n       you.  To keep an existing value, hit enter when prompted for the value.\n       When  you  are prompted for information, the current value will be dis-\n       played in [brackets].  If the config item has no value, it be displayed\n       as  [None].  Note that the configure command only work with values from\n       the config file.  It does not use any configuration values  from  envi-\n       ronment variables or the IAM role.\n\n       Note:  the  values  you  provide  for the AWS Access Key ID and the AWS\n       Secret Access Key will  be  written  to  the  shared  credentials  file\n       (~/.aws/credentials).\n\nCONFIGURATION VARIABLES\n       The following configuration variables are supported in the config file:\n\n       o aws_access_key_id - The AWS access key part of your credentials\n\n       o aws_secret_access_key - The AWS secret access key part of  your  cre-\n         dentials\n\n       o aws_session_token  - The session token part of your credentials (ses-\n         sion tokens only)\n\n       o metadata_service_timeout - The number of seconds to  wait  until  the\n         metadata service request times out.  This is used if you are using an\n         IAM role to provide your credentials.\n\n       o metadata_service_num_attempts - The number  of  attempts  to  try  to\n         retrieve  credentials.   If you know for certain you will be using an\n         IAM role on an Amazon EC2 instance, you can set this value to  ensure\n         any intermittent failures are retried.  By default this value is 1.\n\n       For  more information on configuration options, see Configuring the AWS\n       Command Line Interface in the AWS CLI User Guide.\n\n       See 'aws help' for descriptions of global parameters.\n\n```\n\n其中有用的就是`CONFIGURATION VARIABLES`，一般需要两个参数，`aws_access_key_id`和`aws_secrct_access_key`，这两个参数登陆AWS后从IAM获取，下面是配置方法，`--profile`是给当前配置的身份起一个名字，这里起名叫`dev`：\n```shell\n$ aws configure --profile dev\nAWS Access Key ID [None]: \nAWS Secret Access Key [None]: \nDefault region name [None]: \nDefault output format [None]: \n```\n执行后会让你输入以上几项，`aws_access_key_id`和`aws_secrct_access_key`照常填写，后面几项可以不填，也可按需填写。\n\n这样，就配置完成了，使用`dev`这个身份，就可以访问aws的各种服务了。\n\n---\n\n**到这就算是入门了**","tags":["AWS","Python"],"categories":["AWS"]},{"title":"Golang 项目结构","url":"/2019/08/d923d0c927c5/","content":"\n>  好久没写 golang 的项目了，前两天接个临时需求，需求不难，但要求必须用golang来写。一时间竟然忘了如何开始，从哪入手了，故在此做个记录，以备不时之需。\n<!--more--> \n- 环境： MacOS\n- IDE：GoLand\n\n1. 项目路径\n    为了便于管理和引用其他 package，一般放在 `/{GOPATH}/src` 下。在该目录下，创建一个公司域名的文件夹，在此文件夹下创建项目命名的文件夹，如`/{GOPATH}/src/domain.com/project_name/`。\n\n2. 项目结构\n```\n  project_name/\n    |__bin/\n    |__build/\n    |__config/\n    |__cmd/\n    |  |__service_1/\n    |     |__service_1.go\n    |  |__service_2/\n    |     |__service_2.go\n    |__docs/\n    |__Godep/\n    |__pkg/\n    |    |__lib/\n    |    |__...\n    |    |__...\n    |__resource/\n    |__vendor/\n```\n- bin/：编译后的二进制文件\n- build/：编译、构建脚本文件\n- config/：配置文件，json/yaml等\n- cmd/：所有服务\n- cmd/service_1/：某个具体的服务\n- cmd/service_1/service_1.go：服务入口\n- docs/：文档\n- Godep/：godep 自动生成的目录\n- pkg/：主要代码\n- resource/：资源\n- vendor/：godep 自动生成的目录\n\n3. `godep`\n    包依赖管理工具，使每个项目的依赖的版本相互独立。在项目根目录下执行`godep save ./cmd`，自动生成 Godep 和 vendor。\n\n\n**大致，就这些。**","tags":["Golang"],"categories":["Golang"]},{"title":"AWS EMR 上运行 Spark + Kinesis: NoSuchMethodError: org.apache.spark.internal.Logging","url":"/2019/08/bb99d69df7f6/","content":"\n> 如题，因有需求，这两天在弄这个Spark，用的是AWS的EMR，具体是什么就不解释了。上面这个问题卡了很久，故在此记录一下。\n<!--more--> \n- Spark支持多种语言，如Scala、Java、Python、R，我用的是Python。\n\n官方有个叫WordCount的Example，我没看，直接照着文档撸代码。[Spark文档地址](https://spark.apache.org/docs/latest/streaming-kinesis-integration.html)\n\n\n初始化代码很简单，如下：\n\n```python \n# main.py\nfrom pyspark import SparkContext\nfrom pyspark.streaming import StreamingContext\nfrom pyspark.streaming.kinesis import KinesisUtils, InitialPositionInStream\n\naws_access_key_id = 'your-aws-access-key-id'\naws_secret_access_key = 'your-aws-secret-access-key'\n\nif __name__ == '__main__':\n    sc = SparkContext('local[*]', 'first_test0809')\n    ssc = StreamingContext(sc, 1)\n    kinesis_stream = KinesisUtils.createStream(\n        ssc,\n        'ssc_kinesis',\n        'kinesistest',\n        'https://kinesis.us-west-2.amazonaws.com',\n        'region-name',\n        InitialPositionInStream.TRIM_HORIZON,\n        2,\n        awsAccessKeyId=aws_access_key_id,\n        awsSecretKey=aws_secret_access_key\n    )\n\n    kinesis_stream.pprint(500)\n\n    ssc.start()\n    ssc.awaitTermination()\n```\n\n`kinesistest`是我创建的一个kinesis streaming，会有源源不断的数据写到这个streaming里，Spark负责处理这个streaming里的数据。\n\n接下来就是将这个文件部署到EMR上，依然是照着文档来操作。[文档地址](https://docs.aws.amazon.com/zh_cn/emr/latest/ReleaseGuide/emr-spark-submit-step.html)\n\n不得不说，AWS的文档既简约又简单，却不明了，在这个文档的指引下，没有一次我是顺利走通的。\n\n添加Step的命令：\n\n```shell\naws emr add-steps --cluster-id j-2AXXXXXXGAPLF --steps Type=Spark,Name=\"Spark Program\",ActionOnFailure=CONTINUE,Args=[--class,org.apache.spark.examples.SparkPi,/usr/lib/spark/lib/spark-examples.jar,10]\n```\n\n这个命令要分为两部分来看，前部分是AWS自身的命令`aws emr add-steps`，后部分就是`Args`这个参数的值。\n因为部署Spark程序实际上用的是`spark-submit`命令，而`Args`的值，都会传给`spark-submit`。\n\n前半部分比较简单，`cluster-id`就是在创建EMR集群后自动生成的id，这里需要注意的是，创建的EMR集群必须要设置共有IP，这样外部机器才能访问到。`Type`固定为Spark，`Name`自己随便写，`ActionOnFailure`一般都传CONTINUE，其他可选值可通过`aws emr add-steps help`查看。\n\n后半部分的`Args`的相关说明在[这里](https://github.com/apache/spark/blob/branch-1.3/core/src/main/scala/org/apache/spark/deploy/SparkSubmitArguments.scala#L454)，说的很详细。\n\n在部署运行之后，会报一些`ClassNotFound`的错误，这种错误不要紧，把缺的jar文件当作参数传上去就能解决问题。[Maven搜索地址1](https://mvnrepository.com/) | [Maven搜索地址2](https://search.maven.org/)\n\n上面的main.py用到了两个没有的jar文件，kinesisi和kcl，为了便于观看，使用了另一种格式，如下：\n\n```shell\n$ aws emr add-steps --cluster-id j-2AXXXXXXGAPLF --steps file://./step.json\n```\n\n将参数都抽取到一个josn文件中：\n```json\n[\n  {\n    \"Name\": \"Spark Program\",\n    \"Type\": \"Spark\",\n    \"ActionOnFailure\": \"CONTINUE\",\n    \"Args\": [\n      \"--master\",\n      \"local\",\n      \"--jars\",\n      \"local:///home/hadoop/spark-streaming-kinesis-asl_2.11-2.4.3.jar,local:///home/hadoop/amazon-kinesis-client-1.11.1.jar\",\n      \"local:///home/hadoop/main.py\"\n    ]\n  }\n]\n```\n\n注意，命令中所用到的所有文件，包括jar和py，都需要提前上传到机器上。具体上传方法见`aws emr put`命令\n\n至此，所有的工作基本完成，你以为这样就可以跑起来了吗？\nNO！\n\n最麻烦的问题，就是Spark版本的问题。之前用的最多、最稳定的就是1.6.5版本的，现在最新版已经2.4.3了，里面变动不小，尤其是`Logging`这个类，直接内部化了。\n\n仔细看会发现，上面的kinesis jar文件有两个版本号：2.11-2.4.3，后面的2.4.3是Spark大版本，前面的是什么我没查。在Maven里，这个版本最新的是2.12，所以最开始的时候我直接用了最新的，因为网上一直在强调的都是后面的2.4.3这个版本号，结果就出问题了，如题所写，总是报NoSuchMethodError。\n\n2.0之前的，Logging的位置是org.apache.spark.Logging，2.0之后变成了org.apache.spark.internal.Logging，但我用的都是最新版，为什么总说找不到呢？想了想，想了又想，试了各种办法，都行不通，这个过程持续了一天多，让人头大。\n\n后来不知是巧合，还是时候到了，偶然发现cluster机器上spark-core的版本号是2.11-2.4.3，报着尝试的心态从Maven下了2.11-2.4.3的kinesis jar文件，换上去一跑，哎，就这么成了。真是气人。\n\n所以说呢，有些时候解决问题是很简单的，困难的是发现问题。\n","tags":["AWS","EMR"],"categories":["Spark"]},{"title":"摸摸「浮点数」的底","url":"/2019/06/3754d5b7c490/","content":"\n> 摆理论和套公式其实也是为了说明问题，解释原理，不过有时却适得其反。\n\n\n\n前一个主题介绍了整数在计算机里的存储形式，浮点数，即小数，例如 3.14、2.71828 等，看起来和整数相近，而二者在计算机中存储的形式大为不同，作为一种常用的数据类型，来了解了解其中的本质，这个主题我们一起来摸摸「浮点数」的底。\n\n\n\n浮点数有多种类型，*但是我们写代码时常用到的有两种*，按照所占长度分为：一个是单精度，占用 32 个二进制位，另一个是双精度，占用 64 个二进制位。不管是什么类型、占用多少位，存储的**模式**都是类似的，而这也正是我们想要摸的「底」。\n\n\n\n##### 1. 化身为二进制的浮点数\n\n首先明确一点，不管什么类型的数据，整数也好，浮点数也罢，在计算机中都是以二进制形式存储，即 01001、10110 这样的形式。\n\n\n\n那么，二进制的浮点数该如何表示呢？\n\n\n\n在此之前，我们先来看下十进制的小数 22.71是如何表示的：**小数点左边第一位为个位，表示 1，第二位为十位，表示 10；小数点右边第一位为十分位，表示 1/10，即 10^<sup>-1</sup>，第二位为百分位，表示 1/100，即 10^<sup>-2</sup>，综合如下**。\n\n```java\n22.71 = 2*10^1 + 2*10^0 + 7*10^-1 + 1*10^-2\n      = 20 + 2 + 0.7 + 0.01\n      = 22.71\n```\n\n\n\n上面就是十进制浮点数的表示形式，而二进制与十进制整体相同，唯一区别就在于将 10 换成了 2，举个例子，如二进制浮点数 101.11：**小数点左边第一位表示 2^<sup>0</sup>，即 1，第二位表示 2^<sup>1</sup>，即 2，第三位表示2^<sup>2</sup>，即 4；小数点右边第一位表示 2^<sup>-1</sup>，即 0.5，第二位表示 2^<sup>-2</sup>，即 0.25，综合如下**。\n\n```java\n101.11 = 1*2^2 + 0*2^1 + 1*2^0 + 1*2^-1 + 1*2-2\n       = 4 + 0 + 1 + 0.5 + 0.25\n       = 5.75\n```\n\n\n\n##### 2. 自由转化的浮点数\n\n既然，浮点数既可以用十进制表示，也可以用二进制表示，那么同一个浮点数如何在这两种进制之间自由转化呢？由二进制转为十进制就不用说了，上面刚刚用 101.11 演示完，而由十进制转为二进制很多人都是直接套公式却没想过原理，接下来说说推导公式的过程。**这个转化过程需要将浮点数的整数部分和小数分别转化，之后再进行合并**。\n\n\n\n我们用 6.625 来举例说明。先看整数部分的 6，这个我们一眼就能看出来，结果是 110，但是如果换成 60、600，这些不能一眼看出的数呢？其实很多事情都是如此，将思考过程从「一眼就能看出的」的情况中抽象出来，就是计算方法。这个思考过程无非就是，想知道需要几个二进制位、每个二进制的值是多少，就可以表示 6。\n\n\n\n为了便于理解，我们先看一下计算表示 758 需要几个十进制位以及每位的值是多少。\n\n\n\n```java\n先从个位，即右起第一位开始:\n\n很显然，求个位的值用 758 对 10 取余即可：758 / 10 = 75···8，结果为 8，此时原数还剩下 75*10，大于 0，说明一位不够；\n\n继续求第二位的值：75*10 / 100 = 75 / 10 = 7···5，结果为 5，此时原数还剩下 7*100，大于 0，说明两位还是不够；\n\n继续求第三位的值：7*100 / 1000 = 7 / 10 = 0···7，结果为 7，此时原数还剩下 0*1000，等于 0，说明三位十进制够用了。\n\n最终结果，需要 3 个十进制位，从左到右的值分别是 7、5、8，即 758。\n\n同时我们发现的一个规律是：\n求第二位的值时，用计算完第一位的商对 10 取余即可，\n求第三位的值时，用计算完第二位的商对 10 取余即可。\n```\n\n**由此可得，求第 n 位的值时，用计算完 n-1 位的商对 10 取余数即可，当商为 0 时，结束，注意 n > 1。**如上，就是十进制抽取方法的过程，也同样适用于二进制，区别就在于将 10 换成了 2，实际计算一下。\n\n```java\n计算将 6 用二进制的值，同样从右起的第一位开始：\n\n先求第一位：6 / 2 = 3···0，结果为 0，原数还剩下 3*2^1，大于 0，说明一位不够；\n\n继续求第二位，3 / 2 = 1···1，结果为 1，原数还剩下 1*2^2，大于 0，说明两位不够；\n\n继续求第三位，1 / 2 = 0···1，结果为 1，原数还剩下 0*2^3，等于 0，说明三位二进制够了。\n\n最终结果，需要 3 个二进制位，从左到右的值分别是 1、1、0，即 110，而这也与我们直观上看到的结果相符。\n```\n\n\n\n与整数部分的计算类似，再看下小数部分的计算。同样，先用比较直观的十进制浮点数举例，从而从中总结规律。\n\n```java\n计算 0.358 用几位十进制的浮点数表示，及每位的值的过程，从左开始，\n\n先求第一位，注意，与整数不同的是，这里是取商，而不是余数：\n0.358 / 10^-1 = 0.358 * 10 = 3···0.58，结果是：3，原数还剩下：0.58*10^-1 > 0;\n继续求第二位，\n0.58*10^-1 / 10^-2 = 0.58 * 10 = 5···0.8，结果是：5，还剩下：0.8*10^-2 > 0;\n继续求第三位，\n0.8*10^-2 / 10^-3 = 0.8 * 10 = 8···0，结果是：8，还剩下：0，说明 3 位十进制够了。\n\n最终结果，需要 3 个十进制，从右向左分别是 3、5、8，即 0.358。\n\n同时，我们发现：\n求第二位时，用计算完第一位的余数乘 10 再取商即可，\n求第三位时，用计算完第二位的余数乘 10 再取商即可。\n```\n\n**由此可得，计算第 n 位时，用计算完第 n-1 位的余数乘 10 再取商即可，当余数等于 0 时结束，注意 n > 1。**紧接着，用我们从上面十进制例子中总结的方法计算下二进制。\n\n```java\n计算 6.625 的小数部分 0.625 的二进制形式，从左开始，\n\n先求第一位，0.625 * 2 = 1···0.25，结果是 1，原数还剩下：0.25*2^-1 > 0；\n继续求第二位，0.25 * 2 = 0···0.5，结果是 0，原数还剩下：0.5*2^-2 > 0；\n继续求第三位，0.5 * 2 = 1···0，结果是 1，原数还剩下：0，结束。\n\n最终结果，需要 3 个二进制位，从左向右分别是：1、0、1，即 0.101。\n```\n\n至此，我们完成了所有计算过程，整数部分：110，小数部分：101，最终结果为：110.101。\n\n\n\n##### 3. 如何存储\n\n前面做了那么多铺垫，现在终于可以开始说存储了。存储之前，需要先把二进制的浮点数用科学计数法表示，也称规范化，即 \n\n**N = ±a x 2^<sup>n</sup>** , a∈ **[1,2)**\n\n**a** 叫作尾数，**n** 叫作阶码。计算机存储的浮点数都是这种形式的，例如上面的 110.101 就需要变成 1.10101x2^<sup>2</sup>，而 0.1101 就需要变成 1.101x2^<sup>-1</sup>，这个变换的过程很简单。\n\n\n\n对于浮点数 **±a\\*2^<sup>n</sup>**，计算机将其分成了 3 个部分来进行存储，即存储正负的**符号位**、存储 n 的**指数域**和存储 a 的**尾数域**，是的，存储 a 的部分叫做**尾数域**。\n\n\n\n对于长度为 32 位二进制的浮点数，从左起，第 1 位用来表示符号，0 代表正数，1 代表负数。接下来的 8 位，即第 2 位到第 9 位，用来表示指数。而从第 10 位开始一直到最后的 32 位，都用来表示尾数，对于科学计数法下的 a，其整数部分的值永远都是 1，所以这个 1 就省略了，因此 23 位尾数二进制只存储了 a 的小数部分，即 1.10101 的 10101，1.101 的 101。\n\n\n\n和 32 位类似，长度为 64 位二进制的浮点数，从左起，第一位存储符号，接下来的 11 位存储指数，剩下的 52 位存储尾数，而尾数同样省略了 a 的整数部分，只存储小数部分。\n\n\n\n##### 4. 阶码\n\n符号位，0 或 1，尾数域，采用原码表示，这两种比较简单明了，这里要单独说一说阶码。\n\n\n\n在此之前，先回忆一下移码。所谓移码，实际上就是把负数映射到正轴上，通俗的说就是消灭负数。例如，4 个bit位能表示的范围，[-2^<sup>3</sup>, 2^<sup>3</sup> - 1]，即[-8, 7]。每个数字加上偏移量 2^<sup>3</sup>，即为移码。\n\n\n\n阶码在计算机中也是以移码的形式存储的，区别在于这个偏移量。**根据 IEEE 754 标准，k 位二进制位的解码，偏移量 bias 为 2^<sup>k-1</sup> - 1**，例如 32 位单精度浮点数，阶码为 8 位，则偏移量为 2^<sup>8-1</sup> - 1 = 127。\n\n\n\n**N = (-1)^<sup>S</sup> x 2^<sup>E-Bias</sup> x (1+M)**\n\n其中，**S为符号位的值，E为指数的值，M为尾数域的值，Bias为移码偏移量**。\n\n\n\n举个例子，-6.75，**单精度浮点数，转化为规范化二进制为：**-110.11 = -1.1011 x 2^<sup>2</sup>\n\n符号位 **S = 1**，\n\n阶码 **E = 2 + Bias = 2 + 127 = 129**\n\n尾数 **M = 1.1011 - 1 = 1011** (省去小数点)\n\n**1 10000001 10110000000000000000000** （尾数域：4 位精度 + 19 个 0，共 23 位）\n\n\n\n至此，浮点数就介绍完了。\n\n\n\n","tags":["编码","浮点数"],"categories":["编码"]},{"title":"「原码 反码 补码 移码」一探究竟（下）","url":"/2019/01/0a1eac4519fc/","content":"\n> 抛开复杂的理论，直探事物的本质。\n\n这是这个主题的第三篇文章，前两篇介绍了**这几种码的基本概念**，这篇文章来具体说说「移码」。\n<!--more-->\n**00. 回顾**\n\n先来回顾一下移码是什么，简单说定义就一句话：**将补码符号位取反，即为移码**。乍一看，是不是有点懵，这到底在说什么呢？什么是移码？为什么是这么算？它能干嘛用？莫急，这些问题一个一个都会解决。\n\n相比于移码，应该使用补码的几率更高一些。因为移码主要用在浮点数的阶码中，用的较少。注意，这里又出来了一个新名词，「阶码」，关于这块的内容比较乱，会单独写一篇文章来说。而现在只需要记住一句话，**移码的出现就是为了消灭负数**。\n\n<!--more--> \n\n**01. 如何「消灭」负数**\n\n\n先拿大家都熟悉的数轴举个例子。\n![](https://i.loli.net/2021/07/07/cdtpFeLJPyw9Txl.png)\n\n如图，数轴上一共有 5 个点，分别为 -2、-1、0、1、2，其中有 2 个负数，所谓消灭负数，就是用 5 个非负数来表示这 5 个点，方法就是**将 0 向左移动两个位置**，如下。\n![](https://i.loli.net/2021/07/07/HwXenQjWztJC2rY.png)\n\n很简单吧，这样一移动负数就被消灭了，而「**移码**」的计算就是这个道理，而**将 0 向左移动 2 个位置就等同于将所有数字加 2**，这个很好理解。很显然，**移动的位数就是表示范围内负数的个数。**\n\n**02. 为什么是补码符号位取反？**\n\n先明确一点：**因为移码都是非负数，不需要符号位，所以，所有的二进制位都是用来表示数据的。**\n\n接下来，根据上面得出的结论，我们亲自来算一算移码。为了便于计算，就拿 4 位二进制来举例。在计算机中，4 位二进制能表示的范围为 **[-2^3, 2^3-1] = [-8, 7]**，其中负数的个数为 -1 到 -8，共 **2^3** 个，也就是 8 个，所以需要将 0 向左移动 8 个位置，**即给每个数加上 8**，如下。\n\n```\n     补码   +8  移码\n-8  [1000]  0 [0000]\n-7  [1001]  1 [0001]\n-6  [1010]  2 [0010]\n-5  [1011]  3 [0011]\n-4  [1100]  4 [0100]\n-3  [1101]  5 [0101]\n-2  [1110]  6 [0110]\n-1  [1111]  7 [0111]\n 0  [0000]  8 [1000]\n 1  [0001]  9 [1001]\n 2  [0010] 10 [1010]\n 3  [0011] 11 [1011]\n 4  [0100] 12 [1100]\n 5  [0101] 13 [1101]\n 6  [0110] 14 [1110]\n 7  [0111] 15 [1111]\n```\n\n上面这样对比着看，应该很清晰了。经过计算得出的移码，刚好等于补码符号位取反，所以移码的定义就简化成了一句话：将补码符号位取反，即为移码。\n\n再说一个有点不好理解的方法，觉得啰嗦略过就好。除去首位的符号位不看，单看剩下的  3 位二进制，-8 到 -1 本身就符合从小到大的规律，而 0 到 7 也是如此，但 [0,7] 要大于  [-1,-8]，强转成无符号数，用符号位的 0 和 1 两个值便可以区分原本的 8 个负数和 8 个非负数，**最终就是将负数转化为了正数，将正数转化为了更大的正数**。\n\n**结束**\n\n至此，关于「**原码 反码 补码 移码**」主题的文章就告一段落了。\n\n段首写了这么一句话：「**抛开复杂的理论，直探事物的本质**」。我是这么理解这句话的，讲一样东西，只有把没什么基础的人都说明白了，说懂了，也不用过多的摆理论、套公式，这样才算是真的讲透彻了，话虽俗，理不俗。\n","tags":["编码"],"categories":["编码"]},{"title":"「原码 反码 补码 移码」一探究竟（中）","url":"/2019/01/76011953e8ea/","content":"---\n上文「原码 反码 补码 移码」一探究竟（上）说了基本定义和原码，对于补码，我们只知道是对原码符号位不变，其他位置取反，最后再加 1 得来的，为何如此呢？接下来咱们来揭下「补码」的面具，看看它到底是什么。\n\n<!--more--> \n\n**0. 关于 1 + (-1)**\n\n首先，先看一个问题。\n\n1 的原码为[0000 0001]，-1 的原码为[1000 0001]，所以计算这两个数相加，应该是这样的：\n\n```\n1 + (-1) \n\n= [0000 0001]原 + [1000 0001]原 \n\n= [1000 0010]原 \n\n= -2\n```\n\n结果竟然是 -2，很明显是错的，这样用原码计算就出问题了。当然，劳动人民的智慧不可估量，总能发现合适的方式来解决各种问题，于是，补码就诞生了，再看用补码计算的过程。\n\n```\n1 + (-1) \n\n= [0000 0001]原 + [1000 0001]原 \n\n= [0000 00001]补 + [1111 1111]补 \n\n= [0000 0000]补 \n\n= [0000 0000]原 \n\n= 0\n```\n\n结果正确，问题得以解决，而这也是计算机都是以补码的形式来存储整数的原因。\n\n但是，为什么用补码计算就能得到正确结果呢？为什么补码的计算方式是原码取反再加 1 呢？带着问题，我们继续往下看。\n\n\n**1. 钟表上的哲学**\n\n钟表，每个人应该都清楚的，上面的数字范围[0,11]，也可以理解为[1, 12]，毕竟上面没有写 0 这个数字，但是不变的是，都可以表示12个小时。\n\n比方说，现在是  9:00，时针指向9。我要想知道 7 个小时之前是几点，那么我只需要将时针向回拨动 7 个格子即可，结果很显然，时针将会指向 2，表示  2:00；但是，我要想知道 5 个小时后是几点呢？也很简单，将时针向前拨动 5 个格子，结果也很显然，时针也会指向 2，表示 2:00。\n\n通过不同方式，我们得到了同样的结果，**也就是说在钟表上，9 - 7 = 9 + 5 = 2**。不仅 7 和 5 有这样的规律，8 和 4、9 和 3等都有这样的规律，也就是说，相加等于 12 的两个数都符合这样的规律，即 **X - Y = X + (12 -Y)**，而 12 在这里有个名字，叫做这个钟表的**模**，12 - Y 叫做 Y 的**补数**。\n\n**减去一个数，等于加上这个数的补数，应用这个规律就可以将减法转换为加法了。**\n\n那么问题来了，模长该怎么求？\n\n\n**2. 通俗的「模」**\n\n通俗的讲，很简单。还是拿钟表举例，上面能表示的数字的总数就是其模长，所以不管是[0, 11]，还是[1, 12]，都为12。\n\n再来看 8 位二进制，其原码能表示的范围 (注意看，这里说的是原码)，**[1111 1111] ~ [0111 1111]**，即 **[-2^7 - 1, 2^7 - 1]** = **[-127, 127]**，因为我们是要将其全部转变为非负数，即能表示的范围为[0, 127]，所以模长为 128。\n\n说完了这些，我们再来重新看下 -3 的补码的计算过程。-3 原码为 **[1000 0011]**，而**取反的过程实际上等同于用[0111 1111]减去 -3 原码中的符号位之外的部分**，之后再加 1 即得到补码，所以：\n\n```\n-3 补码(未添加符号位)\n\n= [1000 0011]原 取反 + [0000 0001]\n\n= [0111 1111] - [0000 0011] + [0000 0001]\n \n= [0111 1111] + [0000 0001] - [0000 0011]\n \n= [1000 0000] - [0000 0011]\n\n= 128 - [0000 0011]\n\n= 模  - [0000 0011] \n\n= 模  - 3\n```\n\n看到这，是不是一下就明白了？**补码实际上就是模减去原码的值，再加上一个符号位，也就是所说的：符号位不变，取反再加1**。\n\n所以，在计算机中，整数都是以补码的形式存储的，是为了统一加减法运算。因为计算机之中是没有做减法的逻辑门，减法都会被转化为加法来完成计算。\n\n而通过溢出，符号位也可以直接参与计算，大大简化了计算过程，看个例子就明白了。\n\n```\n7 + （-3）\n\n= [0000 0111]原 + [1000 0011]原 \n\n= [0000 0111]补 + [1111 1101]补 \n\n= [0000 0100]补 (溢出部分不用处理)\n\n= [0000 0100]原 \n\n= 4 \n\n2 + （-3）\n\n= [0000 0010]原 + [1000 0011]原 \n\n= [0000 0010]补 + [1111 1101]补 \n\n= [1111 1111]补 \n\n= [1000 0001]原 \n\n= -1\n```\n\n再看个特例。\n\n```\n-1 + (-127) \n\n= [1000 0001]原 + [1111 1111]原 \n\n= [1111 1111]补 + [1000 0001]补 \n\n= [1000 0000]补 \n\n= -128\n```\n\n用原码能表示的最小负数为 **-127**，补码却能表示的最小负数为 **-128**，但是 **-128** 没有原码和反码表示，由于计算机中使用补码表示整数，所以这没有影响，因此 8 位二进制数，也就是 **byte** 类型能表示的范围是 **[-128, 127]**。\n\n说到这，对于补码，应该足够清晰了吧！","tags":["编码"],"categories":["编码"]},{"title":"「原码 反码 补码 移码」一探究竟（上）","url":"/2019/01/8ebb2c9120f0/","content":"\n> 抛开复杂的理论，直探事物的本质。\n\n**0. 二进制**\n\n相比于二进制，十进制数字大家都比较熟悉。从右往左依次是个位、十位、百位、千位等，每个位置上的数字范围 [0, 9]。个位上的 1 表示 1，十位上的 1 表示 10，百位上的 1 表示 100，即从右向左的第 n 位就代表 10^(n-1)：\n<!--more--> \n```\n761 = 7*100 + 6*10 + 1*1 = 7*10^2 + 6*10^1 + 1*10^0\n```\n\n而二进制，也是同样的道理，区别就是将 10 的 n-1 次幂变成了 2 的 n-1 次幂：\n\n```\n1101 = 1*2^3 + 1*2^2 + 0*2^1 + 1*2^0 = 8 + 4 + 0 + 1 = 13\n```\n\n有了这些基础概念，接着再来看下面的内容。\n\n**1.** **这些「码」都是什么？**\n\n**计算机中的数字一般分为两种，有符号数和无符号数。**\n\n**原码**，是一种计算机中对数字的二进制表示的方法。\n\n**有符号数**，即用最高位的二进制位来表示正负，剩下的位来存储数据。\n\n**无符号数**，即所有的二进制位都来表示数据，所以无符号数字无法表示负数，全部大于等于 0。\n\n光看定义干巴巴的，用长度为 8 位二进制的类型举几个例子。\n\n有符号数，最高位表示正负，0 表示正数，1 表示负数。\n\n```\n   7 : [0000 0111]原\n  -3 : [1000 0011]原\n-127 : [1111 1111]原\n```\n\n无符号数，没有符号位，全部二进制位用来表示数据。\n\n```\n  7 : [0000 0111]原 \n 16 : [0001 0000]原\n255 : [1111 1111]原\n```\n\n上面就是原码的定义，而反码、补码、移码都是在原码的基础上做了对应的变换。\n\n**反码**：正数的反码就是其原码，负数的反码为，符号位不变，其余位取反，即 0 变 1，1 变 0。\n\n**补码**：正数的补码就是其原码，负数的补码为在其反码的基础上再加 1，而在计算机中，整数都是以补码的形式存储的。\n\n**移码**：将补码符号位取反，即为移码。\n\n**这几种码都是针对有符号数，而无符号数用原码就足够了**，后面会对此说明原因。同样，也举几个例子说明。\n\n```\n 7 : [0000 0111]原 [0000 0111]反 [0000 0111]补 [1000 0111]移\n-3 : [1000 0011]原 [1111 1100]反 [1111 1101]补 [0111 1101]移\n```\n\n关于定义，就说这些。既然原码就能表示数字，那为什么又会有这么多类型的码呢？而这些不同的码又是怎么来的呢？计算机中为什么要以补码而不是其他码来存储整数呢？移码又是做什么的呢？鉴于篇幅过长，下篇文章，会对这些问题一一说明。\n","tags":["编码"],"categories":["编码"]},{"title":"Goland调整Terminal窗口字体大小","url":"/2018/12/44fb710f68f6/","content":"\nGoland的Ternimal窗口样式和Console窗口公用同一个样式，修改路径:\n> Setting->Editor->Color Scheme->Console Font\n\n若不生效，重启一下IDE即可。\n<!--more--> \n\n![](https://i.loli.net/2021/07/07/pkb8qoWm7RzV2ij.png)\n","tags":["GoLand"],"categories":["Golang"]},{"title":"Golang websocket client读取数据","url":"/2018/11/f0d738b44296/","content":"\nGolang 既可以写 websocket 的 server 端也可以写 websocket 的 client 端，前者网上的资料很多后者甚少，今天遇到写 client 的需求，在此做个总结。\n\n- 测试地址：火币网\n- websocket包：golang.org/x/net/websocket\n<!--more--> \n### 1. 建立连接。\n连接成功建立后，client 和 server 均可以随时往数据通道里写数据同时也可以从中读取数据。\n\n```golang\nvar wsurl = \"wss://api.huobi.pro/ws\"\nvar origin = \"http://api.huobi.pro/\"\nws, err := websocket.Dial(wsurl, \"\", origin)\nif err != nil {\n    panic(err)\n}\n```\n### 2. 写数据。\n在通道已建立的前提下，写数据操作通过一行代码即可完成：\n\n```golang\nfunc sendMessage(data []bytes) {\n\tws.Write(msg)\n}\n```\n### 3.1 读数据。\n最简单的方法是调用`func (ws *Conn) Read(msg []byte) (n int, err error)`方法，定义一个用来接收数据的`[]byte`数组当作参数传入，但是由于不知道server发来的数据长度，所以一般是定义一个足够大的字节`[]byte`数组，这样读取一来浪费内存二来处理起来麻烦，不建议使用；\n\n```golang\nfunc readMessage(ws *websocket.Conn) {\n\tdata := make([]byte, 1024*10)\n\t_, err := ws.Read(data)\n\tif err != nil {\n\t\tlog.Println(err)\n\t}\n}\n```\n### 3.2 读数据。\n对于都是以json方式传输的数据，websocket包提供了将每条message读取到一个`interface{}`中的方法，等同于`json.Unmarshal`。\n\n```golang\nfunc readJsonMessage(ws *websocket.Conn) {\n\tvar data interfact{} // data的类型为接收的JSON类型struct\n\terr := websocket.Message.Receive(ws, data)\n\tif err != nil {\n\t\tlog.Println(err)\n\t}\n}\n```\n### 3.3 读数据。\n3.2是将接收到的数据直接unmarshal到struct里了，而我的需求比这个要麻烦一点：server发来的数据`[]byte`数组是压缩过的，所以接收到数据后第一步应该解压缩然后才能unmarshal，所以不能再用3.2的方式，参照3.2的源码，实现方式如下。\n\n```golang\nfunc readOriginMessage(ws *websocket.Conn) {\n\tagain:\n\t\tfr, err := ws.NewFrameReader()\n\t\tif err != nil {\n\t\t\tlog.Printf(\"new frame reader err %v\", err)\n\t\t\treturn\n\t\t}\n\t\tframe, err := ws.HandleFrame(fr)\n\t\tif err != nil {\n\t\t\tlog.Printf(\"handle frame err %v\", err)\n\t\t\treturn\n\t\t}\n\t\tif frame == nil {\n\t\t\tgoto again\n\t\t}\n\t\t\n\t\tbytes, err := ioutil.ReadAll(frame)\n\t\tif err != nil {\n\t\t\tlog.Printf(\"read frame data err %v\", err)\n\t\t}\n\t\tunzipData, err := utils.UnzipByte(bytes)\n\t\tif err != nil {\n\t\t\tlog.Printf(\"unzip data err %v\", err)\n\t\t}\n\n\t\tvar message map[string]interface{}\n\t\te := json.Unmarshal(unzipData, &message)\n\t\tif e != nil {\n\t\t\tlog.Printf(\"unmarshal err %v\", e)\n\t\t}\n\t\t\n\t\tlog.Printf(\"message content= %+v\", message)\n}\n```","tags":["Goland","websocket"],"categories":["Golang"]},{"title":"Android WebView加载URL不显示图片","url":"/2018/10/ab916a013a16/","content":"---\n偶然遇到的一个问题\n<!--more--> \n```java\n        WebSettings settings = mWebView.getSettings();\n        settings.setJavaScriptEnabled(true);//启用js\n        settings.setBlockNetworkImage(false);//解决图片不显示\n        if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.LOLLIPOP) {\n            settings.setMixedContentMode(WebSettings.MIXED_CONTENT_ALWAYS_ALLOW);\n        }\n```\n","tags":["Android","WebView"],"categories":["Android"]},{"title":"Program type already present: org.iq80.leveldb.CompressionType","url":"/2018/08/f07f2aa62201/","content":"---\n添加新依赖时遇到一个报错。\n<!--more--> \n今天在Android Studio添加了一个新的依赖：\n```\nimplementation (\"org.ethereum:ethereumj-core:$ethereumj_version\")\n```\n然后`Sync`可以通过，但是`Rebuild`报错如标题，往上搜了几个方法都未奏效，最后只好顺着问题找答案。\n\n报错的内容就是说`CompressionType`重复了，换句话说，添加的新依赖不添加这个即可。双击`Shift`全局搜索`CompressionType`定位，如图：\n![](https://i.loli.net/2021/07/07/nOSFvNhZ4BTgCmE.png)\n\n添加依赖时增加：\n\n```\n implementation (\"org.ethereum:ethereumj-core:$ethereumj_version\") {\n        exclude group: 'org.iq80.leveldb', module: 'leveldb-api'\n    }\n```\n`Sync`通过，`Rebuild`又报新错误：\n\n```\nMore than one file was found with OS independent path 'META-INF/spring.tooling'\n```\n在`android`节点增加配置：\n\n```\nandroid {\n\tpackagingOptions {\n        pickFirst 'META-INF/*'\n    }\n}\n```\n继续`Sync`，通过；`Rebuild`，通过。\n\n问题解决。","tags":["Android","Gradle"],"categories":["Android"]},{"title":"[翻译]种子词","url":"/2018/08/a8ab36581124/","content":"\n> 原文地址：https://en.bitcoin.it/wiki/Seed_phrase\n\n### 种子短语\n种子短语、种子恢复短语或备用种子短语是存储恢复比特币钱包所需的所有信息的单词列表。钱包软件通常会生成一个种子短语并指示用户将其写在纸上。如果用户的电脑坏了或者他们的硬盘坏了，他们可以再次下载相同的钱包软件，使用纸质备份来取回他们的比特币。\n<!--more--> \n任何发现这个短语的人都可以偷比特币，所以比特币必须保存的像珠宝或现金一样安全。例如，它不能被键入任何网站。\n\n种子短语是备份和存储比特币的好方法，因此几乎所有受好评的钱包都使用它们\n\n#### 举例\n种子短语的一个例子是:\n```\nwitch collapse practice feed shame open despair creek road again ice least\n```\n单词的顺序是很重要的。\n\n#### 解释\n关于种子短语如何工作的一个简单的解释是，钱包软件有一个从字典中提取的单词列表，每个单词被分配给一个数字。种子短语可以转换为一个数字，该数字用作种子整数，以生成钱包中使用的所有密钥对的确定性钱包。\n\nBIP39标准2048字的英文词库,如果这个词只包含12个随机的单词,可能的组合的数量将是2048 ^ 12 = 2 ^ 132，并且短语有132位安全性。但是，BIP39短语中的一些数据不是随机的，所以12个单词的BIP39种子短语的实际安全性只有128位。这与所有比特币私钥的强度大致相同，因此大多数专家认为它足够安全。\n\n发明你自己的种子短语并不安全，因为人类不善于产生随机性。最好的方法是让钱包软件生成你写下的短语。\n\n#### 双重种子短语\n种子短语和所有备份一样，可以存储任意数量的比特币。这是一个令人担忧的想法，可能有足够购买整个建筑的钱，却只是写在一张纸上而没有任何保护。由于这个原因，许多钱包使得用密码加密种子短语成为可能。\n\n密码可用于创建一个双因素种子短语，其中需要“你拥有的东西”和“你知道的东西”才能解锁比特币。\n\n它的工作原理是钱包创建一个种子短语并向用户询问密码。然后需要种子短语和额外的单词，才能恢复钱包。Electrum和其他一些钱包把密码短语叫做“种子扩展”，“扩展词”或者“第13 /25个单词”。BIP39标准定义了一种保护种子短语的方法。在Electrum标准中也使用了类似的方案。如果没有密码，则使用空字符串“”。\n\n警告:忘记这个密码将导致比特币钱包和任何钱包里包含的钱丢失。不要高估你记住密码的能力，尤其是当你可能不经常使用密码的时候。\n\n警告:种子短语密码不应该与用于加密磁盘上钱包文件的密码混淆。这可能就是为什么许多钱包称它为扩展词而不是密码。\n\n#### 诱骗的钱包\n这个功能还提供了貌似合理的可否认性，因为每个密码都会生成一个有效的钱包，但只有正确的密码才会让你想要的钱包可用。您可以创建一个具有相同种子短语但不同密码的诱骗钱包，如果身体上被迫，那么只显示第一个密码，并将第二个密码保密。\n\n另一方面，强迫你的实体可能已经知道诱骗钱包的概念。他们可以继续打你，直到你放弃两三个密码。\n\n关于这个问题的更长的讨论，请参见存储比特币# 5美元扳手攻击\n\n#### 长期储存种子短语\n大多数人在纸上写下短语，但也可以用许多其他的方式来存储，比如记忆、雕刻金属、在书页空白处写字、刻石碑或任何其他有创意的方式。\n\n用铅笔在纸上书写要比用钢笔书写好得多。纸张应无酸味或档案纸，存放在黑暗中，避免高温和潮湿。\n\n有些人想把他们的短语分开。在一个地方储存6个单词，在另一个地方储存6个单词。这是一个糟糕的想法，不应该这样做，因为如果一组6个单词被发现，那么就更容易对剩下的短语进行暴力攻击。像这样在多个地方存储比特币应该通过多签名钱包来实现。\n\n另一个坏主意是添加一些对你有意义的随机假词，然后把它们删除，只留下12个单词短语。这个短语来自于一本已知的字典(见下一节)，所以任何人都可以用那本字典来除去假词。\n\n在同一张纸上写一些解释的词，这可能是个好主意。如果长期储存，你可能会忘记一个短语应该如何处理。可以加以修改的示例解释是:\n\n    这十二个字控制着比特币。保管好这张纸，像现金或珠宝一样保密。本文中的比特币信息用密码加密。它是一个多  签名钱包的一部分，是在2012年1月1日由电子比特币钱包软件制作的。\n\n#### 单词列表\n一般来说，种子短语只适用于创建它的相同的钱包软件。如果储存的时间很长，最好也写上钱包的名字。\n\nBIP39英语单词表中，每个单词都由前四个字母唯一地识别出来，这在空间有限的情况下是很有用的。\n\n#### 替代的名字“助记词”\n种子短语有时被称为“助记短语”，特别是在古老的文学作品中。这是一个不好的名字，因为单词助记意味着这个短语应该被记住。把它们叫做种子短语没有那么误导人。","tags":["区块链"],"categories":["区块链"]},{"title":"[翻译]比特币确定性钱包","url":"/2018/08/97037d409735/","content":"\n> 原文地址：https://en.bitcoin.it/wiki/Deterministic_wallet\n<!--more--> \n\n### 确定性钱包\n确定性钱包是一种系统，从一个被称为种子的单一起点获取密钥。种子允许用户在不需要任何其他信息的情况下轻松备份和恢复钱包，在某些情况下，用户可以在不知道私钥的情况下创建公共地址。种子通常被串行化为人类可读的字词。\n\n#### 好处\n早期的客户端，如Satoshi客户端，会生成一个新的随机私钥缓冲区，在将来用作接收和更改地址。在短时间内耗尽密钥池缓冲区(通常是100个地址)后，这将使备份失效。确定性钱包可以在动态中产生无限数量的地址，因此不会受到这个问题的影响。由于地址是以一种已知的方式生成的，而不是随机生成的，一些客户端可以在多个设备上使用，而不会造成资金损失。用户可以方便地以人类可读的格式创建种子的单个备份，这种格式将持续钱包的使用寿命，而不必担心这种备份会变得过时。\n特定类型的确定性钱包(BIP0032, Armory, Coinkite和Coinb)额外允许完全分离私有和公共密钥的创建，以获得更大的安全性和方便性。在这个模型中，服务器可以设置为只知道特定确定性钱包的主公钥。这允许服务器创建尽可能多的公钥来接收资金，但是MPK协议不会允许攻击者从钱包中花钱。它们也可以在Electrum和Armory中使用，以实现完全离线存储和花费，离线计算机知道私钥，而在线的计算机只知道MPK。通过USB存储器，两种计算机之间可以通过USB存储器进行交易，避免将离线计算机暴露给基于网络的攻击。\n由硬件钱包(TREZOR)实现的确定性钱包将生成的私钥保持离线状态，即使花钱时也不将它们暴露给计算机。\n\n#### 类型\n#### 类型1 确定性钱包\n类型1确定性钱包是一种从已知的起始字符串生成地址的简单方法，因此它不允许高级功能，如主公钥。要生成一个私钥，需要使用SHA256(string + n)，其中n是一个ascii编码的数字，它从1开始，并随着需要额外的键而增加。\n这种类型的钱包可以由Casascius比特币地址实用程序创建。\n#### 类型2 分层确定性钱包\n这种钱包类型在bip0032中进行了描述，并在TREZOR、Electrum和CarbonWallet中得到了充分的实现。种子是一个随机的128位值，用户可以使用常用的英语单词作为12个单词的种子短语。该种子在10万轮SHA256之后使用，以减缓对弱用户选择字符串的攻击。\n这种钱包类型的最初描述和工作原理都归功于格雷戈里·麦克斯韦。\n#### Armory确定性钱包\nArmory有自己基于“根键”和“链码”的2型确定性钱包格式。早期版本的Armory需要备份“根键”和“链码”，而较新的版本则以不可逆转的方式从私钥派生链码。这些新的Armory(0.89+)只需要一个256位的根键。这种旧格式打算逐步淘汰，以支持标准BIP0032格式。","tags":["区块链","Bitcoin"],"categories":["区块链"]},{"title":"[翻译]Bitcoin Address介绍","url":"/2018/08/6dcc04b57a51/","content":"\n> 原文地址: https://en.bitcoin.it/wiki/Address\n<!--more--> \n## 地址\n\n一个比特币地址或是一个简单地址，是一个26-35个字母或数字组成的标识符，以数字1或3开头，这代表了比特币支付的可能目的地。任何比特币的使用者不需要任何话费便可以生成地址。例如使用Bitcoin Core客户端，点击“New Address“就会被分配一个地址。通过一个交易所账号或者在线钱包服务来获得比特币地址也是可能的。目前正被使用中的地址有3种格式：\n 1. P2PKH类型，以数字`1`开头，例如：`1BvBMSEYstWetqTFn5Au4m4GFg7xJaNVN2`.\n 2. P2SH类型，以数字`3`开头，例如：`3J98t1WpEZ73CNmQviecrnyiWrnqRhWNLy`.\n 3. Bech32类型，以`bc1`开头，例如：`bc1qar0srrr7xfkvy5l643lydnw9re59gtzzwf5mdq`.\n\n\n#### 比特币地址是一个一次性的令牌\n就像e-mail地址，你可以通过向一个人比特币地址中的一个地址发送比特币来实现给这个人发送比特币。然而，和e-mail地址不同的是，一个人可以拥有很多比特币地址，每一次交易应该使用一个唯一的地址。大多数比特币软件和网站都会帮助你在每次创建发票或付款请求时生成一个全新的地址。\n\n#### 地址可以离线创建\n创建地址无需互联网连接，也不需要与比特币网络进行任何联系或注册。可以使用免费的软件工具创建大量离线地址。生成大量地址在几个场景很有用，比如电子商务网站，为每个选择“用比特币支付”选项的客户提供一个唯一的预先生成的地址。较新的“HD钱包”可以生成一个“种子”令牌，可以用来让不受信任的系统(如webservers)生成无限数量的地址，而无需花费接收到的比特币。\n\n#### 地址通常是区分大小写和准确的\n旧式的比特币地址是大小写敏感的。比特币的地址应该尽可能地使用电脑的剪贴板复制和粘贴。如果你手工键入一个比特币地址，而每个字符都没有被准确地转录(包括大写)，那么不正确的地址很可能会被比特币软件拒绝。你必须检查你的条目，然后再试一次。一个输入错误的地址被接受为有效的概率是1 / 232，也就是大约1 / 42.9亿。新型bech32地址不区分大小写。\n\n#### 证明你收到了一个地址\n大多数比特币钱包都有一个“签名”信息的功能，这可以证明接收资金的实体已经同意该信息。例如，这可以用于在支付合同之前，以一种加密的可验证的方式确定合同。\n有些服务还将利用这种功能，只指定一个特定的地址进行身份验证，在这种情况下，该地址永远不应该用于实际的比特币交易。当您登录或使用他们的服务时，您将提供一个签名，证明您与预先商定的地址相同。\n值得注意的是，这些签名仅仅证明一个人收到了一个地址。由于比特币交易没有“来自”地址，你无法证明你是资金的发送者。\n目前的消息签名标准仅与“0版本”的比特币地址(以数字1开头)兼容。\n\n#### 地址验证\n如果希望在应用程序中验证比特币地址，建议使用[这个线程中](https://bitcointalk.org/index.php?topic=1026.0)的方法，而不是只检查字符串长度、允许的字符，或者地址以1或3开头。验证还可以使用[各种语言](http://rosettacode.org/wiki/Bitcoin/address_validation)的开放源代码或使用[在线验证工具](http://lenschulwitz.com/base58)进行。\n\n#### 多重签名的地址\n可以创建需要多个私钥组合的地址。由于它们利用了较新的特性，所以它们以较新的前缀3而不是旧的1开始。这可以被看作是向两方开出支票——“支付给某人和其他人的订单”——双方必须在支票上签字以获得资金。\n必须满足的实际需求(所需的私钥数量、相应的公钥等)是由生成此类地址的人预先决定的，一旦创建了地址，就不能在不生成新地址的情况下更改该需求。\n\n#### 一个地址里有什么\n大多数比特币的地址是34个字符。它们由随机数字、大写字母和小写字母组成，除了大写字母“O”、大写字母“I”、小写字母“l”和数字“0”从未使用来避免视觉上的歧义。\n一些比特币地址可以短于34个字符(少到26个字符)，但仍然有效。相当大比例的比特币地址只有33个字符，有些甚至可能更短。每个比特币地址代表一个数字。这些较短的地址是有效的，因为它们代表的是恰好以0开头的数字，当这些0被省略时，编码的地址就会变短。\n比特币地址中有几个字符被用作校验和，因此可以自动查找和拒绝排版错误。校验和还允许比特币软件确认一个33个字符(或更短)的地址实际上是有效的，而不是一个缺少字符的地址。\n\n#### 测试网络\n比特币Testnet上的地址是用不同的地址版本生成的，这会产生不同的前缀。有关详细信息，请参阅地址前缀和Testnet列表。\n\n### 误解\n\n#### 地址重用\n地址不打算被使用多次，这样做有许多相关的问题。有关地址重用的详细信息，请参阅专门的文章。\n\n#### 地址余额\n地址不是钱包或账户，也没有余额。他们只收钱，而你在任何时候都不发送“从”地址。各种混乱的服务和软件显示'用一个地址接收比特币',从随机不相关的交易中减去已发送的比特币作为一个'地址余额',但这个数字是没有意义的:它并不意味着向这个地址发送的比特币的接收者已经花掉了它们，也不意味着他们仍然持有接收的比特币。\n这种误解造成比特币损失的一个例子是，人们认为他们的地址包含3btc。他们花了0.5比特币，认为地址现在包含2.5比特币，而实际上它包含零比特币。剩余的2.5比特币被转移到一个没有备份的更改地址，因此丢失。这发生在一些使用纸质钱包的用户的场合。\n\n#### “从“地址\n比特币交易没有任何来源——来源——或“来自”地址。有关“来自地址”的详细信息，请参阅专门的文章。\n\n#### 地址图\n[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-S43U7xMP-1625627005514)(https://en.bitcoin.it/w/images/en/4/48/Address_map.jpg)]\n","tags":["区块链","Bitcoin"],"categories":["区块链"]},{"title":"Linux服务器常用命令","url":"/2018/07/6e2872c17d01/","content":"我常用到的是这几个：\n<!--more--> \n### systemctl\n- systemctl status name.service\n   查看某个服务的状态\n- systemctl | grep name-partern\n   过滤显示所有服务名符合name-partern的服务\n- systemctl enable name.service\n   设置开机自启\n- systemctl restart name.service\n  重启服务\n\n### journalctl\n- journalctl -f -u unit-name\n  实时查看某个服务的log\n- journalctl --since 18:34 --until 19:12 -u unit-name\n  查看某个服务在该时间段内的log\n- journactl --since '2018-07-29 19:00' --until now -u unit-name\n  查看时间段内的日志\n\n### grep\n- grep -E 'regex'\n  根据正则表达式过滤\n- grep -w 'wrod'\n  根据单词word过滤\n- grep -c 'target'\n  显示过滤后的行数\n\n### tail\n- tail -n 2000 file.name\n  显示文件末尾的2000行内容\n- tail -f file.name\n  实时显示文件最新追加的内容\n- tail -s 1\n  显示内容刷新时间间隔为1秒\n\n### ls\n- ls -l\n  以列表形式显示\n- ls -a\n  显示所有文件\n- ls -h\n  以便于阅读的方式显示\n- ls -S\n  按照文件大小排序\n\n### vi\n- :set nu\n  显示行号\n- :set nonu\n  隐藏行号\n- 0\n  移动光标到行首\n- $\n  移动光标到行尾\n- gg\n  移动光标到内容开头\n- G\n  移动光标到内容结束\n- dd\n  删除行\n- x\n  删除一个字符\n- r\n  替换一个字符\n- R\n  一直替换\n- u\n  撤销上次操作\n- 10 j\n  向下移动光标10行\n- /c[ok]\\\\{1\\\\}mplete\n  查找complete\n","tags":["Linux"],"categories":["Linux"]},{"title":"持续集成与自动化测试 Continuous Integration，CI","url":"/2018/05/262671d24b2e/","content":"\n> 所谓持续集成与自动化，是指用机器替代人工持续不间断地集成代码，让产品可以快速迭代，同时还能保证代码质量。一个完整的持续集成环境需要Jenkins与Git、Gerrit一起配合，才能发挥出它最强大的功能。一般来说，在开发者Push代码后会首先到Gerrit进行代码Review。Review分为两部分，一部分是使用程序的自动化Review，主要是通过静态代码检测工具来进行代码质量分析（比如Sonar、CheckStyle、FindBugs等）；另一部分是人工Review，主要检测代码的运行逻辑，当Review完毕后，通过Git hook、Jenkins完成代码的自动拉取、编译和部署，最后通过自动化测试工具完成测试用例，并生成相应的测试报表。这样一整个测试流程需要人工来做的也就是人工代码Review部分，而其他部分全部通过自动化来实现，甚至可以在半夜对程序进行不间断Monkey测试，测试稳定性和潜在问题。\n<!--more--> \n**摘自《Android群英传：神兵利器》**","tags":["Android","CI"],"categories":["Android"]},{"title":"Java继承机制的弊端","url":"/2018/05/d71d19b7fe7b/","content":"\n转载，原文链接:http://www.sunxin.org/forum/thread/20672.html# \n\n为什么Java中继承多数是有害的 \n<!--more--> \n大多数好的设计者象躲避瘟疫一样来避免使用实现继承(`extends` 关系)。实际上80%的代码应该完全用`interface`写,而不是通过`extends`。Java设计模式一书详细阐述了怎样用接口继承代替实现继承。这篇文章描述设计者为什么会这么作。 \n\n`Extends`是有害的;也许对于*Charles Manson*这个级别的不是,但是足够糟糕的它应该在任何可能的时候被避开。JAVA设计模式一书花了很大的部分讨论用`interface`继承代替实现继承。 \n\n好的设计者在他的代码中,大部分用`interface`,而不是具体的基类。本文讨论为什么设计者会这样选择,并且也介绍一些基于`interface`的编程基础。 \n\n- 接口(`Interface`)和类(`Class`)? \n\n一次,我参加一个Java用户组的会议。在会议中,*Jams Gosling*(Java之父)做发起人讲话。在那令人难忘的Q&A部分中,有人问他:如果你重新构造Java,你想改变什么?。我想抛弃classes他回答。在笑声平息后,它解释说,真正的问题不是由于class本身,而是实现继承(`extends`) 关系。接口继承(`implements`关系)是更好的。你应该尽可能的避免实现继承。 \n\n- 失去了灵活性 \n\n为什么你应该避免实现继承呢?第一个问题是明确的使用具体类名将你固定到特定的实现,给底层的改变增加了不必要的困难。 \n\n在当前的敏捷编程方法中,核心是并行的设计和开发的概念。在你详细设计程序前,你开始编程。这个技术不同于传统方法的形式----传统的方式是设计应该在编码开始前完成----但是许多成功的项目已经证明你能够更快速的开发高质量代码,相对于传统的按部就班的方法。但是在并行开发的核心是主张灵活性。你不得不以某一种方式写你的代码以至于最新发现的需求能够尽可能没有痛苦的合并到已有的代码中。 \n\n胜于实现你也许需要的特征,你只需实现你明确需要的特征,而且适度的对变化的包容。如果你没有这种灵活,并行的开发,那简直不可能。 \n\n对于`Inteface`的编程是灵活结构的核心。为了说明为什么,让我们看一下当使用它们的时候,会发生什么。考虑下面的代码: \n```Java\nf() { \n\tLinkedList list = new LinkedList(); \n\tg(list); \n} \ng(LinkedList list) { \n\tlist.add( ... ); \n\tg2(list) ;\n} \n```\n假设一个对于快速查询的需求被提出,以至于这个`LinkedList`不能够解决。你需要用`HashSet`来代替它。在已有代码中,变化不能够局部化,因为你不仅仅需要修改`f()`也需要修改`g()`(它带有`LinkedList`参数),并且还有`g()`把列表传递给的任何代码。像下面这样重写代码: \n```Java\nf() { \n\tCollection list = new LinkedList(); \n\tg(list); \n} \ng(Collection list) { \n\tlist.add(...); \n\tg2(list);\n} \n```\n这样修改Linked list成hash,可能只是简单的用new HashSet()代替new LinkedList()。就这样。没有其他的需要修改的地方。 \n\n作为另一个例子,比较下面两段代码: \n```Java\nf() { \n\tCollection c = new HashSet(); \n\t//... \n\tg( c ); \n} \ng(Collection c) { \n\tfor(Iterator i = c.iterator(); i.hasNext()) \n\t\tdo_something_with(i.next()); \n} \nf2() { \n\tCollection c = new HashSet(); \n\t//... \n\tg2( c.iterator() ); \n} \ng2(Iterator i) { \n\twhile(i.hasNext()) \n\t\tdo_something_with(i.next()); \n} \n```\n\n`g2()`方法现在能够遍历`Collection`的派生,就像你能够从`Map`中得到的键值对。事实上,你能够写`iterator`,它产生数据,代替遍历一个`Collection`。你能够写`iterator`,它从测试的框架或者文件中得到信息。这会有巨大的灵活性。 \n\n- 耦合 \n\n对于实现继承,一个更加关键的问题是耦合---令人烦躁的依赖,就是那种程序的一部分对于另一部分的依赖。全局变量提供经典的例子,证明为什么强耦合会引起麻烦。例如,如果你改变全局变量的类型,那么所有用到这个变量的函数也许都被影响,所以所有这些代码都要被检查,变更和重新测试。而且,所有用到这个变量的函数通过这个变量相互耦合。也就是,如果一个变量值在难以使用的时候被改变,一个函数也许就不正确的影响了另一个函数的行为。这个问题显著的隐藏于多线程的程序。 \n\n作为一个设计者,你应该努力最小化耦合关系。你不能一并消除耦合,因为从一个类的对象到另一个类的对象的方法调用是一个松耦合的形式。你不可能有一个程序,它没有任何的耦合。然而,你能够通过遵守OO规则,最小化一定的耦合(最重要的是,一个对象的实现应该完全隐藏于使用他的对象)。例如,一个对象的实例变量(不是常量的成员域),应该总是`private`。我意思是某段时期的,无例外的,不断的。(你能够偶尔有效地使用`protected`方法,但是`protected`实例变量是可憎的事)同样的原因你应该不用get/set函数---他们对于是一个域公用只是使人感到过于复杂的方式(尽管返回修饰的对象而不是基本类型值的访问函数是在某些情况下是由原因的,那种情况下,返回的对象类是一个在设计时的关键抽象)。 \n\n这里,我不是书生气。在我自己的工作中,我发现一个直接的相互关系在我OO方法的严格之间,快速代码开发和容易的代码实现。无论什么时候我违反中心的OO原则,如实现隐藏,我结果重写那个代码(一般因为代码是不可调试的)。我没有时间重写代码,所以我遵循那些规则。我关心的完全实用?我对干净的原因没有兴趣。 \n\n- 脆弱的基类问题 \n\n现在,让我们应用耦合的概念到继承。在一个用`extends`的继承实现系统中,派生类是非常紧密的和基类耦合,当且这种紧密的连接是不期望的。设计者已经应用了绰号脆弱的基类问题去描述这个行为。基础类被认为是脆弱的是,因为你在看起来安全的情况下修改基类,但是当从派生类继承时,新的行为也许引起派生类出现功能紊乱。你不能通过简单的在隔离下检查基类的方法来分辨基类的变化是安全的;而是你也必须看(和测试)所有派生类。而且,你必须检查所有的代码,它们也用在基类和派生类对象中,因为这个代码也许被新的行为所打破。一个对于基础类的简单变化可能导致整个程序不可操作。 \n\n让我们一起检查脆弱的基类和基类耦合的问题。下面的类`extends`了Java的`ArrayList`类去使它像一个`stack`来运转: \n```Java\nclass Stack extends ArrayList { \n\tprivate int stack_pointer = 0; \n\tpublic void push( Object article ) { \n\t\tadd( stack_pointer++, article ); \n\t} \n\tpublic Object pop() { \n\t\treturn remove( --stack_pointer ); \n\t} \n\tpublic void push_many( Object[] articles ) { \n\t\tfor( int i = 0; i < articles.length; ++i ) \n\t\t\tpush( articles[i] ); \n\t} \n} \n```\n甚至一个象这样简单的类也有问题。思考当一个用户平衡继承和用`ArrayList`的`clear()`方法去弹出堆栈时: \n```java\nStack a_stack = new Stack(); \na_stack.push(\"1\"); \na_stack.push(\"2\"); \na_stack.clear(); \n```\n这个代码成功编译,但是因为基类不知道关于`stack`指针堆栈的情况,这个`stack`对象当前在一个未定义的状态。下一个对于`push()`调用把新的项放入索引2的位置。(`stack_pointer`的当前值),所以`stack`有效地有三个元素-下边两个是垃圾。(Java的stack类正是有这个问题,不要用它). \n\n对这个令人讨厌的继承的方法问题的解决办法是为`Stack`覆盖所有的`ArrayList`方法,那能够修改数组的状态,所以覆盖正确的操作`Stack`指针或者抛出一个例外。(`removeRange()`方法对于抛出一个例外一个好的候选方法)。 \n\n这个方法有两个缺点。第一,如果你覆盖了所有的东西,这个基类应该真正的是一个`interface`,而不是一个`class`。如果你不用任何继承方法,在实现继承中就没有这一点。第二,更重要的是,你不能够让一个`stack`支持所有的`ArrayList`方法。例如,令人烦恼的`removeRange()`没有什么作用。唯一实现无用方法的合理的途径是使它抛出一个例外,因为它应该永远不被调用。这个方法有效的把编译错误成为运行错误。不好的方法是,如果方法只是不被定义,编译器会输出一个方法未找到的错误。如果方法存在,但是抛出一个例外,你只有在程序真正的运行时,你才能够发现调用错误。 \n\n对于这个基类问题的一个更好的解决办法是封装数据结构代替用继承。这是新的和改进的Stack的版本: \n```Java\nclass Stack { \n\tprivate int stack_pointer = 0; \n\tprivate ArrayList the_data = new ArrayList(); \n\tpublic void push( Object article ) { \n\t\tthe_data.add( stack_poniter++, article ); \n\t} \n\tpublic Object pop() { \n\t\treturn the_data.remove( --stack_pointer ); \n\t} \n\tpublic void push_many( Object[] articles ) { \n\t\tfor( int i = 0; i < o.length; ++i ) \n\t\t\tpush( articles[i] ); \n\t} \n} \n```\n到现在为止,一直都不错,但是考虑脆弱的基类问题,我们说你想要在`stack`创建一个变量, 用它在一段周期内跟踪最大的堆栈尺寸。一个可能的实现也许象下面这样: \n```Java\nclass Monitorable_stack extends Stack { \n\tprivate int high_water_mark = 0; \n\tprivate int current_size; \n\tpublic void push( Object article ) { \n\t\tif( ++current_size > high_water_mark ) \n\t\t\thigh_water_mark = current_size; \n\t\tsuper.push( article ); \n\t} \n\tpublish Object pop() { \n\t\t--current_size; \n\t\treturn super.pop(); \n\t} \n\tpublic int maximum_size_so_far() { \n\t\treturn high_water_mark; \n\t} \n} \n```\n这个新类运行的很好,至少是一段时间。不幸的是,这个代码发掘了一个事实,`push_many()`通过调用`push()`来运行。首先,这个细节看起来不是一个坏的选择。它简化了代码,并且你能够得到`push()`的派生类版本,甚至当`Monitorable_stack`通过Stack的参考来访问的时候,以至于`high_water_mark`能够正确的更新。 \n","tags":["Android","Java"],"categories":["Android"]},{"title":"Android使用netty框架配置SSL适配7.0以上的系统","url":"/2018/05/5483a3584872/","content":"\n最近项目在使用的netty框架加上了SSL安全设置，SSL可单项验证也可双向验证，我使用的是双向验证，即Client验证Server同时Server也验证Client。\n以下只说明Client（Android）端的实现方式。\n<!--more--> \n- 首先需要两个文件，`client.p12`和`cacert.pem`，由服务器端提供。\n- 使用java的`keytool`工具将`cacert.pem`导入到keystore中\n```shell\n$ keytool -import -trustcacerts -keystore /Users/xxx/server.bks -file /Users/xxx/cacert.pem -storetype BKS -provider org.bouncycastle.jce.provider.BouncyCastleProvider\n```\n\n记住这个命令执行后要求输入的密码。\n*（其中的org.bouncycastle.jce.provider.BouncyCastleProvider如何添加使用自行百度即可。）*\n\n- 现在已经有了两个文件`client.p12`和`server.bks`\n- 准备完成，下面进行java实现。\n```java\npublic SSLContext createSSLContext(Context context) {\n        SSLContext sslContext = null;\n        try {\n\t        // 该密码为生成client.p12时设置的密码\n            String keyPassword = \"\";\n            // 该密码为生成server.bks时设置的密码\n            String trustPassword = \"\";\n            \n            // key store manager\n            KeyStore keyStore = KeyStore.getInstance(\"PKCS12\");\n            InputStream keyInput = context.getResources().openRawResource(R.raw.client);\n            keyStore.load(keyInput, keyPassword.toCharArray());\n            KeyManagerFactory keyManagerFactory = KeyManagerFactory.getInstance(KeyManagerFactory.getDefaultAlgorithm());\n            keyManagerFactory.init(keyStore, keyPassword.toCharArray());\n            \n            // trust store manager\n            KeyStore trustStore = KeyStore.getInstance(\"BKS\");\n            InputStream trustInput = context.getResources().openRawResource(R.raw.server);\n            trustStore.load(trustInput, trustPassword.toCharArray());\n            TrustManagerFactory trustManagerFactory = TrustManagerFactory.getInstance(TrustManagerFactory.getDefaultAlgorithm());\n            trustManagerFactory.init(trustStore);\n            \n            // assemble\n            sslContext = SSLContext.getInstance(\"TLS\");\n            sslContext.init(keyManagerFactory.getKeyManagers(), trustManagerFactory.getTrustManagers(), null);\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n        return sslContext;\n    }\n```\n\n- 接下来配置netty中的SSL\n```java\nclass ClientInitializer extends ChannelInitializer<SocketChannel> {\n\n        private SSLContext mSslContext;\n\n        public ClientInitializer(SSLContext sslContext) {\n            mSslContext = sslContext;\n        }\n        \n        @Override\n        protected void initChannel(SocketChannel ch) throws Exception {\n            ChannelPipeline pipeline = ch.pipeline();\n            SSLEngine sslEngine = mSslContext.createSSLEngine();\n            sslEngine.setUseClientMode(true);\n            pipeline.addFirst(\"ssl\", new SslHandler(sslEngine));\n            pipeline.addLast(\"decoder\", new ClientDecoder());\n            pipeline.addLast(\"encoder\", new ClientEncoder());\n            pipeline.addLast(\"handler\", new ClientHandler());\n\n        }\n    }\n```\n\n- 至此，所有工作就完成了，以上标准配置在android7.0以下的机器上均可正常运行，但是一旦运行到7.0及以上的机器上就会报错\n```java\njavax.net.ssl.SSLHandshakeException: java.security.cert.CertPathValidatorException: Trust anchor for certification path not found.\n        at org.apache.harmony.xnet.provider.jsse.OpenSSLSocketImpl.startHandshake(OpenSSLSocketImpl.java:374)\n        at libcore.net.http.HttpConnection.setupSecureSocket(HttpConnection.java:209)\n        at libcore.net.http.HttpsURLConnectionImpl$HttpsEngine.makeSslConnection(HttpsURLConnectionImpl.java:478)\n        at libcore.net.http.HttpsURLConnectionImpl$HttpsEngine.connect(HttpsURLConnectionImpl.java:433)\n        at libcore.net.http.HttpEngine.sendSocketRequest(HttpEngine.java:290)\n        at libcore.net.http.HttpEngine.sendRequest(HttpEngine.java:240)\n        at libcore.net.http.HttpURLConnectionImpl.getResponse(HttpURLConnectionImpl.java:282)\n        at libcore.net.http.HttpURLConnectionImpl.getInputStream(HttpURLConnectionImpl.java:177)\n        at libcore.net.http.HttpsURLConnectionImpl.getInputStream(HttpsURLConnectionImpl.java:271)\n```\n\n经过一番查询验证，在官网上找到了解决办法，[原链接](https://developer.android.google.cn/training/articles/security-ssl#CommonProblems)-不需翻墙即可访问。\n\n**解决方式如下**\n\n- 和服务器端再要一个文件`server.crt`。\n- 准备完成，下面修改java实现\n```java\npublic SSLContext createSSLContext(Context context) {\n        SSLContext sslContext = null;\n        try {\n            String keyPassword = \"\";\n\n             // key store manager\n            KeyStore keyStore = KeyStore.getInstance(\"PKCS12\");\n            InputStream keyInput = context.getResources().openRawResource(R.raw.client);\n            keyStore.load(keyInput, keyPassword.toCharArray());\n            KeyManagerFactory keyManagerFactory = KeyManagerFactory.getInstance(KeyManagerFactory.getDefaultAlgorithm());\n            keyManagerFactory.init(keyStore, keyPassword.toCharArray());\n            KeyManagerFactory keyManagerFactory = KeyManagerFactory.getInstance(KeyManagerFactory.getDefaultAlgorithm());\n            keyManagerFactory.init(keyStore, keyPassword.toCharArray());\n\n            // trust store manager\n            CertificateFactory cf = CertificateFactory.getInstance(\"X509\");\n            InputStream caInput = context.getResources().openRawResource(R.raw.server);\n            Certificate ca;\n            try {\n                ca = cf.generateCertificate(caInput);\n            } finally {\n                caInput.close();\n            }\n            KeyStore trustStore = KeyStore.getInstance(KeyStore.getDefaultType());\n            trustStore.load(null, null);\n            trustStore.setCertificateEntry(\"CA\", ca);\n            TrustManagerFactory trustManagerFactory = TrustManagerFactory.getInstance(TrustManagerFactory.getDefaultAlgorithm());\n            trustManagerFactory.init(trustStore);\n\n            // assemble\n            sslContext = SSLContext.getInstance(\"TLS\");\n            sslContext.init(keyManagerFactory.getKeyManagers(), trustManagerFactory.getTrustManagers(), null);\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n        return sslContext;\n    }\n```\n**只需要修改`trust store`的创建方式，其他不需要改动。经过以上修改，程序在所有版本的机器上都可以正常运行了！棒**\n","tags":["Android","Netty"],"categories":["Android"]},{"title":"MySql的modify和change区别","url":"/2018/04/c9ea6aa5bbde/","content":"\n- 相同点：都是用来改变column的属性，change和modify执行成功后都会用本次设置的属性替换column原属性，请注意是【替换】；\n- 不同点：重命名只能使用change\n<!--more--> \n格式（mysql默认不区分大小写）\n\n 1 change\n```\nalter table table_name change current_column_name new_column_name type extra;\n// for example.（如果是改名字需要把column原属性都挂上，因为是替换）\nalter table user change id userid int(11) not null auto_increment;\n```\n 2 modify\n \n\n```\nalter table table_name modify column_name type extra;\n// for example\nalter table user modify id int(11) not null auto_increment;\n```","tags":["MySql"],"categories":["MySql"]},{"title":"「巧用Gradle构建Android应用」读书整理","url":"/2018/04/23aff262eba5/","content":"\n周末看完了「巧用Gradle构建Android应用」，故将新认知整理在此以便以后供自己以及有需要的人查看。\n<!--more--> \nGradle\n\n- Gradle构建过程实际上是执行DAG(Directed Acyclic Graph，有向无环图)，允许定义自己的task并插入到其中。\n  build.gradle中Android块时Android DSL()的入口。\n- 依赖的语法\n```groovy\n//完整语法 (禁用传递依赖)\ntestCompile group: 'junit', name: 'junit', version: '4.12'， transitive: false \n//排除依赖\nandroidTestCompile('org.splckframeword:spock-core:1.0-groovy-2.4') {\n\texclude group: 'org.codehaus.groovy'\n\texclude group: 'junit'\n}\n```\n\n- 配置仓库\n```groovy\nrepositories {\n\tmaven {\n\t// 其中的username值和password值可以写在gradle.properties或者在执行gradlew命令时以参数输入\n\t// ./gradlew -Puser=user_from_pFlag -Ppass=pass_from_pFlag\n\t\tusername 'username'\n\t\tpassword 'password'\n\t}\n\turl 'http://repo.mycompany.com/maven2'\n}\n// 还可以在ext块中配置\next {\n\tif (!project.hasProperty('user')) {\n\t\tdef username = 'alice'\n\t}\n\tif (!project.hasProperty('pass')) {\n\t\tdef password = 'passpass'\n\t}\n}\n```\n\n- 升级Gradle版本\n```groovy\n// 方法一\ntask wrapper(type: Wrapper) {\n\tgradleVersion = 2.12\n}\n./gradlew wrapper\n// 方法二：直接修改gradle-wrapper.properties文件的distributionUrl属性。\n```\n\n- 签名\n```groovy\nandroid {\n\t// ...other section...\n\tsigningConfigs {\n\t\trelease {\n\t\t\tkeyAlias 'my_alias'\n\t\t\tkeyPassword 'password'\n\t\t\tstoreFile file('/Users/kousen/keystores/myapp.ketstore')\n\t\t\tstorePassword 'password'\n\t\t}\n\t}\n}\n// 同样，密码可以放到gradle.properties中，或者以gradlew的参数输入\n```\n\n- 构建类型\n```groovy\nbuildTypes {\n// 加后缀区分可同时安装在同一设备上\n\tdebug {\n\t\tapplicationIdSuffix '.debug'\n\t\tversionNameSuffix '-debug'\n\t}\n}\n```\n\n- 产品定制&维度\n```groovy\nandroid {\n\tproductFlavors {\n\t\tarrogant {\n\t\t\tdimension 'attitude'\n\t\t\tapplicationId 'com.oreilly.helloword.arrg'\n\t\t}\n\t\tfriendly {\n\t\t\tdimension 'attitude'\n\t\t\tapplicationId 'com.oreilly.helloword.fund'\n\t\t}\n\t\tstark {\n\t\t\tdimension 'client'\n\t\t}\n\t}\n}\n```\n\n- 自定义任务。Gradle的DSL API已经存在很多任务，如Copy、Wrapper和Exec等，这些任务可以简单地设置属性然后使用。比如Copy任务所包含的from和into属性。\n```groovy\n// 复制任务\ntask copyApks(type: Copy) {\n\tfrom(\"$buildDir/outputs/apk\") {\n\t\texclude '**/*unsigned.apk', '**/*unaligned.apk'\n\t}\n\tinto '../apks'\n}\n// 显示所有可用任务的变种。这个任务中无论在doLast之前还是之后的所有事情都是在配置阶段执行，\n// doLast块中的代码在运行阶段执行\n// applicationVariants属性只针对com.android.application插件有效\n// libraryVariants属性只针对com.android.library插件有效\ntask printVariantNames() {\n\tdoLast {\n\t\tandroid.applicationVariants.all { variant ->\n\t\t\tprintln variant.name\n\t\t}\n\t}\n}\n// 执行安装所有应用的变种的任务\n// dependsOn属性显示这是配置阶段的一部分，而不是运行阶段。每一个变种名字都被首字母大写了\n// 并且相应的安装任务也被添加到installDebugFlavors任务的一个依赖\ntask installDebugFlavors() {\n\tandroid.applicationVariants.all { v ->\n\t\tif (v.name.endWiths('Debug')) {\n\t\t\tString name = v.name.capitalize()\n\t\t\tdependsOn \"install$name\"\n\t\t}\n\t}\n}\n```\n\n- 延长ADB超时时长\n```groovy\n// 30秒\nandroid {\n\tadbOptions {\n\t\ttimeOutInMs = 30 * 1000\n\t}\n}\n```\n\n- 添加自定义任务到构建过程\n```groovy\n// 基于assembleDebug的依赖意味着在运行copy任务之前所有调试APK都会被生成。\ntask copyApks (type: Copy, dependsOn: assembleDebug) {\n\tfrom(\"$buildDir/outputs/apk\") {\n\t\texclude '**/*unsigned.apk', '**/*unsigned.apk'\n\t}\n\tinto '../apks'\n}\n// 如果想要在每次构建的时候都运行copyApks任务，将其作为build任务的一个依赖\nbuild.dependsOn copyApks\n```\n\n- 排除任务\n```groovy\n> ./gradlw build -x lint\n// Gradle运行时，其组装了一个task graph，通过gradle获得这个图的引用，所有对这个图的操纵都需要发生\n// 在其构建出来之后，所以需要使用whenReady属性\ngradle.taskGraph.whenReady { graph ->\n\tif (project.hasProperty('nolint')) {\n\t\tgraph.allTask.findAll {\n\t\t\tit.name ==~/lint.*/}*.enabled = false\n\t\t}\n\t}\n}\n```\n\n- 性能\n```groovy\n// gradle.properties\n// 守护进程\norg.gradle.daemon=true\n// 按需配置设置\norg.gradle.configureondemand=true\n// 选择JVM设置 Xmx最大内存 Xms初始内存 XX:MaxPermSize永代久空间 \n// HeapDumpOnOutOfMemoryError发生时，将堆中情况导出到一个文件中\norg.gradle.jvmargs=-Xmx2048m -XX:MaxPermSize=512m -XX:+HeapDumpOnOutOfMemoryError\n\n// 使用dex选项\ndexOptions {\n\tincremental true\n\tjavaMaxHeapSize '2g'\n\tjumboMode = true//运载dex文件中出现的大量字符串，可能需要配置ProdGuard\n\tpreDexLibraries = true\n} \n```","tags":["Android","Gradle"],"categories":["读书笔记"]},{"title":"gradle各个版本资源","url":"/2017/12/22d73a690578/","content":"\ngradle官网下载地址:[点击跳转](http://services.gradle.org/distributions/)\n\n但是这个网站有时需要翻墙有时下载速度慢，趁着现在翻墙方便一次性将上面的里程碑版本下了下来\n<!--more--> \n链接: https://pan.baidu.com/s/1i4Fm9Q9 密码: cjfd\n\n**最新更新日期:2017-12-22 18:17:06**(如果想的起来就更新)\n\nps: 如有小更新版本需求, 邮箱联系 : oynix@foxmail.com\n\n\n---\n**如何使用**\n\n当用AndroidStudio打开一个项目长时间卡在build页面，多半是项目所需要版本的gradle在本地没有，AS去上面那个网址下却又下不来。操作如下:\n\n1. 关闭AS, 找到项目所使用gradle的版本, 打开**项目根目录/gradle/wrapper/gradle-wrapper.properties**文件, 里面的**distributionUrl**就是;\n2. 将下载好的对应版本的gradle的zip压缩包复制到gradle本地路径, Windows和Mac相同, **~/.gradle/wrapper/dists/{项目使用的版本}/{一串数字字母的名字}/**, 如果该目录存在则直接替换, 复制完直接将zip解压到当前文件夹, 即解压到**{一串数字字母的名字}**文件夹下, 完成后重新打开AS即可.\n","tags":["Android","Gradle"],"categories":["Android"]},{"title":"HelloKotlin - Error:Gradle-failed to create directory","url":"/2017/12/11b68604d6b4/","content":"---\n今天在看Kotlin-Docs，于是随手建了一个HelloKotlin的项目准备练练手，于是引发了一连串的问题。在此记录过程。\n\n<!--more-->\n\n**环境**\n\n - Windows 7 64bit\n - AndroidStudio 3.0.1\n \n---\n一般的，像下面这样，直接写一个程序入口main函数，跑一些简单代码时不用构建apk省时省力：\n![](https://i.loli.net/2021/07/07/5vgDVB4MTyKipoW.png)\n\n同样的，我想创建一个Kotlin的程序入口。\n创建项目时勾选上Kotlin，AndroidStudio便自动导入Kotlin环境，然后直接新建了一个Hello.kt的文件，里面代码很简单，只有三行，如下：\n\n```kotlin\nfun main(args: Array<String>) {\n\tSystem.out.print(\"Hello Kotlin\")\n}\n```\n**fun**单词前有个彩色的Kotlin Logo，直接点击就可以运行HelloKotlin（按道理这样就可以正常跑起来了，我是这么以为的），**但是，报了下面这个错误**：\n![](https://i.loli.net/2021/07/07/g7Jp9tOwETl6diU.png)\n\n在网上搜索**Error:Gradle:failed to create directory**一番后，找到了解决办法，原来是新版AndroidStudio自带的Aapt2引起的，直接禁用就好：在**gradle.properties**添加如下配置即可：\n\n```\nandroid.enableAapt2=false\n```\n\n再次点击**fun**前面的彩色Kotlin Logo，我以为可以运行了，**但是，又报了下面这个错误**：\n![](https://i.loli.net/2021/07/07/uxXfnlNcjMZeOmP.png)\n\n**IDE说找不到HelloKt.class，然而勤劳的我却凭借双手找到了，措不及防**\n![](https://i.loli.net/2021/07/07/b4U69Lmts1A2qBn.png)\n<br>\n这下我就有点不知所措了。。。\n网上也没查出什么相关参考，又试了几种不同的写法，依然不行，最后不知怎么突然想到修改Gradle版本试试看，事实证明此路可行！\nAndroidStudio 3.0.1创建新项目默认的Gradle版本时4.1，Android Plugin Version是3.0.1。我把HelloKotlin项目向下降了一个版本，即Gradle-3.4，Android Plugin - 2.3.3，去掉DSL method google()\n![](https://i.loli.net/2021/07/07/7LJtogyjH4Od3GV.png)\n\n相应的，Module的build.gradle里一些版本都要下调。\n\n```groovy\n// 部分内容\nandroid {\n    compileSdkVersion 25\n    buildToolsVersion '25.0.3'\n    defaultConfig {\n        applicationId \"com.oy.hellokot\"\n        minSdkVersion 15\n        targetSdkVersion 25\n        versionCode 1\n        versionName \"1.0\"\n        testInstrumentationRunner \"android.support.test.runner.AndroidJUnitRunner\"\n    }\n    ...\n}\n\ndependencies {\n    compile fileTree(dir: 'libs', include: ['*.jar'])\n    compile\"org.jetbrains.kotlin:kotlin-stdlib-jre7:$kotlin_version\"\n    compile 'com.android.support:appcompat-v7:25.3.1'\n    compile 'com.android.support.constraint:constraint-layout:1.0.2'\n    testCompile 'junit:junit:4.12'\n    androidTestCompile 'com.android.support.test.espresso:espresso-core:2.2.2'\n}\n```\n\n如上配置以后，再次点击**fun**之前的彩色Kotlin Logo，程序便可以跑起来了。","tags":["AndroidStudio","Kotlin"],"categories":["Kotlin"]},{"title":"Windows下编译OpenSSL","url":"/2017/11/0d432f214850/","content":"---\n\n今天为了获取FB秘钥，里面有个命令openssl，于是网上找了一下教程，众说纷纭，最后可算成功了，在此记录过程。\n<!--more-->\n#### **环境**\n - Windows 64位\n - 已安装Visual Studio 2017 社区版（已过期不过没影响）\n - 已安装Active Perl v5.16.2\n\n#### **准备源码**\n - [OpenSSL官网](https://www.openssl.org/)\n - 或者直接用文中所用的 :  https://pan.baidu.com/s/1pL0vDhx 密码: hndw\n\n---\n#### **过程**\n1. 在Microsoft Visual Studio目录下搜索**vcvarsall.bat**并进入所在目录。\n![](https://i.loli.net/2021/07/07/hbDj3oUKWFLJfuq.png)\n2. 在所在目录下打开cmd，运行`vcvarsall.bat x86_amd64`\n\n\t```sh\n\tC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Auxiliary\\Build>vcvarsall.bat x86_amd64\n\t[vcvarsall.bat] Environment initialized for: 'x86_x64'\n\t```\n3.  cmd切换到解压完的OpenSSL源码目录运行\n\n\t```sh\nC:\\Users\\it\\Desktop\\openssl-1.0.2m>perl Configure VC-WIN64A\n\t```\n4. 继续运行\n\n\t```sh\nC:\\Users\\it\\Desktop\\openssl-1.0.2m>ms\\do_win64a\n\t```\n5. 继续执行，这步在我的电脑上跑了好几分钟\n\n\t```sh\nC:\\Users\\it\\Desktop\\openssl-1.0.2m>nmake -f ms\\nt.mak \n\t```\n6. 继续执行。执行完第六步之后，编译好的OpenSSL就复制到了`\\usr\\local\\ssl\\lib`路径下，我是在桌面编译的，所以在C盘根目录\n\n\t```sh\nC:\\Users\\it\\Desktop\\openssl-1.0.2m>nmake -f ms\\nt.mak install\n\t```\n\n7. 将OpenSSL路径`C:\\usr\\local\\ssl\\bin`添加到系统路径path里\n\n8. 打开一个新的cmd窗口，运行openssl命令，如图表明成功\n![](https://i.loli.net/2021/07/07/UHcXsjCJErxna65.png)\n\n---\n#### **注意**\n第2步到第3步要在同一个cmd窗口里运行。开始运行第5步不管用，总提示找不到nmake命令，我就直接把nmake.exe（Microsoft Visual Studio目录下搜索到的，同步骤1）直接放到系统路径里了，可以运行，后来发现2、 3只要在同一个cmd窗口就可以了。\n","tags":["Windows","OpenSSL"],"categories":["OpenSSL"]},{"title":"「Effective Java」读书整理","url":"/2017/11/29c00d69eefc/","content":"---\n书地址 ：链接: https://pan.baidu.com/s/1kUAwYgv 密码: ij4j\n<!--more-->\n###  - Chapter 3 适用于所有对象\n#### **8. 重写`equals`方法**\n> 三个原则：对称性、传递性、一致性\n\n#### **9. 重写`equals`方法必定要重写`hashCode`方法**\n> 例如在HashMap中存储时会调用该方法\n\n#### **10. 始终要重写`toString`方法**\n> 便于阅读，使类用起来更加舒适\n\n#### **11. 谨慎的覆盖`clone`方法**\n> 相当于另一个构造器\n\n#### **12. 考虑实现Comparable接口**\n> 用于对象比较、排序（在集合里sort）\n\n----\n\n### - Chapter 4 类和接口\n#### **13. 使类和成员的可访问性最小化(encapsulation)**\n```java\n// 错误方式,安全漏洞; \n// 当域为基本类型或不可变对象时安全;\n// 当为可变对象的引用时存在安全漏洞, VALUE虽不可修改但数组里的对象可被修改\npublic static final Thing[] VALUE = {....};\n// 正确方式\nprivate static final Thing[] PRIVATE_VALUES = {...};\npublic static final List<Thing> VALUES = Collections.unodifiableList(Arrays.asList(PRIVATE_VALUES));\n```\n#### **14. 在公有类中使用访问方法而非公有域**\n> 总有类永远不应该暴露可变域\n\n#### **15. 使可变性最小化**\n成为不可变类的5条规则 :\n\n 1. 不要提供任何会修改对象状态的方法;\n 2. 保证类不会被扩展(fina);\n 3. 使所有域都是final的;\n 4. 使所有域都成为私有的;\n 5. 确保对于任何可变组件的互斥访问.\n\n#### **16. 复合优先于继承**\n> 当B和A的关系为\"is-a\"时，让B继承自A；否则B中应包含一个A的实例（复合），而不是扩展A（继承）。\n\n#### **17. 要么为继承而设计，并提供文档说明， 要么就禁止继承**\n> 1>. 关于程序文档有句格言：*好的API文档应该描述一个给定的方法做了什么工作，而不是描述它如何做到的。*\n\n为了允许继承，类还必须遵守其他一些约束：\n\n - 构造器决不能调用可被覆盖的方法；\n - 无论是clone（Cloneable接口）还是readObject（Serializable接口），都不可调用可覆盖的方法，不管是直接还是间接的方式。\n\n#### **18. 接口优先于抽象类**\n> 抽象类的演变比接口容易；\n> 骨架实现，即接口的简单实现\n\n#### **19. 接口只用于定义类型**\n> 避免常量接口；\n> 接口应该只被用来定义类型\n\n#### **20. 类层次优先于标签类**\n> 标签类过于冗长、容易出错，并且效率底下\n\n\n#### **21. 用函数对象表示策略**\n> 比较器：String.CASE_INSENSITIVE_ORDER\n\n#### **22. 优先考虑静态成员类**\n嵌套类种类\n\n 1. 静态成员类；\n 2. 非静态成员类；\n 3. 匿名类；\n 4. 局部类。\n\n后三种都被称为内部类。\n> 如果声明成员类不要求访问外围实例，就要始终把static修饰符放在它的声明中，使它成为静态成员类，而不是非静态成员类。如果省略了static修饰符，则每个实例都将包含一个额外的指向外围对象的引用。例如ViewHolder。\n\n---\n\n### - Chapter 5 泛型\n\n#### 23. 请不要在新代码中使用原生态类型\n\n - `Set` : 原生态类型， 脱离了泛型系统；\n - `Set<?>` : 无限通配符类型，只能包含某种未知对象类型；\n - `Set<Object>`: 参数化类型，可以包含任何对象类型。\n\n```java\nif (o instanceof Set) {\n\tSet<?> m = (Set<?>) o;\n}\n```\n> 原生态类型只是为了与引入泛型之前的遗留代码进行兼容和互用而提供的。\n\n术语 | 示例\n-------| -------\n参数化类型 | `List<String>`\n实际类型参数 | `String`\n泛型 | `List<E>`\n形式类型参数 | `E`\n无限制通配符类型 | `List<?>`\n有限制类型参数 | `<E extends Number>`\n递归类型限制 | `<T extends Comparable<T>>`\n有限制通配符类型 | `List<? extends Number>`\n泛型方法 | `static <E>List<E> asList(E[] a)`\n泛型令牌 | `String.class`\n\n#### **24. 消除非受检警告**\n> @SuppressWarnings(\"unchecked\")要放在一个声明上，要将禁止非受检警告范围缩到最小；每次使用时都要添加一个注释，说明为什么这么做是安全的。\n\n```java\n// 例如ArrayList中的toArray方法, 注解不加在方法上而是单独声明一个局部变量\n// 为的就是缩小非受检警告范围, 这么做是值得的.\npublic <T> T[] toArray(T[] a) {\n\tif (a.length < size) {\n\t\t// This cast is correct because the array we're creating \n\t\t// is of the same type as the one passed in, which is T[].\n\t\t@SuppressWarnings(\"unchecked\")\n\t\tT[] result = (T[]) Arrays.copyOf(elements, size, a.getClass());\n\t\treturn result;\n\t}\n\tSystem.arrayCopy(elements, 0, a, 0, size);\n\tif (a.length > size)\n\t\ta[size] = null;\n\treturn a;\n}\n```\n\n#### **25. 列表优先于数组**\n\n - 禁止创建泛型数组，优先使用集合；\n - 数组是协变且可以具体化的，泛型是不可变的且可以被擦除的。\n - 混合使用时如何得到编译时错误或者警告时，用列表代替数组。\n\n#### **26. 优先考虑泛型**\n> 使用泛型比使用需要在客户端代码中进行转换的类型来的更加安全，也更加容易。只要时间允许，就把现有的类型都泛型化。\n\n#### **27. 优先考虑泛型方法**\n\n```java\n// 递归泛型 类型参数\npublic static <T extends Comparable<T>> T max(List<T> list) {\n\tIterator<T> i = list.iterator();\n\tT result = i.next();\n\twhile (i.hasNext()) {\n\t\tT t = i.next();\n\t\tif (t.compare(result) > 0)\n\t\t\tresult = t;\n\t}\n\treturn result;\n}\n```\n\n#### **28. 利用有限制通配符来提升API的灵活性**\n> 为了获得最大限度的灵活性，要在表示生产者或者消费者的输入参数上使用通配符类型。\n> **PECS表示producer-extends，consumer-super**\n> 换句话说， 如果参数化类型表示一个T生产者，就使用<? extends T>；如果表示一个T消费者，就使用<? super T>\n\n```java\n// 用Stack示例\npublic void pushAll(Iterable<? extends E> src) {\n\tfor (E e : src)\n\t\tpush(e);\n}\npublic void popAll(Collection<? super E> dst) {\n\twhile (!isEmpty()) \n\t\tdst.add(pop());\n}\n```\n修改过的使用通配符类型的声明：PECS规则，list生产T实例，T的comparable消费T实例并产生表示顺序关系的整值。comparable始终是消费者，因此使用时始终应该是`Comparable<? super T>`优先于`Comparable<T>`。对于comparator也一样，因此使用时始终应该是`Comparator<? super T>` 优先于`Comparator<T>`\n\n```java\npublic static <T extends Comparable<? super T>> T max(List<? extends T> list)  {\n\t// 这里做了修改\n\tIterator<? extends T> i = list.iterator();\n\tT result = i.next();\n\twhile (i.hasNext()) {\n\t\tT t = i.next();\n\t\tif (t.compare(result) > 0)\n\t\t\tresult = t;\n\t}\n\treturn result;\n}\n```\n#### **29. 优先考虑类型安全的异构容器**\n\n```java\npublic class Favorites {\n\tprivate Map<Class<?>, Object> favorites = new HashMap<Class<?>, Object>();\n\n\tpublic <T> void putFavorite(Class<T> type, T instance) {\n\t\tif (type == null) \n\t\t\tthrow new NullPointerException(\"type is null\");\n\t\tfavorites.put(type, instance);\n\t}\n\n\tpublic <T> T getFavorite(Class<T> type) {\n\t\treturn type.cast(favorites.get(type));\n\t}\n}\n```\n确保永远不违背它的类型约束条件：\n```java\nCollections.checkedXXX();\n```\n利用Class.asSubclass方法进行转换：\n\n```java\npublic <T extends Annotation> T getAnnotation(Class<T> annotationType);\nClass<?> typeOne = Class.forName(typeOneInstance);\ngetAnnotation(typeOne.asSubclass(Annotation.class));\n```\n\n### -Chapter 6 枚举和注解\n#### **30. 用enum代替int常量**\n> 枚举类型有一个自动产生valueOf（String）方法，它将常量的名字转变成常量本身；\n> 枚举中的switch语句适合于给外部的枚举类型增加特定于常量的行为。\n```java\npublic enum Operation {\n\tPLUS(\"+\") {double apply(double x, double y) {return x + y;} },\n\tMIMUS(\"-\") {double apply(double x, double y) {return x - y} },\n\tTIMES(\"*\") {double apply(double x, double y) {return x * y} },\n\tDIVEDES(\"/\") {double apply(double x, double y) {return x / y} };\n\n\tprivate String symbol;\n\tpublic Operation(String sym) {\n\t\tthis.symbol = sym;\n\t}\n\t@Override\n\tpublic void toString() {\n\t\treturn symbol;\n\t}\n\tabstract double apply(double x, double y);\n}\n```\n\n#### **31. 用实例域代替序数**\n> 所有的枚举都有一个`ordinal`方法， 它返回每个枚举常量在类型中的数字位置。永远不要根据枚举的序数导出与它关联的值，而是要将它保存在一个实例中\n\n```java\npublic enum Ensemble {\n\tSOLO(1), DUET(2), TRIO(3);\n\n\tprivate int numberOfMusicians;\n\tpublic Ensemble(int size) {\n\t\tthis.numberOfMusicians = size;\n\t}\n\tpublic int numberOfMusician() {\n\t\treturn numberOfMusicians;\n\t}\n}\n```\n\n#### **32. 用EnumSet代替位域**\n> 正是因为枚举类型要用在集合Set中, 所有没有理由用位域来表示它.EnumSet具有简洁和性能的优势.\n```java\npublic class Text {\n\tpublic enum Style {BOLD, ITALIC, UNDERLINE, STRIKETHROUGH}\n\t\n\t// 所有的Set都可传入, 但是EnumSet最好\n\t// 考虑到可能还有其他实现,所以使用Set<Style>而不是EnumSet<Style>\n\tpublic void applyStyles(Set<Style> styles){...}\n}\n\n// 下面是将EnumSet实例传递给applyStyles方法的客户端代码。EnumSet提供了丰富的\n// 静态工厂来轻松创建集合, 其中一个如下\ntext.applyStyles(EnumSet.of(Style.BOLD, Style.ITALIC));\n```\n\n#### **33. 用EnumMap代替序数索引**\n\n```java\nMap<Herb.Type, Set<Herb>> herbsByType = new EnumMap<Herb.Type, Set<Herb>>(Herb.Type.class);\nfor (Herb.Type t : Herb.Type.values()) {\n\therbsByType.put(t, new HashSet<Herb>);\n}\nfor (Herb b : garden) {\n\therbsByType.get(b.type).add(b);\n}\n```\n\n#### **34. 用接口模拟可伸缩的枚举**\n> 避免扩展枚举类型(继承), 采用用枚举类型实现接口(实现)\n```java\n// 定义一个接口\npublic interface Operation{...}\n// ExtendOperation实现了这个接口\npublic ExtendOperation implements Operation{...}\npublic static void main(String[] args) {\n\tdouble x = 3.3;\n\tdouble y = 3.4;\n\t// 方法一\n\ttest(ExtendOperation.class, x, y);\n\t// 方法二\n\ttest(Arrays.asList(ExtendOperation.values()), x, y);\n}\n// 方法一 : 确保Class对象既表示枚举又表示Operation的子类型\nprivate static <T extends Enum<T> & Operation> void test(\n\tClass<T> opSet, double x, double y) {\n\tfor (Operation op : opSet.getEnumConstants()) {\n\t\t// do sth\n\t}\n}\n// 方法二 \nprivate static void test(Collection<? extends Operation> opSet, double x, double y) {\n\tfor (Operation op : opSet) {\n\t\t// do sth\n\t}\n}\n```\n\n#### **35. 注解优先于命名模式**\n\n```java\n// 注解类, 只用在无参数的静态方法上\n@Retention(RetentionPolicy.RUNTIME)\n@Target(ElementType.METHOD)\npublic @interface Test {}\n\n// 测试\nClass testClass = Class.forName(agrs[0]);\nfor (Method m : testClass.getDeclaredMethods()) {\n\t// 判断某个方法是否被Test注解标注\n\tif (m.isAnnotationPresent(Test.class)) {\n\t\ttry {\n\t\t\t// 可直接执行说明是静态方法; 传入null说明无参数\n\t\t\tm.invoke(null);\n\t\t} catch(InvocationTargetException ite) {\n\t\t\t// 1. 实例方法\n\t\t\t// 2. 一个或多个参数\n\t\t\t// 3. 不可访问的方法\n\t\t}\n\t}\n}\n\n// 只有抛出异常才算成功的注解类\n@Retention(RetentionPolicy.RUNTIME)\n@Target(ElementType.METHOD)\npublic @interface ExceptionTest {\n\tClass<? extends Exception> value();\n}\n// 待测试的方法\n@ExceptionTest(ArithmeticException.class)\npublic static void method1() {\n\tint i = 0;\n\ti = i / i;\n}\n@ExceptionTest(ArithmeticException.class)\npublic static void method2() {\n\tint[] arr = new int[1];\n\tint i = arr[3];\n}\n@ExceptionTest(ArithmeticException.class)\npublic static void method3() {\n\t// do nothing\n}\n\n// 测试工具类\nif (m.isAnnotationPresent(ExceptionTest.class)) {\n\ttry {\n\t\tm.invoke(null);\n\t} catch (InvocationTargetExcetpion ite) {\n\t\t// 出现的异常类型\n\t\tThrowable exception = ite.getCause();\n\t\t// 期待的异常类型\n\t\tClass<? extends Exception> ex = m.getAnnotation(ExceptionTest.class).value();\n\t\t// 出现的异常与期待的异常时同一种\n\t\tif (ex.instanceOf(exception)) {...}\n\t}\n}\n\n// 多种类型异常注解类\n@Retention(RetentionPolicy.RUNTIME)\n@Target(ElementTarget.METHOD)\npublic @interface ExceptionsTest {\n\tClass<? extends Exception>[] value();\n}\n// 待测试方法注解\n@ExceptionsTest({IndexOutOfBoundException.class, ArithmeticException.class})\npublic static void method4() {\n}\n```\n\n#### **36. 坚持使用Override注解**\n> IDE可检查\n\n#### **37. 用标记接口定义类型**\n**标记接口，类似于Serializable接口，没有方法，只是一个空接口作为标记，被标记过的实例可以通过ObjectOutputStream处理。**\n两者比较：标记接口和标记注解\n - 标记接口定义的类型是由被标记类的实例实现的；标记注解则是没有定义这样的类型。这个类型允许你在编译时捕捉在使用标记注解的情况下要到运行时才能捕捉到的错误；\n - 标记接口的另一个优点，可以被跟家精确的锁定；\n - 标记注解胜过标记接口的最大优点在于，它可以通过默认的方式添加一个或者多个注解类型元素，给一倍使用过的注解类型添加更多的信息。随着时间的推移，简单类型的标记注解可以演变成丰富的标记注解， 标记接口则不能。\n - 标记注解的另一个优点在于，它们是更大的注解机制的一部分。因此，标记注解在那些支持注解作为编程元素之一的框架中同样具有一致性。\n\n区分使用\n\n - 应用到任何程序元素（方法，字段等）而不是类或者接口，必须用标记注解；\n - 标记类和接口， 优先使用标记接口；\n - 标记只用于特殊接口的元素，将标记定义为该接口的一个子接口；\n - 如果以后需要扩展，用标记注解；\n - 当目标是ElementType.TYPE时，多考虑标记接口。\n\n### -Chapter 7 方法\n\n#### **38. 检查参数的有效性**\n\n - 在方法体的开头检查参数；\n - 使用断言assert，失败时抛出AssertionError；\n - 检查构造器的参数尤为重要\n\n#### **39. 必要时进行保护性拷贝**\n\n- 保护性拷贝是在检查参数有效性之前进行的，并且有效性检查是针对拷贝之后的对象；\n- 对于参数类型可以被不可信任方子类化的参数，请不要使用clone进行保护性拷贝\n\n#### **40. 谨慎设计方法签名**\n\n 1. 谨慎选择方法名称。\n 2. 不要过于追求提供便利的方法。\n 3. 避免过长的参数列表（小于等于4）。\n 4. 对于参数类型，优先使用接口而不是类。\n 5. 对于boolean参数， 优先使用两个元素的枚举类型。\n\n#### **41. 慎用重载**\n\n - 对于重载方法（overloaded method）的选择是静态的，而对于被覆盖的方法（overridden method）的选择是动态的。\n - 避免胡乱使用重载机制的安全而保守的策略是，永远不要导出两个具有相同参数数目的重载方法。如果方法是可变参数，保守策略是根本不要重载它。\n\n#### **42. 慎用可变参数**\n#### **43. 返回零长度的数组或集合，而不是null**\n\n```java\nprivate final List<Cheese> cheeseInStock = ....;\nprivate final static Cheese[] EMPTY_CHEESE_ARRAY = new Cheese[0];\n\npublic Cheese[] getCheese() {\n\treturn cheeseInStock.toArray(EMPTY_CHEESE_ARRAY);\n}\n\n// 集合值的方法\npublic List<Cheese> getCheeseList() {\n\tif (cheeseOfStock .isEmpty()) {\n\t\treturn Collections.emptyList();\n\t} else {\n\t\treturn new ArrayList<Cheese>(cheeseOfStock);\n\t}\n}\n```\n\n#### **44. 为所有到处的API元素编写文档注释**\n\n### -Chapter 8 通用程序设计\n\n#### **45. 将局部变量的作用域最小化**\n\n - 要是局部变量的作用域最小化，最有力的方法就是在第一次使用它的地方声明。\n - 几乎每个局部变量的声明都应该包含一个初始化表达式，如果没有则应推迟声明。try-catch例外。\n - 如果循环终止之后不再需要循环变量的内容，for循环优于while循环。\n\n```java\n// n的作用是:避免每次循环产生额外计算的开销\nfor (int i = 0 , n = getSize(); i < n; i++) {\n\tdoSomething(i);\n}\n```\n\n#### **46. for-each循环优于传统的for循环**\n\n三种情况无法使用for-each\n 1. 过滤：如果需要遍历集合，并删除选定的元素，就需要使用显示的迭代器，以便可以调用它的remove方法。\n 2. 转换：如果需要遍历列表或者数组，并取代它的部分或者全部元素值，就需要列表迭代器或者数组索引，以便设定元素的值。\n 3. 平行迭代：如果需要并行的遍历多个集合，就需要显示的控制迭代器或者索引变量，以便所有迭代器或者索引变量都可以得到同步前移。\n\n#### **47. 了解和使用类库**\n\n - 使用标准类库而不是专门的实现。\n - Collections Framework\n - java.util.concurrent包含高级并发工具来简化多线程的编程任务，还包含低级别的并发基本类型\n\n#### **48. 如果需要精确的答案， 请避免使用float和double**\n> 使用int或者long或者BigDecimal替代。\n\n#### **49. 基本类型优先于装箱基本类型**\n\n#### **50. 如果其他类型更适合， 则尽量避免使用字符串**\n\n - 字符串不合适代替其他的值类型。\n - 字符串不合适代替枚举类型。\n - 字符串不适合代替聚集类型。\n - 字符串也不适合代替能力表。\n\n#### **51. 当心字符串连接的性能**\n> 使用StringBuilder\n\n#### **52. 通过接口引用对象**\n> 如果有合适的接口类型存在，那么对于参数、返回值、变量和域来说，就都应该使用接口类型进行声明，如List。\n> 如果没哟合适的接口存在，完全可以用类而不是接口来引用对象，如值类String、BigInteger\n\n#### **53. 接口优先于反射机制**\n\n#### **54. 谨慎地使用本地方法**\n> 使用本地方法提高性能的做法不值得提倡\n\n#### **55. 谨慎地进行优化**\n\n - 努力避免那些限制性能的设计决策。\n - 为获得更好的性能而对API进行包装，这是一种非常不好的想法。\n\n#### **56. 遵守普遍接受的命名惯例**\n\n### -Chapter 9 异常\n\n#### **57. 只针对异常的情况才使用异常**\n\n#### **58. 对于可恢复的情况使用受检异常，对编程错误使用运行时异常**\n\n#### **59. 避免不必要地使用受检异常**\n\n#### **60. 优先使用标准的异常**\n\n#### **61. 抛出与抽象相对应的异常**\n> 底层的异常被传到高层的异常，高层的异常提供访问方法（Throwable.getCause）来获得底层的异常\n\n#### **62. 每个方法抛出的异常都要有文档**\n\n#### **63. 在细节消息中包含能捕获失败的信息**\n\n#### **64. 努力使失败保持原子性**\n\n#### **65. 不要忽略异常**\n\n### -Chapter 10 并发\n\n#### **66. 同步访问共享的可变数据**\n> 当多个线程共享可变数据的时候，每个读或者写数据的线程必须执行同步。\n\n#### **67. 避免过度同步**\n\n - 为了避免活性失败和安全性失败，在一个被同步的方法或者代码块中，永远不要放弃对客户端的控制。\n - 在同步区域内做尽可能少的工作。\n - 为了避免死锁和数据损坏，千万不要从同步区域内部调用外来方法。\n\n#### **68. executor和task优先于线程**\n\n#### **69. 并发工具优先于wait和notify**\n\n - 除非迫不得已，否则应该优先使用ConcurrentHashMap，而不是使用Collections.synchronizedMap或Hashtable。只要用并发Map替代老式的同步Map，就可以极大地提升应用程序的性能。更一般地，应该优先使用并发集合，而不是使用外部的同步集合。\n - 对于间歇式的定时，始终应该优先使用System.nanoTime，而不是System.currentTimeMills，前者更加准确也更加精确，它不受系统的实时始终的调整影响。\n - 使用应该使用wait循环模式来调用wait方法；永远不要在循环之外调用wait方法。循环会在等待之前和之后测试条件。\n\n```java\nprivate static final ConcurrentMap<String, String> map = ConcurrentHashMap<>();\n\npublic static String intern(String s) {\n\tString result = map.get(s);\n\tif (result == null) {\n\t\t// 应对并发情况\n\t\tresult = map.putIfAbsent(s, s);\n\t\tif (result == null) {\n\t\t\tresult = s;\n\t\t}\n\t}\n\treturn result;\n}\n```\n\n#### **70. 线程安全性的文档化**\n\n - “出现synchronized关键字就足以用文档说明线程安全性”的这种说法隐含了一个错误的观念，即认为线程安全性是一种“要么全有要么全无”的属性。\n\n线程安全性的几种级别：\n\n 1. 不可变的（immutable）：这个类的实例是不变的。所以，不需要外部的同步。这样的例子包括String、Long和BigInteger。\n 2. 无条件的线程安全（unconditionally thread-safe）：这个类的实例是可变的，但是这个类有着足够的内部同步，所以，它的实例可以被并发使用，无需任何外部同步。其例子包括Random和ConcurrentHashMap。\n 3. 有条件的线程安全（conditionally thread-safe）：除了有些方法为进行安全的并发使用而需要外部同步之外，这种线程安全级别与无条件的线程安全相同。这样的例子包括Collections.synchronized包装返回的集合，它们的迭代器（iterator）要求外部同步。\n 4. 非线程安全（not thread-safe）：这个类的实例是可变的。为了并发地使用它们，客户必须利用自己选择的外部同步包围每个方法调用（或者调用序列）。这样的例子包括通用的集合实现，例如ArrayList和HashMap。\n 5. 线程对立的（thread-hostile）：这个类不能安全地被多个线程并发使用，即使所有的方法调用都被外部同步包围。线程对立的根源通常在于，没有同步地修改静态数据。没有人会有意编写一个线程对立的类；这种类是因为没有考虑到并发性儿产生的后果。幸运的是，在Java平台类库中，线程对立的类或者方法非常少。System.runFinalizersOnExit方法是线程对立的，但已经被废除了。\n\n#### **71. 慎用延迟初始化**\n\n - 在大多数情况下，正常初始化要优先于延迟初始化。如果域只在类的实例部分被访问，并且初始化这个域的开销很高，可能就值得进行延迟初始化。\n\n```java\n// 正常初始化\nprivate final FieldType field = computeFieldValue();\n\n// 延迟初始化，要使用同步访问方法\nprivate FieldType field;\nsynchronized FieldType getField() {\n\tif (field == null)\n\t\tfield = computeFieldValue();\n\treturn field;\n}\n```\n\n - 如果出于性能的考虑而需要对**静态域**使用延迟初始化，就是用lazy initialization holder class模式。这种模式保证了类要到用到的时候才会被初始化。\n\n```java\nprivate static class FieldHolder {\n\tstatic final FieldType field = computeFieldValue();\n}\nstatic Field getField() {\n\treturn FieldHolder.field;\n}\n```\n\n - 如果处于性能考虑而需要对**实例域**使用延迟初始化，就使用双重检查模式。这种模式避免了在域被初始化之后访问这个域时的锁定开销。\n\n```java\nprivate volatile FieldType field;\nFieldType getField() {\n\t// 局部变量result的作用是确保field只在已经被初始化的情况下读取一次,提升性能\n\tFieldType result = field;\n\tif (result == null) {\n\t\tsynchronized(this) {\n\t\t\tresult = field;\n\t\t\tif (result == null)\n\t\t\t\tfield = result = computeFieldValue();\n\t\t}\n\t}\n\treturn result;\n}\n```\n\n - 延迟初始化一个可以接受重复初始化的实例域，可使用单重检查模式。\n \n \n\n```java\nprivate volatile FieldType field;\nprivate FieldType getField() {\n\tFieldType result = field;\n\tif (result == null) \n\t\tfield = result = computeFieldValue();\n\treturn result;\n}\n```\n\n#### **72. 不要依赖于线程调度器**\n> 不要让程序的正确性依赖于线程调度器，否则结果得到的应用将既不健壮也不具有可移植性。作为推论，不要依赖Thread.yield或者线程优先级。\n\n#### **73. 避免使用线程组**\n\n### -Chapter 11 序列化\n\n#### **74. 谨慎地实现Serializable接口**\n> 为了继承而设计的类应该尽可能少地去实现Serializable接口，用户的接口也应该尽可能少地继承Serializable接口。\n> 如果一个类或者一个接口存在的目的主要是为了参与到某个框架中，该框架要求所有的参与者必须实现Serializable接口，这个时候实现或者扩展Serializable接口就很有意义。\n> 内部类不应该实现Serializable，内部类的默认序列化形式是定义不清楚的，然而静态成员类却可以实现Serializable。\n\n```java\npublic class Foo extends AbstractFoo implements Serializable {\n\tprivate void readObject(ObjectInputStream s) throws IOException, ClassNotFoundException {\n\t\ts.defaultReadObject();\n\t\t// Manually deserialize and initialize superclass state\n\t\tint x = s.readInt();\n\t\tint y = s.readInt();\n\t\tinitialize(x, y);\n\t}\n\n\tprivate void writeObject(ObjectOutputStream s) throws IOException {\n\t\ts.defaultWriteObject();\n\t\t// Manually serialize superclass state\n\t\ts.writeInt(getX());\n\t\ts.writeInt(getY());\n\t}\n\t\n\tpublic Foo(int x, int y) {\n\t\tsuper(x, y);\n\t}\n\t\n\tprivate static final long serialVersionUID = 185683560954L;\n}\n```\n\n#### **75. 考虑使用自动以序列化形式**\n\n```java\npublic final class StringList implements Serializable {\n\tprivate int size = 0;\n\tprivate Entry head = null;\n\tprivate static class Entry implements Serializable {\n\t\tString data;\n\t\tEntry next;\n\t\tEntry previous;\n\t}\n\t// ...Remainder omitted\n}\n```\n\n当一个对象的物理表示法与它的逻辑数据内容有实质性的区别时，使用默认序列化形式会有以下4个缺点：\n\n 1. **它使这个类的导出API永远地束缚在该类的内部表示法上。**在上面的例子中，私有的StringList.Entry类变成了公有API的一部分。如果在将来额版本中，内部表示法发生了变化，StringList类仍将需要接受链表形式的输入，并产生链表形式的输出。这个类永远也摆脱不了维护链表项所需要的所有代码，即使它不再使用链表作为内部结构了，也仍然需要这些代码。\n 2. **它会消耗过多的空间。**在上面的例子中，序列化形式既表示了链表中的每个项，也表示了所有的链接关系，这是不必要的。这些链表项以及链表只不过是实现细节，不值得记录在序列化形式中。因为这样的序列化形式过于庞大，所以把它写到硬盘中，或者在网络上发送都将非常慢。\n 3. **它会消耗过多的时间。**序列化逻辑并不了解对象图的拓补关系，所以它必须要经过一个昂贵的图遍历（traversal）过程。在上面的例子中，沿着next引用进行遍历是非常简单的。\n 4. **它会引起栈溢出。**默认的序列化过程要对对象图执行一次递归遍历，即使对于中等规模的对象图，这样的操作也可能引起栈溢出。到底多少个元素会引发栈溢出，这要取决于JVM的具体实现以及Java启动时的命令行参数，（比如Heap Size的-Xms与-Xmx的值）有些实现可能根本不存在这样的问题。\n\n修订版本，transient修饰符表明这个实例域将从一个类的默认序列化形式中省略掉。\n\n```java\npublic final class StringList implements Serializable {\n\tprivate transient int size = 0;\n\tprivate transient Entry head = null;\n\tprivate static class Entry {\n\t\tString data;\n\t\tEntry next;\n\t\tEntry previous;\n\t}\n\t// 添加指定的string到这个集合\n\tpublic final void add(String s) {...}\n\n\t// 重写writeObject方法, 与物理表示法的细节脱离\n\tprivate void writeObject(ObjectOutputStream s) throws IOException {\n\t\ts.defaultWriteObject();\n\t\ts.writeInt(size);\n\t\tfor (Entry e = head; e != null; e = e.next) {\n\t\t\ts.writeObject(e.data);\n\t\t}\n\t}\n\n\t// 重写readObject方法,与write对应\n\tprivate void readObject(ObjectInputStream s) throws IOException, ClassNotFoundException {\n\t\ts.defaultReadObject();\n\t\tint numElements = s.readInt();\n\t\tfor (int i = 0; i < numElements; i++) {\n\t\t\tadd((String) s.readObject());\n\t\t}\n\t}\n\t...// Remainder omitted\n}\n```\n> 尽管StringList的所有域都是瞬时的(transient)，但wirteObject方法的首要任务仍是调用defaultWriteObject，readObject方法的首要任务则是调用defaultReadObject。如果所有的实例域都是瞬时的，从技术角度而言，不调用defaultWriteObject和defaultReadObject也是允许的，但是不推荐这样做。即使所有的实例域都是transient的，调用defaultWriteObject也会影响该类的序列化形式，从而极大地增强灵活性。这样得到的序列化形式允许在以后的发行版中增加非transient实例域，并且还能保持向前或者向后兼容性。如果某一个实例将在未来的版本中被序列化，然后在前一个版本中被反序列化，那么，后增加的域将被忽略掉。如果旧版本的readObject方法没有调用defaultReadObject，反序列化过程将失败，引发StreamCorrupted Exception异常。\n> 无论是否使用默认的序列化形式，当defaultWriteObject方法被调用的时候，每一个未被标记为transient的实例域都会被序列化。因此每一个可以被标记为transient的实例域都应该做上这样的标记。这包括那些冗余的域，即它们的值可以根据其他“基本数据类型”计算而得到的域，比如缓存起来的散列值。**在将一个域做成非transient的之前，请一定要确信它的值是该对象逻辑状态的一部分。**如果你正在使用一种自定义的序列化形式，大多数实例域，或者所有的实例域则都应该被标记为transient，就像上面例子中的StringList那样。\n> 如果正在使用默认的序列化形式， 并且把一个或者多个域标记为transient，则要记住，当一个实例被反序列化的时候，这些域将被初始化为它们的默认值。\n> 无论是否使用默认的序列化形式，如果在读取整个对象状态的任何其他方法上强制任何同步，则必须在对象序列化上强制这种同步。\n> 不管选择了哪种序列化形式，都要为自己编写的每个可序列化的类声明一个显示的序列化版本UID（serial version UID）。第一避免不兼容，第二减小额外计算的开销。\n\n```java\npirvate static final long serialVersionUID = randomLongValue;\n```\n> 在编写新类时，为randomLongValue选择什么值并不重要。通过在该类上运行serialver工具，就可以得到这样一个值，但是，凭空编造一个数值也是可以的。如果想修改一个没有序列版本UID的现有的类，并希望新的版本能够接受现有的序列化实例，就必须使用serialver工具为旧版本生成值。\n\n#### **76. 保护性地编写readObject方法**\n> 当一个对象被反序列化的时候，对于客户端不应该拥有的对象引用，如果哪个域包含了这样的对象引用，就必须要做保护性拷贝，这是非常重要的。\n\n指导方针：\n\n - 对于对象引用域必须保持为私有的类，要保护性的拷贝这些域中的每个对象。不可变类的可变组件就属于这一类别。\n - 对于任何约束条件，如果检查失败，则抛出一个InvalidObjectException异常。这些检查动作应该跟在所有的保护性拷贝之后。\n - 如果整个对象图在被反序列化之后必须进行验证，就应该使用ObjectInputValidation接口。\n - 无论是直接方式还是间接方式，都不要调用类中任何可被覆盖的方法。\n\n#### **77. 对于实例控制，枚举类型优先于readResolve**\n> readResolve特性允许你用readObject创建的实例代替另一个实例。对于一个正在被反序列化的对象，如果它的类定义了一个readResolve方法，并且具备正确的声明，那么在反序列化之后，新建对象上的readResolve方法就会被调用。然后该方法返回的对象引用将被返回，取代新建的对象。在这个特性的绝大多数用法中，指向新建对象的引用不需要再被保留，因此立即成为垃圾回收的对象。\n\n> 总而言之，应该尽可能地使用枚举dang来实施实例控制的约束条件。如果做不到，同时又需要一个既可序列化又是实例受控的类，就必须提供一个readResolve方法，并确保该类的所有实例域都为基本类型，或者时transient。\n\n#### **78. 考虑用序列化代理代替序列化实例**\n序列化代理模式相当简单：\n\n 1. 为可序列化的类设计一个私有的静态嵌套类，精确地表示外围类的实例的逻辑状态。这个嵌套类被称作序列化代理，它应该有一个单独的构造器，其参数类型就是那个外围类。这个构造器只从它的参数中复制数据：它不需要进行任何一致性检查或者保护性拷贝。从设计的角度来看，序列化代理的默认序列化形式是外围类最好的序列化形式。外围类及其序列代理都必须声明实现Serializable接口。\n\t \n\t```\n\tprivate static class SerializationProxy implements Serializable {\n\t\tprivate final Date start;\n\t\tprivate final Date end;\n\t\n\t\tSerializationProxy(Period p) {\n\t\t\tthis.start = p.start;\n\t\t\tthis.end = p.end;\n\t\t}\n\t\tprivate static final long serialVerionUID = 302480420480234L;\n\t}\n\t```\n\n 2.  接下来，将下面的writeReplace方法添加到外围类中。通过序列化代理，这个方法可以被逐字复制到任何类中：\n \n\t```\n\tprivate Object writeReplace() {\n\t\treturn new SerializationProxy(this);\n\t}\n\t```\n这个方法的存在导致序列化系统产生一个SerializationProxy实例,代替外围类的实例。换句话说，writeReplace方法在序列化之前，将外围类的实例转变成了它的序列化代理。所以序列化系统永远不会产生外围类的序列化实例，为了避免攻击者伪造，只要在外围类中添加这个readObject方法即可：\n\n\t```\n\tprivate void readObject(ObjectInputStream s) throws InvalidationException {\n\t\tthrow new InvalidationException(\"Proxy required\");\n\t}\n\t```\n\n 3. 最后，在SerializationProxy类中提供一个readResolve方法，它返回一个逻辑上相当于外围类的实例。这个方法使序列化系统在反序列化时将序列化代理转变回外围类的实例。\n这个readResolve方法仅仅利用它的公有API创建外围类的一个实例，这正是该模式的魅力之所在。它极大地消除了序列化机制中语言本身之外的特征，因为反序列化实例是利用与任何其他实例相同的构造器、静态工厂和方法而创建的。这样就不必单独确保被反序列化的实例一定要遵守类的约束条件。如果该类的静态工厂或者构造器建立了这些约束条件，并且它的实例方法在维持着这些约束条件，你就可以确信序列化也会维持这些约束条件。\n上述Period.SerializationProxy的readResolve方法：\n\n\t```\n\tprivate Object readResolve() {\n\t\treturn new Period(start, end);\n\t}\n\t```\n\n---\n- 两个局限性：它不能与可以被客户端扩展的类兼容，它也不能与对象图中包含循环的某些类兼容：如果企图从一个对象的序列化代理的readResolve方法内部调用这个对象的方法，就会得到一个ClassCastException异常，因为还没有这个对象，只有它的序列化代理。\n-  代价：比保护性拷贝进行的开销大。\n- 当必须在一个不能被客户端扩展的类（final）上编写readObject或者writeObject方法的时候，就应该考虑使用序列化代理模式。","tags":["Java"],"categories":["读书笔记"]},{"title":"Android YuvImage直接旋转","url":"/2017/10/5fec38fe91ba/","content":"---\n操作相机的`Preview`可通过以下三种方式添加回调接口：\n<!--more--> \n```java\nCamera.setPreviewCallbackBuffer(PreviewCallback);\nCamera.setOneShotPreviewCallback(PreviewCallback);\nCamera.setPreviewCallback(PreviewCallback);\n```\n**PreviewCallback**接口里面只有一个回调方法:\n`void onPreviewFrame(byte[] data, Camera camera);`\n\n其中的`byte[] data`就是`Preview`的图像数据，格式为`YuvImage`，而这个图像天生是横着的，一般的旋转操作是:\nYuvImage的byte[] --> Bitmap的byte[] --> 生成Bitmap --> 旋转Bitmap\n---\n<!--more-->\n**示例代码**\n\n```java\npublic void onPreviewFrame(byte[] data, Camera camera) {\n        final int width = camera.getParameters().getPreviewSize().width;\n        final int height = camera.getParameters().getPreviewSize().height;\n        // 通过YuvImage得到Bitmap格式的byte[]\n        YuvImage yuvImage = new YuvImage(data, ImageFormat.NV21, width, height, null);\n        ByteArrayOutputStream out = new ByteArrayOutputStream();\n        yuvImage.compressToJpeg(new Rect(0, 0, width, height), 100, out);\n        byte[] dataBmp = out.toByteArray();\n        // 生成Bitmap\n        Bitmap bitmap = BitmapFactory.decodeByteArray(data, 0, dataBmp.length);\n        // 旋转\n        Matrix matrix = new Matrix();\n        matrix.setRotate(90);\n        Bitmap bmp = Bitmap.createBitmap(bitmap, 0, 0, width, height, matrix, false);\n        // 保存到本地\n        File file = new File(\"/storage/emulated/0/\" + System.currentTimeMillis() + \".jpg\");\n        try {\n            FileOutputStream fos = new FileOutputStream(file);\n            bmp.compress(Bitmap.CompressFormat.JPEG, 100, fos);\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n```\n\n## 原理\n---\n实际上，可以直接旋转YuvImage。Camera返回的数据格式默认是`NV21`，即YUV420的YV12，每4个Y共用一组UV分量。换句话说就是假设一张宽为`width`高为`height`的图像，共`sum = width * height`个像素点，那么Y分量一共`sum`个，U分量一共`sum/4`,V分量一共`sum/4`，YUV同RGB类似，都是用来表示图像属性，YUV各占1个byte，所以存储该图像的byte[] 的长度为YUV的数量之和，3/2*sum。\n例如，一张4像素x4像素的图片，存储格式为\n![](https://i.loli.net/2021/07/06/kEtbGrWgdw7qY14.png)\n**每个像素点都有YUV3个分量**，一个方格代表1byte，Y分量顺序排列，之后VU分量交叉排列，Y1、Y2、Y5、Y6共用V1U1分量，也就是说第1个像素点为[Y1 V1 U1]，第2个像素点为[Y2 V1 U1]，第5个像素点[Y5 V1 U1]，第6个像素点[Y6 V1 U1]，同理颜色相同都共用。有了上面的基础再来说旋转，图像旋转就是改变数组中YUV各个分量的位置，变换之后要保证共用关系不能变，即Y1、Y2、Y5、Y6还要共用V1、U1分量，顺时针旋转90度后如下\n![](https://i.loli.net/2021/07/06/v1AquyOJP5bhQfL.png)\n由图可以看出，**简单说就是Y分量部分和VU分量部分分别旋转**\n有了以上的基础，再来总结一下顺时针旋转90后角标对应关系：\n旋转前的图：srcWidth、srcHeight\n旋转后的图：dstWidth、dstHeight（旋转前后宽高对调，即sW=dH、sH=dW）\n先看Y分量，假设旋转后的图中第i行，第j列的一个像素，它的Y分量为(i, j)，它在旋转(顺时针旋转90度)前的位置为(srcHeight-1-j, i)；\n再看VU分量，因为`NV21`格式每组UV分量有4个Y分量共用，所以只要随着4个中的一个改变一次就可以了，我选择让VU分量跟着左上角的Y分量一起变换（例如，V1U1跟着旋转后的Y5变换）即，当(i, j)为左上角的Y时，这个时候它对应旋转前的4个分量中左下角的Y（后Y5和前Y5），前Y5的VU分量，放到后Y5VU分量的位置即可，当进行到旋转后的图4个Y分量中的其他3个分量时不再进行VU分量的操作；\nY分量与其对应的VU分量的行角标对应关系为：目标VU行角标 = Y行角标 + 图像的高。\n## 实践（上面不懂不重要，代码可以直接用~）\n---\n\n```java\n  public void onPreviewFrame(final byte[] data, Camera camera) {\n\t\t// 将系统回调的数组拷贝一份,操作拷贝的数据\n        byte[] dataCopy = new byte[data.length];\n        System.arraycopy(srcData, 0, dataCopy , 0, data.length);\n        Camera.Size size = camera.getParameters().getPreviewSize();\n        final int srcWidth = size.width;\n        final int srcHeight = size.height;\n        final int dstWidth = size.height;\n        final int dstHeight = size.width;\n        // 1.5倍的总数,多出来的部分装VU分量\n        byte[] buf = new byte[dstWidth * dstHeight * 3 / 2];\n\n        for (int i = 0; i < dstHeight; i++) {\n            for (int j = 0; j < dstWidth; j++) {\n                // 新数组中摆放Y值 旋转后(i,j) --> 旋转前(srcHeight-1-j, i)\n                buf[i * dstWidth + j] = dataCopy[(srcHeight - 1 - j) * srcWidth + i];\n                // 确认是左上角的点\n                if (i % 2 == 0 && j % 2 == 0) {\n                    // 摆放V值 目标行号= 行号/2 + 高\n                    buf[(i / 2 + srcWidth) * dstWidth + j] = dataCopy[((srcHeight - 1 - j) / 2 + srcHeight) * srcWidth + j];\n                    // 摆放U值\n                    buf[(i / 2 + srcWidth) * dstWidth + j + 1] = dataCopy[((srcHeight - 1 - j) / 2 + srcHeight) * srcWidth + j + 1];\n                }\n            }\n        }\n        \n        YuvImage yuvImage = new YuvImage(buf, ImageFormat.NV21, dstWidth, dstHeight, null);\n\n        File file = new File(\"/storage/emulated/0/\" + System.currentTimeMillis() + \".jpg\");\n        try {\n            FileOutputStream fos = new FileOutputStream(file);\n            yuvImage.compressToJpeg(new Rect(0, 0, dstWidth, dstHeight), 100, fos);\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n}\n```","tags":["Android","Yuv"],"categories":["Android"]},{"title":"ScrollView在SlidingUpPanelLayout中下滑无效问题","url":"/2017/10/208c39b1bdad/","content":"\n当在`ScrollableView`(即, 可上下滑动的ViewGroup)中含有`ScrollView`时，向上滑动`ScrollableView`至其全部上移展示出来时，继续向上滑动时`ScrollView`会响应滑动事件向上滑动，但是此时抬起手后再向下滑动时，首先响应滑动事件的是`ScrollabldView`，这就导致`ScrollView`无法下滑，解决该问题一种简单有效的实践：\n<!--more--> \n```java\nSlidingUpPanelLayout.setScrollableView(ScrollView)\n```\n\n**用`ScrollView`替换整个滑动的ViewGroup**\n","tags":["Android","SlidingUpPanelLayout"],"categories":["Android"]},{"title":"手把手教你实现RecyclerView的下拉刷新和上拉加载更多","url":"/2017/10/a9bb97b2a678/","content":"---\n\n纵观多数App，下拉刷新和上拉加载更多是很常见的功能，但是谷歌官方只有一个SwipeRefreshLayout用来下拉刷新，上拉加载更多还要自己做。\n\n基于RecyclerView简单封装了这两个操作，下拉刷新支持LinearLayoutManager、GridLayoutManager和StaggeredGridLayoutManager;上拉加载更多只支持前两者。\n\n<!--more-->\n----------\n\n\n#### 话不多说先上效果图 数据来自[**干货集中营**](http://gank.io/api)\n\n![](https://i.loli.net/2021/07/03/O6JtWNRBz7n1udD.gif)\n(下拉刷新）\n\n![](https://i.loli.net/2021/07/03/Rygwk9KZPBGaNnv.gif)\n（上拉加载更多 -- LinearLayoutManager）\n\n![](https://i.loli.net/2021/07/03/j7mqzU3PDXOYFpE.gif)\n（上拉加载更多 -- GridLayoutManager）\n\n\n----------\n\n\n### (一) 使用方式，很简单 如下：\n\n* **1. 下拉刷新 3步走**\n\n**1.1 布局文件**\n\t\n```xml\n// 用SwipeRefreshLayout包裹RecyclerView\n<android.support.v4.widget.SwipeRefreshLayout\n\t        android:id=\"@+id/gank_swipe_refresh_layout\"\n\t        android:layout_width=\"match_parent\"\n\t        android:layout_height=\"match_parent\">\n\t\n<android.support.v7.widget.RecyclerView\n\t         android:id=\"@+id/gank_recycler_view\"\n\t            android:layout_width=\"match_parent\"\n\t            android:layout_height=\"match_parent\"\n\t            android:overScrollMode=\"never\"/>\n</android.support.v4.widget.SwipeRefreshLayout>\n```\n\t\n\n\n**1.2 给`SwipeRefreshLayout` 添加监听 增加触发刷新时的操作(比如重新请求数据)**\n\n```java\nSwipeRefreshLayout swipeRefreshLayout = findViewById();\nswipeRefreshLayout.setOnRefreshListener(new swipeRefreshLayout.OnRefreshListener() {\n            @Override\n            public void onRefresh() {\n\t            // do something, such as re-request from server or other\n            }\n        });\n```\n\n**1.3 刷新操作(重新请求数据)完成后要回调来停止隐藏刷新动画(中上方圆形悬浮进度条旋转动画)**\n\n```java\nswipeRefreshLayout.setRefreshing(false);\n```\n\t\n**至此下拉刷新完成**\n<br/>\n\n* **2.上拉加载3步走**\n\n**2.1 初始化`AdapterWrapper`和`SwipeToLoadHelper`**\n```java\n// adapter是你自己为RecyclerView写的Adapter\nRecyclerView.Adapter adapter = new YourOwnAdapter();\nAdapterWrapper adapterWrapper = new AdapterWrapper(adapter);\nRecyclerView recyclerView = findViewById();\n// 将RecyclerView和刚创建的adapterWrapper传入\nSwipeToLoadHelper helper = new SwipeToLoadHelper(recyclerView, adapterWrapper);\n```\n**2.2 设置加载动作触发后的监听**\n```java\nhelper.setLoadMoreListener(new SwipeToLoadHelper.LoadMoreListener() {\n            @Override\n            public void onLoad() {\n            // do something, such as request more data from server or other.\n            }\n        })\n```\n**2.3 加载更多内容完成后要回调方法停止动画**\n```java\nhelper.setLoadMoreFinish()\n```\n**至此上拉加载完成 (注意更新数据时要调用`AdapterWrapper.notifyDataSetChanged`)**\n\n---\n\n### (二) 简明扼要的实现思路(上拉加载操作)\n\n> `RecyclerView`的`itemView`的显示情况分为四种：\n> \n> 1. 第1个可见的（部分显示或者完全显示都算可见）\n> 2. 第1个可见的且是完整的（完全显示算作完整的）\n> 3. 最后1个可见的\n> 4. 最后1个可见的且是完整的\n\n* **1. 回弹效果**\n即手指抬起滑动停止，`上拉加载更多`部分显示时，将`上拉加载更多`滚动到不显示，使上面挨着它的`itemView`为最后1个可见且是最后1个完整可见。<br/>\n监听`RecyclerView`的滚动，当`RecyclerView`处于`SCROLL_STATE_IDLE` 状态时，获取最后1个完整可见的`itemView`：如果是倒数第2个`item`则计算该`item`的下边距到`RecyclerView`底部的距离`deltaY`，然后将`RecyclerView`向下滚动`deltaY`；如果是`上拉加载更多`则触发加载操作；其他情况不用处理。\n\n```java\n// 关键代码 rv : recyclerView\nint lcp = layoutManager.findLastCompletelyVisibleItemPosition();\nif (lcp == layoutManager.getItemCount() - 2) {\n\t// 倒数第2项\n\tint fcp = layoutManager.findFirstCompletelyVisibleItemPosition();\n    View child = layoutManager.findViewByPosition(lcp);\n    int deltaY = rv.getBottom() - rv.getPaddingBottom() - \n\t\t\t\t    child.getBottom();\n\t// fcp为0时说明列表滚动到了顶部, 不再滚动\n    if (deltaY > 0 && fcp != 0) {\n\t      rv.smoothScrollBy(0, -deltaY);\n    }\n} else if (lcp == layoutManager.getItemCount() - 1) {\n    // 最后一项完全显示, 触发操作, 执行加载更多操作\n    if (listener != null) {\n\t    listener.onLoad();\n    }\n}\n```\n<br/>\n\n* **2. 添加底部`加载更多`itemView**\n\n2.1 `AdapterWrapper`重写了`getItemCount`方法，保证得到`itemView`的数量包括`加载更多`。当是`LinearLayoutManager`类型时直接加1；当是`GridLayoutManager`类型时，如果需要则先将列表最后一行填满，再加1。比如：列表每行有3个`itemView`，最后一行只有1个，这时就需要先加2，再加1，来保证`加载更多`占据完整的一行。\n\n```java\n// 关键代码 其中的adapter为构造函数中传入的原生RecyclerView.Adapter\nif (adapterType == ADAPTER_TYPE_LINEAR) {\n\t// 线性布局\n\treturn adapter.getItemCount() + 1;\n} else {\n\t// 网格布局 spanCount为每行itemView的个数\n    int remain = adapter.getItemCount() % spanCount; // 余数\n    if (remain == 0) {\n\t    return adapter.getItemCount() + 1;\n    }\n    // 余数不为0时,先凑满再加1\n    return adapter.getItemCount() + 1 + (spanCount - remain);\n}\n```\n\n2.2 `AdapterWrapper`重写了`getItemViewType`方法，当是最后一个位置时返回`ITEM_TYPE_LOAD`\n\n```java\n// 关键代码\npublic int getItemViewType(int position) {\n    // 位置是最后一个时, wrapper进行拦截\n    if (osition == getItemCount() - 1) {\n        return ITEM_TYPE_LOAD;// 要避免和原生adapter返回值可能重复\n    }\n    // 其他情况交给原生adapter处理\n    return adapter.getItemViewType(position);\n}\n```\n\n2.3 `AdapterWrapper`重写了`onCreateViewHolder`方法，当类型为`ITEM_TYPE_LOAD`时返回`加载更多`的`ViewHolder`，其他情况交给原生的`adapter`处理。\n\n```java\n// 关键代码\npublic RecyclerView.ViewHolder onCreateViewHolder(ViewGroup parent, int viewType) {\n    if (viewType == ITEM_TYPE_LOAD) {\n        return new LoadMoreHolder();\n    } else {\n        return adapter.onCreateViewHolder(parent, viewType);\n    }\n}\n```\n\n2.4 `AdapterWrapper`重写了`onBindViewHolder`，这里有三种可能的情况：1. 正常的数据项`itemView`，交给`adapter`处理；2. `GridView`的空白`itemView`，隐藏处理；3. 底部的`加载更多`，目前不需要做什么处理。\n\n```java\n// 关键代码\npublic void onBindViewHolder(RecyclerView.ViewHolder holder, int position) {\n    if (position == getItemCount() - 1) {\n    } else if (position < adapter.getItemCount()){\n        adapter.onBindViewHolder(holder, position);\n    } else {\n        holder.itemView.setVisibility(View.INVISIBLE);\n    }\n }\n```\n----\n### (三) 额外的两个说明\n* `SwipeFreshLayout`有个`setEnable(boolean)`方法，设置为`false`的时候就下拉刷新功能就没有了，等同于普通的`RecyclerView`\n* 同样`SwipeToLoadHelper`有个`setSwipeToLoadEnabled(boolean)`方法，设置为`false`的时候上拉加载功能就没有了， 等同于普通的`RecyclerView`\n\n---\n#### **如有问题，欢迎指正~**\n\n附[项目仓库地址](https://github.com/oynix/wraprecyclerview)，如有需要请自取~\n","tags":["Android","RecyclerView","自定义控件"],"categories":["Android"]},{"title":"几分钟完成发布开源库到jCenter","url":"/2017/10/31c771f65733/","content":"---\n\n在AndroidStudio中导入开源库一般就是一句话的事：`compile 'xxx.xx.xx:xx'`。 实际上我们也可以通过这种方式来导入自己的开源库，方便自己的使用。AndroidStudio执行`compile 'xxx.xxx.xx:xx'` 会先到jCenter上查找该开源库，所以需要我们把自己的开源库库发布到jCenter上。无法直接在jCenter上发布开源库，要通过它的托管商--Bintray（Bintray托管着很多仓库，jCenter只是其中一个）来完成。\n\n把自己平时经常用到的一些代码写到一起上传到jCenter，以后不管做什么项目一句话就能导入，算来还是一个比较实用的功能。\n<!--more-->\n#### 总体步骤概览\n\n >  [1. 注册Bintray账号并创建仓库](#step1)\n    [2. 准备开源库](#step2)\n    [3. 修改gradle文件](#step3)\n    [4. 编译并上传至Bintray](#step4)\n    [5. linked to jCenter](#step5)\n\n\n----------\n<h3 id=\"step1\"> 1. 注册Bintray账号并创建仓库</h3>\n\n使用Bintray当然要先注册个账号，[注册地址](https://bintray.com/signup/oss)\n\n![注册界面](https://i.loli.net/2021/07/02/nDrYj29khgLP3HQ.png)\n我选的是`Sign up with Github`。\n注册登录之后应该是这个样子， 点击`Add New Repository`\n\n![](https://i.loli.net/2021/07/02/lSWt5zHh7qaBY1r.png)\n![](https://i.loli.net/2021/07/02/7gemVscRGIrH2MQ.png)\n\n* Name：仓库的名字，写了之后不能再改，记住该名字，后面上传时会用到；\n* Type：仓库类型，选择`Maven`；\n* License：开源协议，随便选一个就好；\n* Description：仓库描述，随便写；\n\n**点击`Create` 完成仓库创建，到此第一步完成。**\n\n\n----------\n<h3 id=\"step2\"> 2. 准备开源库</h3>\n\n备好你想要上传的开源库，有两种方式：\n1. AndroidStudio中new一个project，然后在project中new一个Module，类型选择`Android Library`.\n2. 直接修改当前Module的build.gradle（**注意区分project的build.gradle文件和Module的build.gradle文件，前者在project根目录下，后者在对应的Module目录下**）文件，将第一行的`apply plugin: 'com.android.application` 改为 `apply plugin: com.android.library` ，再把下面的`applicationId \"你的包名\"` 这一行删除(library是不允许有applicationId的).\n\n两种方式最终结果都是得到了一个`Android Library` 类型的Module，在Module里添加你想要上传的开源库代码（我随便弄了一个，里面有个我常用到的加载App Icon的方法）。\n\n**到此第二步准备开源库完成**\n\n\n----------\n<h3 id=\"step3\"> 3. 修改gradle文件</h3>\n\n**还是那句话，注意区分project的build.gradle文件和Module的build.gradle文件，前者在project根目录下，后者在对应的Module目录下**\n\n* 修改project的build.gradle文件，添加下面这两句话\n![](https://i.loli.net/2021/07/02/3xVtoCEBzNfD6KT.png)\n[*Maven Github地址*](https://github.com/dcendents/android-maven-gradle-plugin)：对应里面的说明选择使用的版本号\n[*Bintray Github地址*](https://github.com/bintray/gradle-bintray-plugin)：对应里面的说明选择使用的版本号\n\n* 修改Module的build.gradle文件（这步有点乱，认真看）\n需要配置3个信息：\n1. Bintray账号配置和Developer信息，告诉AndroidStudio传到哪及开发者介绍；\n2. Project信息，开源库的介绍；\n3. 上传配置，对以上3个信息的调用以及其他一些配置；\n\n为了看起来条理清晰，我把能独立的部分都独立到单独文件里了，便于阅读，以下分别说明。\n\n**1. Bintray账号信息和Developer信息**\n`AndroidStudio`创建项目时默认会在project根目录下创建`local.properties` 文件并添加到了`.gitignore` 文件中（如果没有请自行创建并添加至`.gitignore` 中），在其中添加以下内容：\n\n![](https://i.loli.net/2021/07/02/NevJYK8bCSkWUV5.png)\n\n * bintray.user：Bintray注册的用户名\n * bintray.apikey：Bintray的API key\n * developer.id：开源社区的昵称（一般指github，或是使用的其他开源社区）\n * developer.name：姓名\n * developer.email：邮箱地址\n\n*查看API key方法：*\n![](https://i.loli.net/2021/07/02/cPX6dYtHeijrZbl.png)\n![](https://i.loli.net/2021/07/02/78qtx2wumGjSy1d.png)\n\n\n**2. Project信息配置**\n\n在***开源库Module目录***下新建`project.properties`文件，添加以下内容：\n\n![](https://i.loli.net/2021/07/02/ho8iIzSP3tBxJK4.png)\n\n* project.name：开源库名字\n* project.groupId：项目组ID，写包名\n* project.artifaceId：项目ID，写Module名\n* project.packaging：打包方式，写aar\n* project.siteUrl：项目主页，没有就写github地址\n* project.gitUrl：项目仓库地址\n* javadoc.name：javadoc主页显示的名称，写项目名字就好\n\n**3. 上传配置**\n\n在***开源库Module目录***下新建`bintrayUpload.gradle`文件，添加以下内容：(内容较多，直接贴源码了，阅读可能不太美观）\n\n```groovy\napply plugin: 'com.github.dcendents.android-maven'\napply plugin: 'com.jfrog.bintray'\n\n// load properties\nProperties properties = new Properties()\n\nFile projectPropertiesFile = project.file(\"project.properties\")\nif(projectPropertiesFile.exists()){\n    properties.load(projectPropertiesFile.newDataInputStream())\n}\n\n// read properties\ndef projectName = properties.getProperty(\"project.name\")\ndef projectGroupId = properties.getProperty(\"project.groupId\")\ndef projectArtifactId = properties.getProperty(\"project.artifactId\")\ndef projectVersionName = android.defaultConfig.versionName\ndef projectPackaging = properties.getProperty(\"project.packaging\")\ndef projectSiteUrl = properties.getProperty(\"project.siteUrl\")\ndef projectGitUrl = properties.getProperty(\"project.gitUrl\")\ndef javadocName = properties.getProperty(\"javadoc.name\")\n\n\nFile localPropertiesFile = project.rootProject.file(\"local.properties\")\nif(localPropertiesFile.exists()){\n    properties.load(localPropertiesFile.newDataInputStream())\n}\ndef developerId = properties.getProperty(\"developer.id\")\ndef developerName = properties.getProperty(\"developer.name\")\ndef developerEmail = properties.getProperty(\"developer.email\")\n\ndef bintrayUser = properties.getProperty(\"bintray.user\")\ndef bintrayApikey = properties.getProperty(\"bintray.apikey\")\n\n\ngroup = projectGroupId\n\n// This generates POM.xml with proper parameters\ninstall {\n    repositories.mavenInstaller {\n        pom {\n            project {\n                name projectName\n                groupId projectGroupId\n                artifactId projectArtifactId\n                version projectVersionName\n                packaging projectPackaging\n                url projectSiteUrl\n                licenses {\n                    license {\n                        name 'The Apache Software License, Version 2.0'\n                        url 'http://www.apache.org/licenses/LICENSE-2.0.txt'\n                    }\n                }\n                developers {\n                    developer {\n                        id developerId\n                        name developerName\n                        email developerEmail\n                    }\n                }\n                scm {\n                    connection projectGitUrl\n                    developerConnection projectGitUrl\n                    url projectSiteUrl\n                }\n            }\n        }\n    }\n}\n\n// This generates sources.jar\ntask sourcesJar(type: Jar) {\n    from android.sourceSets.main.java.srcDirs\n    classifier = 'sources'\n}\n\ntask javadoc(type: Javadoc) {\n    source = android.sourceSets.main.java.srcDirs\n    classpath += project.files(android.getBootClasspath().join(File.pathSeparator))\n}\n\n// This generates javadoc.jar\ntask javadocJar(type: Jar, dependsOn: javadoc) {\n    classifier = 'javadoc'\n    from javadoc.destinationDir\n}\n\nartifacts {\n    archives javadocJar\n    archives sourcesJar\n}\n\n// javadoc configuration\njavadoc {\n    options{\n        encoding \"UTF-8\"\n        charSet 'UTF-8'\n        author true\n        version projectVersionName\n        links \"http://docs.oracle.com/javase/7/docs/api\"\n        title javadocName\n    }\n}\n\n// bintray configuration\nbintray {\n    user = bintrayUser\n    key = bintrayApikey\n    configurations = ['archives']\n    pkg {\n        repo = \"maven\"\n        name = projectName\n        websiteUrl = projectSiteUrl\n        vcsUrl = projectGitUrl\n        licenses = [\"Apache-2.0\"]\n        publish = true\n    }\n}\n```\n\n上传开源库的配置基本都是这样，不用改动什么，值得注意的是`bintray` 节点的`repo` 指的是第一步中创建的Maven仓库的名字，这两个名字要一致；此外开源库的版本号默认取的是project的版本号`def projectVersionName = android.defaultConfig.versionName`，如果有需要也可把这两个属性抽取到`project.properties` 文件中，便于管理。\n\n最后一个操作，在***开源库Module***的`build.gradle` 文件末尾中添加如下代码`apply from: 'bintrayUpload.gradle'` 来调用配置文件。\n\n**至此第3步配置gradle文件完成。**\n\n\n----------\n<h3 id=\"step4\"> 4. 编译并上传至Bintray</h3>\n\n* 编译：打开AndroidStudio的Terminal窗口（一般在底部，没有的话点击`顶部工具栏`->`View`->`Tools Windows`-> `Terminal`），输入命令并回车：\n\n> gradlew install\n\n等待一段时间后提示`BUILD SUCCESSFUL`，表示成功。\n\n* 上传，同样在Terminal中输入以下命令并回车：\n\n> gradlew bintrayUpload\n\n\n等待一段时间后提示`BUILD SUCCESSFUL`，表示成功。\n\n**至此第4步编译并上传完成。**\n\n\n----------\n<h3 id=\"step5\"> 5. Linked to jCenter</h3>\n\n![](https://i.loli.net/2021/07/02/LZm2MYtP8XJ1RjU.png)\n\n![](https://i.loli.net/2021/07/02/HKzyexF9aZscOdW.png)\n\n![](https://i.loli.net/2021/07/02/CNPLzhVtXdxnRI8.png)\n\n![](https://i.loli.net/2021/07/02/Ed6kULb9QNpMDAa.png)\n\n**按照上面4步，发送include request之后等待Bintray团队审核，审核完成后会收到邮件和站内信。**\n\n![](https://i.loli.net/2021/07/02/bdaZXRcOkflTy96.png)\n\n**至此第5步Linked to jCenter完成。**\n\n\n----------\n\n### 如果遇到问题，请参考这两篇文章\n\n1. [Android 项目打包到 JCenter 的坑](http://www.jianshu.com/p/c721f9297b2f?utm_campaign=hugo&utm_medium=reader_share&utm_content=note)\n2. [Android 发布项目到 JCenter 遇到的各种坑](http://www.jianshu.com/p/c518a10fdaed)\n\n\n#### **如有问题，欢迎指正~**","tags":["Android","jCenter"],"categories":["Android"]},{"title":"Android Drawable 和 xml文件转化关系","url":"/2017/09/8b0716318a1c/","content":"---\nDrawable类既可以在代码中创建也可以在xml文件中设置，以下是各类型的对应关系。\n<!--more-->\n`<selector />`---------`StateListDrawable`  \n`<level-list />`---------`LevelListDrawable`  \n`<layer-list />`---------`LayerDrawable`  \n`<transition />`---------`TransitionDrawable`  \n`<color />`---------`ColorDrawable`  \n`<shape />`---------`GradientDrawable`  \n`<scale />`---------`ScaleDrawable`  \n`<clip />`---------`ClipDrawable`  \n`<rotate/>`---------`RotateDrawable`  \n`<animation-list />`---------`AnimationDrawable`  \n`<inset />`---------`InsetDrawable`  \n`<bitmap/>`---------`BitmapDrawable`  \n`<nine-patch />`---------`NinePatchDrawable`  \n`<stupid-tag />`---------`Resources.NotFoundException`  ","tags":["Android","Drawable"],"categories":["Android"]},{"title":"Android改变图片属性之饱和度","url":"/2017/09/992c82f9c39e/","content":"---\n简单实现改变图片饱和度\n<!--more-->\n```\n ImageView image = (ImageView) findViewById(R.id.image);\n ColorMatrix matrix = new ColorMatrix();\n matrix.setSaturation(0f);\n image.setColorFilter(new ColorMatrixColorFilter(matrix));\n```\n\n**通过设置Matrix的参数来实现.**","tags":["Android","图片饱和度"],"categories":["Android"]},{"title":"Android 自定义样式通知栏的坑RemoteServiceException","url":"/2017/07/373186e06a55/","content":"---\nAndroid 自定义样式通知栏的坑RemoteServiceException\n```\nAndroid.app.RemoteServiceException: Bad notification posted from packagecom.my.package:\n\n```\n\n是的，就是这个异常。\n\n<!--more-->\n----------\n没有使用系统提供的三个方法\n\n```\nsetContentText（）\nsetContentTitle（）\nsetSmallIcon（）\n```\n而用的是`RemoteViews`，然后就掉坑里了。\n\n**原因是这样的，请往下看~**\n\n1. 布局中的控件只有**7种**，除此之外，均会报错！\n```\nAnalogClock，Button，Chronometer，ImageButton，mageView，ProgressBar，TextView\n```\n\n2. 另外还有一个问题，就是控件长宽的设定，必须为`0dp`，`wrap_content`或者`match_parent`，除此之外，也均会报错！\n\n```\nif (layoutWidth != 0 && layoutWidth != ViewGroup.LayoutParams.MATCH_PARENT\n            && layoutWidth != ViewGroup.LayoutParams.WRAP_CONTENT) {\n        throw new IllegalArgumentException(\"Only supports 0, WRAP_CONTENT and MATCH_PARENT\");\n    }\n```\n**这就是原因，内部会检测。但不知为何，我接收到的都是文章开头提到的那个异常，让人苦恼。**\n","tags":["Android","RemoteServiceException"],"categories":["Android"]},{"title":"Android获取系统相册所有图片","url":"/2017/06/eccdf08dbb5b/","content":"---\n\n### 直接获取所有照片的信息，而不是打开照片选择页面\n<!--more-->\n```java\n  private ArrayList<CategoryFile> queryCategoryFilesSync(FileType type) {\n    ArrayList<CategoryFile> files = new ArrayList<>();\n    Uri uri = MediaStore.Images.Media.getContentUri(\"external\");\n    if (uri != null) {\n        String[] projection = new String[]{FileColumns._ID, // id\n                FileColumns.DATA, // 文件路径\n                FileColumns.SIZE, // 文件大小\n                FileColumns.DATE_MODIFIED}; // 修改日期\n        Cursor cursor = getContentResolver().query(uri, projection, null, null, null);\n        if (cursor != null) {\n            try {\n                if (cursor.moveToFirst()) {\n                    final int pathIdx = cursor\n                            .getColumnIndex(FileColumns.DATA);\n                    final int sizeIdx = cursor\n                            .getColumnIndex(FileColumns.SIZE);\n                    final int modifyIdx = cursor\n                            .getColumnIndex(FileColumns.DATE_MODIFIED);\n                    do {\n                        String path = cursor.getString(pathIdx);\n                        CategoryFile file = new CategoryFile();\n                        file.mType = type;\n                        file.mPath = path;\n                        file.mParent = FileUtil.getPathFromFilepath(file.mPath);\n                        file.mName = FileUtil.getNameFromFilepath(file.mPath);\n                        file.mSize = cursor.getLong(sizeIdx);\n                        file.mLastModifyTime = cursor.getLong(modifyIdx);\n                        files.add(file);\n                    } while (cursor.moveToNext());\n                }\n            } catch (Exception e) {\n                e.printStackTrace();\n            } finally {\n                cursor.close();\n            }\n        }\n    }\n    return files;\n }\n```\n\n其中`CategoryFile`为存储照片信息的Bean类\n### FileUtil类\n```java\npublic class FileUtil {\n\n    private static final char UNIX_SEPARATOR = '/';\n\n    public static String getPathFromFilepath(String filepath) {\n        if (!TextUtils.isEmpty(filepath)) {\n            int pos = filepath.lastIndexOf(UNIX_SEPARATOR);\n            if (pos != -1) {\n                return filepath.substring(0, pos);\n            }\n        }\n        return \"\";\n    }\n\n    public static String getNameFromFilepath(String filepath) {\n        if (!TextUtils.isEmpty(filepath)) {\n            int pos = filepath.lastIndexOf(UNIX_SEPARATOR);\n            if (pos != -1) {\n                return filepath.substring(pos + 1);\n            }\n        }\n        return \"\";\n    }\n}\n```","tags":["Android"],"categories":["Android"]},{"title":"正则表达式(Regular Expression)","url":"/2017/05/cbfcda6ce2f5/","content":"---\n\n***整理参考于** : http://www.runoob.com/regexp/regexp-tutorial.html*\n<!--more-->\n\n## **一. 简介**\n\n\n#### ^[0-9]+abc$\n - `^` 为匹配输入字符串的开始位置。\n - `[0-9]+` 匹配多个数字 `[0-9]` 匹配单个数字 `+` 匹配一个或者多个\n - `abc$`匹配字母 `abc` 并以 `abc` 结尾，`$` 为匹配输入字符串的结束位置。\n\n\n## **二. 语法**\n\n正则表达式(regular expression)描述了一种字符串匹配的模式（pattern），可以用来检查一个串是否含有某种子串、将匹配的子串替换或者从某个串中取出符合某个条件的子串等。\n例如：\n\n - runoo+b，可以匹配 runoob、runooob、runoooooob 等，**`+` 号代表前面的字符必须至少出现一次（1次或多次）**。\n - runoo*b，可以匹配 runob、runoob、runoooooob 等，**`*` 号代表前面的字符可以不出现，也可以出现一次或者多次（0次、或1次、或多次）**。\n - colou?r 可以匹配 color 或者 colour，**`?` 问号代表前面的字符最多只可以出现一次（0次、或1次）**。\n\n\n## **三. 字符分类**\n\n### 1. 普通字符\n普通字符包括没有显式指定为元字符的所有可打印和不可打印字符。这包括所有大写和小写字母、所有数字、所有标点符号和一些其他符号。\n\n\n### 2. 非打印字符\n非打印字符也可以是正则表达式的组成部分。下表列出了表示非打印字符的转义序列：\n   字符 | 描述    \n  :: | \n\\cx\t|匹配由x指明的控制字符。例如， \\cM 匹配一个 Control-M 或回车符。x 的值必须为 A-Z 或 a-z 之一。否则，将 c 视为一个原义的 'c' 字符。\n\\f\t|匹配一个换页符。等价于 \\x0c 和 \\cL。\n\\n\t|匹配一个换行符。等价于 \\x0a 和 \\cJ。\n\\r\t|匹配一个回车符。等价于 \\x0d 和 \\cM。\n\\s\t|匹配任何空白字符，包括空格、制表符、换页符等等。等价于 [ \\f\\n\\r\\t\\v]。\n\\S\t|匹配任何非空白字符。等价于 [^ \\f\\n\\r\\t\\v]。\n\\t\t|匹配一个制表符。等价于 \\x09 和 \\cI。\n\\v\t|匹配一个垂直制表符。等价于 \\x0b 和 \\cK。\n\n\n### 3. 特殊字符\n所谓特殊字符，就是一些有特殊含义的字符，如上面说的 `runoo*b` 中的` *`，简单的说就是表示任何字符串的意思。如果要查找字符串中的` *` 符号，则需要对` *` 进行转义，即在其前加一个` \\: runo\\*ob` 匹配 `runo*ob`。\n许多元字符要求在试图匹配它们时特别对待。若要匹配这些特殊字符，必须首先使字符\"转义\"，即，将反斜杠字符\\ 放在它们前面。下表列出了正则表达式中的特殊字符：\n\n  特别字符 | 描述\n  :-----:|-----\n \\$ | 匹配输入字符串的结尾位置。如果设置了 RegExp 对象的 Multiline 属性，则 $ 也匹配 '\\n' 或 '\\r'。要匹配 $ 字符本身，请使用 \\$。\n( )\t|标记一个子表达式的开始和结束位置。子表达式可以获取供以后使用。要匹配这些字符，请使用 \\( 和 \\)。\n\\*\t| 匹配前面的子表达式零次或多次。要匹配 `*` 字符，请使用 `\\*`。\n\\+\t|  匹配前面的子表达式一次或多次。要匹配 `+` 字符，请使用 `\\+`。\n\\.\t| 匹配除换行符 \\n 之外的任何单字符。要匹配 `.` ，请使用 `\\.` 。\n\\[\t| 标记一个中括号表达式的开始。要匹配 `[`，请使用 `\\[`。\n?\t| 匹配前面的子表达式零次或一次，或指明一个非贪婪限定符。要匹配 `?` 字符，请使用 `\\?`。\n\\\t| 将下一个字符标记为或特殊字符、或原义字符、或向后引用、或八进制转义符。例如， `'n'` 匹配字符 `'n'`。`'\\n'` 匹配换行符。序列 `'\\\\'` 匹配 `\"\\\"`，而 `'\\('` 则匹配 `\"(\"`。\n^\t| 匹配输入字符串的开始位置，除非在方括号表达式中使用，此时它表示不接受该字符集合。要匹配 `^` 字符本身，请使用 `\\^`。\n{\t| 标记限定符表达式的开始。要匹配 `{`，请使用 `\\{`。\n\\|\t| 指明两项之间的一个选择。要匹配 `|`，请使用 `\\|`。\n\n### 4. 限定符\n限定符用来指定正则表达式的一个给定组件必须要出现多少次才能满足匹配。有 * 或 + 或 ? 或 {n} 或 {n,} 或 {n,m} 共6种。\n正则表达式的限定符有：\n\n字符 | \t描述\n:-----:|-----\n\\*|\t匹配前面的子表达式零次或多次。例如，`zo*` 能匹配 `\"z\"` 以及 `\"zoo\"`。`*` 等价于`{0,}`。\n\\+|匹配前面的子表达式一次或多次。例如，`'zo+'` 能匹配 `\"zo\"` 以及 `\"zoo\"`，但不能匹配 `\"z\"`。`+` 等价于 `{1,}`。\n?|\t匹配前面的子表达式零次或一次。例如，`\"do(es)?\"` 可以匹配 `\"do\"` 或 `\"does\"` 中的`\"do\"` 。`?` 等价于 `{0,1}`。\n{n}\t|`n`是一个非负整数。匹配确定的 `n` 次。例如，`'o{2}'` 不能匹配 `\"Bob\"` 中的 `'o'`，但是能匹配 `\"food\"` 中的两个 `o`。\n{n,}|`n` 是一个非负整数。至少匹配`n` 次。例如，`'o{2,}'` 不能匹配 `\"Bob\"` 中的 `'o'`，但能匹配 `\"foooood\"` 中的所有 `o`。`'o{1,}'` 等价于 `'o+'`。`'o{0,}'` 则等价于 `'o*'`。\n{n,m}|`m` 和 `n` 均为非负整数，其中`n <= m`。最少匹配 `n` 次且最多匹配 `m` 次。例如，`\"o{1,3}\"` 将匹配 `\"fooooood\"` 中的前三个 `o`。`'o{0,1}'` 等价于 `'o?'`。请注意在逗号和两个数之间不能有空格。\n\n 由于章节编号在大的输入文档中会很可能超过九，所以您需要一种方式来处理两位或三位章节编号。限定符给您这种能力。下面的正则表达式匹配编号为任何位数的章节标题：\n`/Chapter [1-9][0-9]*/`\n\n请注意，限定符出现在范围表达式之后。因此，它应用于整个范围表达式，在本例中，只指定从 0 到 9 的数字（包括 0 和 9）。\n这里不使用 `+` 限定符，因为在第二个位置或后面的位置不一定需要有一个数字。也不使用`？`字符，因为它将章节编号限制到只有两位数。您需要至少匹配 Chapter 和空格字符后面的一个数字。\n如果您知道章节编号被限制为只有 99 章，可以使用下面的表达式来至少指定一位但至多两位数字。\n`/Chapter [0-9]{1,2}/`\n\n上面的表达式的缺点是，大于 99 的章节编号仍只匹配开头两位数字。另一个缺点是 Chapter 0 也将匹配。只匹配两位数字的更好的表达式如下：\n`/Chapter [1-9][0-9]?/`\n\n或\n`/Chapter [1-9][0-9]{0,1}/`\n\n`*`、`+`和`?`限定符都是贪婪的，因为它们会尽可能多的匹配文字，只有在它们的后面加上一个?就可以实现非贪婪或最小匹配。\n例如，您可能搜索 HTML 文档，以查找括在 H1 标记内的章节标题。该文本在您的文档中如下：\n>```<H1>Chapter 1 - 介绍正则表达式</H1>```\n\n**贪婪**：下面的表达式匹配从开始小于符号 (<) 到关闭 H1 标记的大于符号 (>) 之间的所有内容。\n`/<.*>/`\n\n**非贪婪**：如果您只需要匹配开始和介绍 H1 标记，下面的非贪婪表达式只匹配 `<H1>`。\n`/<.*?>/`\n\n如果只想匹配开始的 H1 标签，表达式则是：\n`/<\\w+?>/`\n\n通过在`*`、`+` 或 `?` 限定符之后放置 `?`，该表达式从\"贪心\"表达式转换为\"非贪心\"表达式或者最小匹配。\n\n### 5. 定位符\n定位符使您能够将正则表达式固定到行首或行尾。它们还使您能够创建这样的正则表达式，这些正则表达式出现在一个单词内、在一个单词的开头或者一个单词的结尾。\n定位符用来描述字符串或单词的边界，`^` 和`$` 分别指字符串的开始与结束，`span class=\"marked\">\\b` 描述单词的前或后边界，`span class=\"marked\">\\B` 表示非单词边界。\n正则表达式的限定符有：\n\n字符 |\t描述\n:-----:|-----\n^\t|匹配输入字符串开始的位置。如果设置了 RegExp 对象的 Multiline 属性，^ 还会与 \\n 或 \\r 之后的位置匹配。\n\\$\t|匹配输入字符串结尾的位置。如果设置了 RegExp 对象的 Multiline 属性，$ 还会与 \\n 或 \\r 之前的位置匹配。\n\\b\t|匹配一个字边界，即字与空格间的位置。\n\\B\t|非字边界匹配。\n\n**注意**：不能将限定符与定位点一起使用。由于在紧靠换行或者字边界的前面或后面不能有一个以上位置，因此不允许诸如 `^*` 之类的表达式。\n若要匹配一行文本开始处的文本，请在正则表达式的开始使用 `^` 字符。不要将 `^` 的这种用法与中括号表达式内的用法混淆。\n若要匹配一行文本的结束处的文本，请在正则表达式的结束处使用 `$` 字符。\n若要在搜索章节标题时使用定位点，下面的正则表达式匹配一个章节标题，该标题只包含两个尾随数字，并且出现在行首：\n`/^Chapter [1-9][0-9]{0,1}/`\n\n真正的章节标题不仅出现行的开始处，而且它还是该行中仅有的文本。它即出现在行首又出现在同一行的结尾。下面的表达式能确保指定的匹配只匹配章节而不匹配交叉引用。通过创建只匹配一行文本的开始和结尾的正则表达式，就可做到这一点。\n`/^Chapter [1-9][0-9]{0,1}$/`\n\n匹配字边界稍有不同，但向正则表达式添加了很重要的能力。字边界是单词和空格之间的位置。非字边界是任何其他位置。下面的表达式匹配单词 Chapter 的开头三个字符，因为这三个字符出现字边界后面：\n`/\\bCha/`\n\n`\\b` 字符的位置是非常重要的。如果它位于要匹配的字符串的开始，它在单词的开始处查找匹配项。如果它位于字符串的结尾，它在单词的结尾处查找匹配项。例如，下面的表达式匹配单词 Chapter 中的字符串 ter，因为它出现在字边界的前面：\n`/ter\\b/`\n\n下面的表达式匹配 Chapter 中的字符串 apt，但不匹配 aptitude 中的字符串 apt：\n`/\\Bapt/`\n\n字符串 apt 出现在单词 Chapter 中的非字边界处，但出现在单词 aptitude 中的字边界处。对于 \\B 非字边界运算符，位置并不重要，因为匹配不关心究竟是单词的开头还是结尾。\n\n### 6. 选择\n用圆括号将所有选择项括起来，相邻的选择项之间用|分隔。但用圆括号会有一个副作用，是相关的匹配会被缓存，此时可用?:放在第一个选项前来消除这种副作用。\n\n其中 `?:` 是非捕获元之一，还有两个非捕获元是 `?=` 和 `?!`，这两个还有更多的含义，前者为正向预查，在任何开始匹配圆括号内的正则表达式模式的位置来匹配搜索字符串，后者为负向预查，在任何开始不匹配该正则表达式模式的位置来匹配搜索字符串。\n\n### 7. 反向引用\n对一个正则表达式模式或部分模式两边添加圆括号将导致相关匹配存储到一个临时缓冲区中，所捕获的每个子匹配都按照在正则表达式模式中从左到右出现的顺序存储。缓冲区编号从 1 开始，最多可存储 99 个捕获的子表达式。每个缓冲区都可以使用 `\\n` 访问，其中 `n` 为一个标识特定缓冲区的一位或两位十进制数。\n可以使用非捕获元字符 `?:`、`?=` 或 `?!` 来重写捕获，忽略对相关匹配的保存。\n\n反向引用的最简单的、最有用的应用之一，是提供查找文本中两个相同的相邻单词的匹配项的能力。以下面的句子为例：\n`Is is the cost of of gasoline going up up?`\n\n上面的句子很显然有多个重复的单词。如果能设计一种方法定位该句子，而不必查找每个单词的重复出现，那该有多好。\n\n\n## **四. 元字符**\n\n下表包含了元字符的完整列表以及它们在正则表达式上下文中的行为：\n\n字符 |\t描述\n:-: | ----\n\\\t|将下一个字符标记为一个特殊字符、或一个原义字符、或一个 向后引用、或一个八进制转义符。例如，'n' 匹配字符 \"n\"。'\\n' 匹配一个换行符。序列 '\\\\' 匹配 \"\\\" 而 \"\\(\" 则匹配 \"(\"。\n^\t|配输入字符串的开始位置。如果设置了 RegExp 对象的 Multiline 属性，^ 也匹配 '\\n' 或 '\\r' 之后的位置。\n\\$\t|匹配输入字符串的结束位置。如果设置了RegExp 对象的 Multiline 属性，$ 也匹配 '\\n' 或 '\\r' 之前的位置。\n\\*|匹配前面的子表达式零次或多次。例如，zo* 能匹配 \"z\" 以及 \"zoo\"。* 等价于{0,}。\n+|匹配前面的子表达式一次或多次。例如，'zo+' 能匹配 \"zo\" 以及 \"zoo\"，但不能匹配 \"z\"。+ 等价于 {1,}。\n?\t|匹配前面的子表达式零次或一次。例如，\"do(es)?\" 可以匹配 \"do\" 或 \"does\" 中的\"do\" 。? 等价于 {0,1}。\n{n}\t|n 是一个非负整数。匹配确定的 n 次。例如，'o{2}' 不能匹配 \"Bob\" 中的 'o'，但是能匹配 \"food\" 中的两个 o。\n{n,}\t|n 是一个非负整数。至少匹配n 次。例如，'o{2,}' 不能匹配 \"Bob\" 中的 'o'，但能匹配 \"foooood\" 中的所有 o。'o{1,}' 等价于 'o+'。'o{0,}' 则等价于 'o*'。\n{n,m}\t|m 和 n 均为非负整数，其中n <= m。最少匹配 n 次且最多匹配 m 次。例如，\"o{1,3}\" 将匹配 \"fooooood\" 中的前三个 o。'o{0,1}' 等价于 'o?'。请注意在逗号和两个数之间不能有空格。\n?\t|当该字符紧跟在任何一个其他限制符 (*, +, ?, {n}, {n,}, {n,m}) 后面时，匹配模式是非贪婪的。非贪婪模式尽可能少的匹配所搜索的字符串，而默认的贪婪模式则尽可能多的匹配所搜索的字符串。例如，对于字符串 \"oooo\"，'o+?' 将匹配单个 \"o\"，而 'o+' 将匹配所有 'o'。\n.\t|匹配除 \"\\n\" 之外的任何单个字符。要匹配包括 '\\n' 在内的任何字符，请使用像\"(.|\\n)\"的模式。\n(pattern)|匹配 pattern 并获取这一匹配。所获取的匹配可以从产生的 Matches 集合得到，在VBScript 中使用 SubMatches 集合，在JScript 中则使用 $0…$9 属性。要匹配圆括号字符，请使用 '\\(' 或 '\\)'。\n(?:pattern)|匹配 pattern 但不获取匹配结果，也就是说这是一个非获取匹配，不进行存储供以后使用。这在使用 \"或\" 字符 (|) 来组合一个模式的各个部分是很有用。例如， 'industr(?:y|ies) 就是一个比 'industry|industries' 更简略的表达式。\n(?=pattern)\t|正向预查，在任何匹配 pattern 的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如，'Windows (?=95|98|NT|2000)' 能匹配 \"Windows 2000\" 中的 \"Windows\" ，但不能匹配 \"Windows 3.1\" 中的 \"Windows\"。预查不消耗字符，也就是说，在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始。\n(?!pattern)\t|负向预查，在任何不匹配 pattern 的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如'Windows (?!95|98|NT|2000)' 能匹配 \"Windows 3.1\" 中的 \"Windows\"，但不能匹配 \"Windows 2000\" 中的 \"Windows\"。预查不消耗字符，也就是说，在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始。\nx\\|y|匹配 x 或 y。例如，'z|food' 能匹配 \"z\" 或 \"food\"。'(z|f)ood' 则匹配 \"zood\" 或 \"food\"。\n[xyz]\t|字符集合。匹配所包含的任意一个字符。例如， '[abc]' 可以匹配 \"plain\" 中的 'a'。\n[^xyz]\t|负值字符集合。匹配未包含的任意字符。例如， '[^abc]' 可以匹配 \"plain\" 中的'p'、'l'、'i'、'n'。\n[a-z]\t|字符范围。匹配指定范围内的任意字符。例如，'[a-z]' 可以匹配 'a' 到 'z' 范围内的任意小写字母字符。\n[^a-z]\t|负值字符范围。匹配任何不在指定范围内的任意字符。例如，'[^a-z]' 可以匹配任何不在 'a' 到 'z' 范围内的任意字符。\n\\b\t|匹配一个单词边界，也就是指单词和空格间的位置。例如， 'er\\b' 可以匹配\"never\" 中的 'er'，但不能匹配 \"verb\" 中的 'er'。\n\\B\t|匹配非单词边界。'er\\B' 能匹配 \"verb\" 中的 'er'，但不能匹配 \"never\" 中的 'er'。\n\\cx\t|匹配由 x 指明的控制字符。例如， \\cM 匹配一个 Control-M 或回车符。x 的值必须为 A-Z 或 a-z 之一。否则，将 c 视为一个原义的 'c' 字符。\n\\d\t|匹配一个数字字符。等价于 [0-9]。\n\\D\t|匹配一个非数字字符。等价于 [^0-9]。\n\\f\t|匹配一个换页符。等价于 \\x0c 和 \\cL。\n\\n\t|匹配一个换行符。等价于 \\x0a 和 \\cJ。\n\\r\t|匹配一个回车符。等价于 \\x0d 和 \\cM。\n\\s\t|匹配任何空白字符，包括空格、制表符、换页符等等。等价于 [ \\f\\n\\r\\t\\v]。\n\\S\t|匹配任何非空白字符。等价于 [^ \\f\\n\\r\\t\\v]。\n\\t\t|匹配一个制表符。等价于 \\x09 和 \\cI。\n\\v\t|匹配一个垂直制表符。等价于 \\x0b 和 \\cK。\n\\w\t|匹配包括下划线的任何单词字符。等价于'[A-Za-z0-9_]'。\n\\W\t|匹配任何非单词字符。等价于 '[^A-Za-z0-9_]'。\n\\xn\t|匹配 n，其中 n 为十六进制转义值。十六进制转义值必须为确定的两个数字长。例如，'\\x41' 匹配 \"A\"。'\\x041' 则等价于 '\\x04' & \"1\"。正则表达式中可以使用 ASCII 编码。\n\\num|匹配 num，其中 num 是一个正整数。对所获取的匹配的引用。例如，'(.)\\1' 匹配两个连续的相同字符。\n\\n\t|标识一个八进制转义值或一个向后引用。如果 \\n 之前至少 n 个获取的子表达式，则 n 为向后引用。否则，如果 n 为八进制数字 (0-7)，则 n 为一个八进制转义值。\n\\nm\t|标识一个八进制转义值或一个向后引用。如果 \\nm 之前至少有 nm 个获得子表达式，则 nm 为向后引用。如果 \\nm 之前至少有 n 个获取，则 n 为一个后跟文字 m 的向后引用。如果前面的条件都不满足，若 n 和 m 均为八进制数字 (0-7)，则 \\nm 将匹配八进制转义值 nm。\n\\nml|如果 n 为八进制数字 (0-3)，且 m 和 l 均为八进制数字 (0-7)，则匹配八进制转义值 nml。\n\\un\t|匹配 n，其中 n 是一个用四个十六进制数字表示的 Unicode 字符。例如， \\u00A9 匹配版权符号 (?)。\n\n## **五. 运算符优先级**\n\n正则表达式从左到右进行计算，并遵循优先级顺序，这与算术表达式非常类似。\n相同优先级的从左到右进行运算，不同优先级的运算先高后低。下表从最高到最低说明了各种正则表达式运算符的优先级顺序：\n\n运算符|\t描述\n:-| ---\n\\\t|转义符\n(), (?:), (?=), []\t|圆括号和方括号\n*, +, ?, {n}, {n,}, {n,m}\t|限定符\n^, $, \\任何元字符、任何字符\t|定位点和序列（即：位置和顺序）\n\\||替换，\"或\"操作字符具有高于替换运算符的优先级，使得\"m\\|food\"匹配\"m\"或\"food\"。若要匹配\"mood\"或\"food\"，请使用括号创建子表达式，从而产生\"(m\\|f)ood\"。\n\n\n## **六. 匹配规则**\n\n#### **1. 基本模式匹配**\n一切从最基本的开始。模式，是正规表达式最基本的元素，它们是一组描述字符串特征的字符。模式可以很简单，由普通的字符串组成，也可以非常复杂，往往用特殊的字符表示一个范围内的字符、重复出现，或表示上下文。例如：\n`^once`\n\n这个模式包含一个特殊的字符^，表示该模式只匹配那些以once开头的字符串。例如该模式与字符串\"once upon a time\"匹配，与\"There once was a man from NewYork\"不匹配。正如如^符号表示开头一样，$符号用来匹配那些以给定模式结尾的字符串。\n`bucket$`\n\n这个模式与\"Who kept all of this cash in a bucket\"匹配，与\"buckets\"不匹配。字符^和$同时使用时，表示精确匹配（字符串与模式一样）。例如：\n`^bucket$`\n\n只匹配字符串\"bucket\"。如果一个模式不包括^和$，那么它与任何包含该模式的字符串匹配。例如：模式\n> once\n\n与字符串\n> There once was a man from NewYork\nWho kept all of his cash in a bucket.\n\n是匹配的。\n在该模式中的字母(o-n-c-e)是字面的字符，也就是说，他们表示该字母本身，数字也是一样的。其他一些稍微复杂的字符，如标点符号和白字符（空格、制表符等），要用到转义序列。所有的转义序列都用反斜杠(\\)打头。制表符的转义序列是：\\t。所以如果我们要检测一个字符串是否以制表符开头，可以用这个模式：\n> ^\\t \n\n类似的，用\\n表示\"新行\"，\\r表示回车。其他的特殊符号，可以用在前面加上反斜杠，如反斜杠本身用\\\\表示，句号.用\\.表示，以此类推。\n\n#### **2. 字符簇**\n字符簇\n在INTERNET的程序中，正规表达式通常用来验证用户的输入。当用户提交一个FORM以后，要判断输入的电话号码、地址、EMAIL地址、信用卡号码等是否有效，用普通的基于字面的字符是不够的。\n所以要用一种更自由的描述我们要的模式的办法，它就是字符簇。要建立一个表示所有元音字符的字符簇，就把所有的元音字符放在一个方括号里：\n> [AaEeIiOoUu]\n\n这个模式与任何元音字符匹配，但只能表示一个字符。用连字号可以表示一个字符的范围，如：\n>[a-z] //匹配所有的小写字母 \n[A-Z] //匹配所有的大写字母 \n[a-zA-Z] //匹配所有的字母 \n[0-9] //匹配所有的数字 \n[0-9\\.\\-] //匹配所有的数字，句号和减号 \n[ \\f\\r\\t\\n] //匹配所有的白字符\n\n同样的，这些也只表示一个字符，这是一个非常重要的。如果要匹配一个由一个小写字母和一位数字组成的字符串，比如\"z2\"、\"t6\"或\"g7\"，但不是\"ab2\"、\"r2d3\" 或\"b52\"的话，用这个模式：\n> ^[a-z][0-9]$\n\n尽管[a-z]代表26个字母的范围，但在这里它只能与第一个字符是小写字母的字符串匹配。\n前面曾经提到^表示字符串的开头，但它还有另外一个含义。当在一组方括号里使用^是，它表示\"非\"或\"排除\"的意思，常常用来剔除某个字符。还用前面的例子，我们要求第一个字符不能是数字：\n> ^[^0-9][0-9]$\n\n这个模式与\"&5\"、\"g7\"及\"-2\"是匹配的，但与\"12\"、\"66\"是不匹配的。下面是几个排除特定字符的例子：\n>[^a-z] //除了小写字母以外的所有字符 \n[^\\\\\\/\\^] //除了(\\)(/)(^)之外的所有字符 \n[^\\\"\\'] //除了双引号(\")和单引号(')之外的所有字符\n\n特殊字符\".\" (点，句号)在正则表达式中用来表示除了\"新行\"之外的所有字符。所以模式\"^.5$\"与任何两个字符的、以数字5结尾和以其他非\"新行\"字符开头的字符串匹配。模式\".\"可以匹配任何字符串，除了空串和只包括一个\"新行\"的字符串。\nPHP的正规表达式有一些内置的通用字符簇，列表如下：\n\n字符簇|\t描述\n-|-\n[[:alpha:]]\t|任何字母\n[[:digit:]]\t|任何数字\n[[:alnum:]]\t|任何字母和数字\n[[:space:]]\t|任何空白字符\n[[:upper:]]\t|任何大写字母\n[[:lower:]]\t|任何小写字母\n[[:punct:]]\t|任何标点符号\n[[:xdigit:]]\t|任何16进制的数字，相当于[0-9a-fA-F]\n\n#### **4. 确定重复出现**\n到现在为止，你已经知道如何去匹配一个字母或数字，但更多的情况下，可能要匹配一个单词或一组数字。一个单词有若干个字母组成，一组数字有若干个单数组成。跟在字符或字符簇后面的花括号({})用来确定前面的内容的重复出现的次数。\n\n字符簇\t|描述\n-|-\n^[a-zA-Z_]$\t|所有的字母和下划线\n^[[:alpha:]]{3}$|\t所有的3个字母的单词\n^a$\t|字母a\n^a{4}$|\taaaa\n^a{2,4}$\t|aa,aaa或aaaa\n^a{1,3}$\t|a,aa或aaa\n^a{2,}$\t|包含多于两个a的字符串\n^a{2,}\t|如：aardvark和aaab，但apple不行\na{2,}\t|如：baad和aaa，但Nantucket不行\n\\t{2}\t|两个制表符\n.{2}\t|所有的两个字符\n\n这些例子描述了花括号的三种不同的用法。一个数字 {x} 的意思**是前面的字符或字符簇只出现x次** ；一个数字加逗号** {x,}** 的意思是**前面的内容出现x或更多的次数** ；两个数字用逗号分隔的数字** {x,y}** 表示 **前面的内容至少出现x次，但不超过y次**。我们可以把模式扩展到更多的单词或数字：\n>^[a-zA-Z0-9_]{1,}$      // 所有包含一个以上的字母、数字或下划线的字符串 \n^[1-9][0-9]{0,}$        // 所有的正整数 \n^\\-{0,1}[0-9]{1,}$      // 所有的整数 \n^[-]?[0-9]+\\.?[0-9]+$   // 所有的浮点数\n\n最后一个例子不太好理解，是吗？这么看吧：以一个可选的负号 (**[-]?**) 开头 (^)、跟着1个或更多的数字(**[0-9]+**)、和一个小数点(\\.)再跟上1个或多个数字(**[0-9]+**)，并且后面没有其他任何东西(**$**)。下面你将知道能够使用的更为简单的方法。\n\n特殊字符** ?** 与 **{0,1}** 是相等的，它们都代表着： **0个或1个前面的内容** 或 **前面的内容是可选的** 。所以刚才的例子可以简化为：\n>^\\-?[0-9]{1,}\\.?[0-9]{1,}$\n\n特殊字符 ***** 与 **{0,}** 是相等的，它们都代表着 **0 个或多个前面的内容** 。最后，字符 **+** 与 **{1,}** 是相等的，表示 **1 个或多个前面的内容** ，所以上面的4个例子可以写成：\n>^[a-zA-Z0-9_]+\\$      // 所有包含一个以上的字母、数字或下划线的字符串 \n^[1-9][0-9]*\\$        // 所有的正整数 \n^\\-?[0-9]+\\$          // 所有的整数 \n^\\-?[0-9]+\\.?[0-9]*\\$ // 所有的浮点数\n\n当然这并不能从技术上降低正规表达式的复杂性，但可以使它们更容易阅读。\n\n## **七. 示例**\n\n#### **1. 简单表达式**\n正则表达式的最简单形式是在搜索字符串中匹配其本身的单个普通字符。例如，单字符模式，如 A，不论出现在搜索字符串中的何处，它总是匹配字母 A。下面是一些单字符正则表达式模式的示例：\n>/a/\n/7/\n/M/\n\n可以将许多单字符组合起来以形成大的表达式。例如，以下正则表达式组合了单字符表达式：a、7 和 M。\n> /a7M/\n\n请注意，没有串联运算符。只须在一个字符后面键入另一个字符。\n\n#### **2. 字符匹配**\n\n句点 (.) 匹配字符串中的各种打印或非打印字符，只有一个字符例外。这个例外就是换行符 (\\n)。下面的正则表达式匹配 aac、abc、acc、adc 等等，以及 a1c、a2c、a-c 和 a#c：\n> /a.c/\n\n若要匹配包含文件名的字符串，而句点 (.) 是输入字符串的组成部分，请在正则表达式中的句点前面加反斜扛 (\\) 字符。举例来说明，下面的正则表达式匹配 filename.ext：\n> /filename\\.ext/\n\n这些表达式只让您匹配\"任何\"单个字符。可能需要匹配列表中的特定字符组。例如，可能需要查找用数字表示的章节标题（Chapter 1、Chapter 2 等等）。\n\n#### **3. 中括号表达式**\n\n若要创建匹配字符组的一个列表，请在方括号（[ 和 ]）内放置一个或更多单个字符。当字符括在中括号内时，该列表称为\"中括号表达式\"。与在任何别的位置一样，普通字符在中括号内表示其本身，即，它在输入文本中匹配一次其本身。大多数特殊字符在中括号表达式内出现时失去它们的意义。不过也有一些例外，如：\n\n - 如果 ] 字符不是第一项，它结束一个列表。若要匹配列表中的 ] 字符，请将它放在第一位，紧跟在开始 [ 后面。\n - \\ 字符继续作为转义符。若要匹配 \\ 字符，请使用 \\\\\\。\n\n括在中括号表达式中的字符只匹配处于正则表达式中该位置的单个字符。以下正则表达式匹配 Chapter 1、Chapter 2、Chapter 3、Chapter 4 和 Chapter 5：\n>/Chapter [12345]/\n\n请注意，单词 Chapter 和后面的空格的位置相对于中括号内的字符是固定的。中括号表达式指定的只是匹配紧跟在单词 Chapter 和空格后面的单个字符位置的字符集。这是第九个字符位置。\n若要使用范围代替字符本身来表示匹配字符组，请使用连字符 (-) 将范围中的开始字符和结束字符分开。单个字符的字符值确定范围内的相对顺序。下面的正则表达式包含范围表达式，该范围表达式等效于上面显示的中括号中的列表。\n> /Chapter [1-5]/\n\n当以这种方式指定范围时，开始值和结束值两者都包括在范围内。注意，还有一点很重要，按 Unicode 排序顺序，开始值必须在结束值的前面。\n若要在中括号表达式中包括连字符，请采用下列方法之一：\n\n - 用反斜扛将它转义：\n>[\\-]\n \n - 将连字符放在中括号列表的开始或结尾。下面的表达式匹配所有小写字母和连字符：\n>[-a-z]\n[a-z-]\n \n - 创建一个范围，在该范围中，开始字符值小于连字符，而结束字符值等于或大于连字符。下面的两个正则表达式都满足这一要求：\n>[!--]\n[!-~]\n\n若要查找不在列表或范围内的所有字符，请将插入符号 (^) 放在列表的开头。如果插入字符出现在列表中的其他任何位置，则它匹配其本身。下面的正则表达式匹配1、2、3、4 或 5 之外的任何数字和字符：\n\n> /Chapter [^12345]/\n\n在上面的示例中，表达式在第九个位置匹配 1、2、3、4 或 5 之外的任何数字和字符。这样，例如，Chapter 7 就是一个匹配项，Chapter 9 也是一个匹配项。\n上面的表达式可以使用连字符 (-) 来表示：\n> /Chapter [^1-5]/\n\n中括号表达式的典型用途是指定任何大写或小写字母或任何数字的匹配。下面的表达式指定这样的匹配：\n> /[A-Za-z0-9]/\n\n#### **4. 替换和分组**\n\n替换使用 | 字符来允许在两个或多个替换选项之间进行选择。例如，可以扩展章节标题正则表达式，以返回比章标题范围更广的匹配项。但是，这并不象您可能认为的那样简单。替换匹配 | 字符任一侧最大的表达式。\n您可能认为，下面的表达式匹配出现在行首和行尾、后面跟一个或两个数字的 Chapter 或 Section：\n> /^Chapter|Section [1-9][0-9]{0,1}$/\n\n很遗憾，上面的正则表达式要么匹配行首的单词 Chapter，要么匹配行尾的单词 Section 及跟在其后的任何数字。如果输入字符串是 Chapter 22，那么上面的表达式只匹配单词 Chapter。如果输入字符串是 Section 22，那么该表达式匹配 Section 22。\n若要使正则表达式更易于控制，可以使用括号来限制替换的范围，即，确保它只应用于两个单词 Chapter 和 Section。但是，括号也用于创建子表达式，并可能捕获它们以供以后使用，这一点在有关反向引用的那一节讲述。通过在上面的正则表达式的适当位置添加括号，就可以使该正则表达式匹配 Chapter 1 或 Section 3。\n下面的正则表达式使用括号来组合 Chapter 和 Section，以便表达式正确地起作用：\n> /^(Chapter|Section) [1-9][0-9]{0,1}$/\n\n尽管这些表达式正常工作，但 Chapter|Section 周围的括号还将捕获两个匹配字中的任一个供以后使用。由于在上面的表达式中只有一组括号，因此，只有一个被捕获的\"子匹配项\"。\n\n在上面的示例中，您只需要使用括号来组合单词 Chapter 和 Section 之间的选择。若要防止匹配被保存以备将来使用，请在括号内正则表达式模式之前放置 ?:。下面的修改提供相同的能力而不保存子匹配项：\n> /^(?:Chapter|Section) [1-9][0-9]{0,1}$/\n\n除 ?: 元字符外，两个其他非捕获元字符创建被称为\"预测先行\"匹配的某些内容。正向预测先行使用 ?= 指定，它匹配处于括号中匹配正则表达式模式的起始点的搜索字符串。反向预测先行使用 ?! 指定，它匹配处于与正则表达式模式不匹配的字符串的起始点的搜索字符串。\n<br>\n例如，假设您有一个文档，该文档包含指向 Windows 3.1、Windows 95、Windows 98 和 Windows NT 的引用。再进一步假设，您需要更新该文档，将指向 Windows 95、Windows 98 和 Windows NT 的所有引用更改为 Windows 2000。下面的正则表达式（这是一个正向预测先行的示例）匹配 Windows 95、Windows 98 和 Windows NT：\n> /Windows(?=95 |98 |NT )/\n\n找到一处匹配后，紧接着就在匹配的文本（不包括预测先行中的字符）之后搜索下一处匹配。例如，如果上面的表达式匹配 Windows 98，将在 Windows 之后而不是在 98 之后继续搜索。\n\n#### **5. 其他示例**\n\n下面列出一些正则表达式示例：\n\n正则表达式\t|描述\n-| -\n/\\b([a-z]+) \\1\\b/gi\t|一个单词连续出现的位置。\n/(\\w+):\\/\\/([^/:]+)(:\\d*)?([^# ]*)/\t|将一个URL解析为协议、域、端口及相对路径。\n/^(?:Chapter\\|Section) [1-9][0-9]{0,1}\\$/\t|定位章节的位置。\n/[-a-z]/\t|a至z共26个字母再加一个-号。\n/ter\\b/\t|可匹配chapter，而不能匹配terminal。\n/\\Bapt/\t|可匹配chapter，而不能匹配aptitude。\n/Windows(?=95 \\|98 \\|NT )/\t|可匹配Windows95或Windows98或WindowsNT，当找到一个匹配后，从Windows后面开始进行下一次的检索匹配。\n/^\\s*$/\t|匹配空行。\n/\\d{2}-\\d{5}/\t|验证由两位数字、一个连字符再加 5 位数字组成的 ID 号。\n/<\\s*(\\S+)(\\s[^>]*)?>[\\s\\S]*<\\s*\\/\\1\\s*>/\t|匹配 HTML 标记。","tags":["正则表达式"],"categories":["正则"]}]